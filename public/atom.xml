<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[OpenTable Tech UK Blog]]></title>
  <link href="http://tech.opentable.co.uk/atom.xml" rel="self"/>
  <link href="http://tech.opentable.co.uk/"/>
  <updated>2016-01-07T12:12:26+00:00</updated>
  <id>http://tech.opentable.co.uk/</id>
  <author>
    <name><![CDATA[OpenTable]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Testing React Components]]></title>
    <link href="http://tech.opentable.co.uk/blog/2016/01/07/react-testing/"/>
    <updated>2016-01-07T11:00:00+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2016/01/07/react-testing</id>
    <content type="html"><![CDATA[<p>At OpenTable it’s becoming an increasingly popular trend to use <em><a href="https://facebook.github.io/react/">React</a></em>.
One of the reasons for this is the ability for it  to server-side render whilst still
giving us the client side flexibility that we all crave!</p>

<p>We all know to have stable, reliable software you need to have well written tests. Facebook knows this and
provides the handy <em><a href="https://facebook.github.io/react/docs/test-utils.html">Test Utilities</a></em> library to make
our lives easier.</p>

<p>Cool — I hear you all say! But what is the best approach to testing React components?</p>

<p>Well unfortunately this is something that is not very well documented and if not approached in
the correct way can lead to brittle tests.</p>

<p>Therefore I have written this blog post to discuss the different approaches we have available to us.</p>

<p>All code used in this post is avaliable on my <em><a href="https://github.com/chriscartlidge/React-Testing-Blog-Code">GitHub</a></em>.</p>

<h2>The Basics</h2>

<p>To make our lives a lot easier when writing test it&rsquo;s best to use a couple of basic tools. Below is
the absolute minimum required to start testing React components.</p>

<ul>
<li><em><a href="https://mochajs.org/">Mocha</a></em> &ndash; This is a testing framework that runs in the browser or Node.JS (others are available).</li>
<li><em><a href="https://facebook.github.io/react/docs/test-utils.html">ReactTestUtils</a></em> &ndash; This is the basic testing framework that Facebook provides to go testing with React.</li>
</ul>


<h2>The Scenario</h2>

<p>We have a landing page broken down into two separate components:</p>

<ul>
<li>Container &ndash; The holding container for all sub-components.</li>
<li>Menu Bar &ndash; Contains the site navigation and is always displayed.</li>
</ul>


<p><img src="http://tech.opentable.co.uk/images/posts/react-comp.png" alt="react-comp" /></p>

<p>Each React component is self-contained and should be tested in isolation.</p>

<p>For the purpose of this exercise we will focus on the test for the container component and
making sure that the menu bar is displayed within it.</p>

<h2>Approach 1 (Full DOM):</h2>

<p>I like to call this the “Full DOM” approach because you take a component and render it in its entirety
including all of its children. The React syntax are transformed and any assertion
you make will be against the rendered HTML elements.</p>

<p>Below is our test scenario written in this approach.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">import</span> <span class="nx">React</span> <span class="nx">from</span> <span class="s1">&#39;react/addons&#39;</span><span class="p">;</span>
</span><span class='line'><span class="p">...</span>
</span><span class='line'><span class="kr">import</span> <span class="nx">jsdom</span> <span class="nx">from</span> <span class="s1">&#39;jsdom&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="nx">global</span><span class="p">.</span><span class="nb">document</span> <span class="o">=</span> <span class="nx">jsdom</span><span class="p">.</span><span class="nx">jsdom</span><span class="p">(</span><span class="s1">&#39;&lt;!doctype html&gt;&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;&#39;</span><span class="p">);</span>
</span><span class='line'><span class="nx">global</span><span class="p">.</span><span class="nb">window</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">parentWindow</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="nx">describe</span><span class="p">(</span><span class="s1">&#39;Container&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">it</span><span class="p">(</span><span class="s1">&#39;Show the menu bar&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="kd">let</span> <span class="nx">container</span> <span class="o">=</span> <span class="nx">TestUtils</span><span class="p">.</span><span class="nx">renderIntoDocument</span><span class="p">(</span><span class="o">&lt;</span><span class="nx">Container</span> <span class="o">/&gt;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">let</span> <span class="nx">result</span> <span class="o">=</span> <span class="nx">TestUtils</span><span class="p">.</span><span class="nx">scryRenderedDOMComponentsWithClass</span><span class="p">(</span><span class="nx">container</span><span class="p">,</span>
</span><span class='line'>      <span class="s1">&#39;menu-bar-container&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">assert</span><span class="p">.</span><span class="nx">lengthOf</span><span class="p">(</span><span class="nx">result</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</span><span class='line'>  <span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you run the above test it passes but how does it work?</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">import</span> <span class="nx">jsdom</span> <span class="nx">from</span> <span class="s1">&#39;jsdom&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="nx">global</span><span class="p">.</span><span class="nb">document</span> <span class="o">=</span> <span class="nx">jsdom</span><span class="p">.</span><span class="nx">jsdom</span><span class="p">(</span><span class="s1">&#39;&lt;!doctype html&gt;&lt;html&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;&#39;</span><span class="p">);</span>
</span><span class='line'><span class="nx">global</span><span class="p">.</span><span class="nb">window</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">parentWindow</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>This sets up our DOM which is a requirement of <em><a href="https://facebook.github.io/react/docs/test-utils.html#renderintodocument">TestUtils.renderIntoDocument</a></em>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">let</span> <span class="nx">container</span> <span class="o">=</span> <span class="nx">TestUtils</span><span class="p">.</span><span class="nx">renderIntoDocument</span><span class="p">(</span><span class="o">&lt;</span><span class="nx">Container</span> <span class="o">/&gt;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p><em><a href="https://facebook.github.io/react/docs/test-utils.html#renderintodocument">TestUtils.renderIntoDocument</a></em> then takes the React syntax and renders it into the DOM as HTML.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">let</span> <span class="nx">result</span> <span class="o">=</span> <span class="nx">TestUtils</span><span class="p">.</span><span class="nx">scryRenderedDOMComponentsWithClass</span><span class="p">(</span><span class="nx">container</span><span class="p">,</span> <span class="s1">&#39;menu-bar-container&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>We now query the DOM for a unique class that is contained within the menu-bar and get an array of
DOM elements back which we can assert against.</p>

<p>The example above is a common approach but is it necessarily the best way?</p>

<p>From my point of view no, as this approach makes our tests brittle. We are exposing and querying on the inner workings
of the menu-bar and if someone was to refactor it and remove/rename the &ldquo;menu-bar-container&rdquo; class then our test would fail.</p>

<h2>Approach 2 (Shallow Rendering):</h2>

<p>With the release of React 0.13 Facebook provided the ability to “shallow render” a component.
This allows you to instantiate a component and get the result of its render function, a ReactElement, without a DOM.
It also only renders the component one level deep so you can keep your tests more focused.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">import</span> <span class="nx">React</span><span class="p">,</span> <span class="p">{</span> <span class="nx">addons</span> <span class="p">}</span> <span class="nx">from</span> <span class="s1">&#39;react/addons&#39;</span><span class="p">;</span>
</span><span class='line'><span class="kr">import</span> <span class="nx">Container</span> <span class="nx">from</span> <span class="s1">&#39;../../src/Container&#39;</span><span class="p">;</span>
</span><span class='line'><span class="kr">import</span> <span class="nx">MenuBar</span> <span class="nx">from</span> <span class="s1">&#39;../../src/MenuBar&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="nx">describe</span><span class="p">(</span><span class="s1">&#39;Container&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">shallowRenderer</span> <span class="o">=</span> <span class="nx">React</span><span class="p">.</span><span class="nx">addons</span><span class="p">.</span><span class="nx">TestUtils</span><span class="p">.</span><span class="nx">createRenderer</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">it</span><span class="p">(</span><span class="s1">&#39;Show the menu bar&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">shallowRenderer</span><span class="p">.</span><span class="nx">render</span><span class="p">(</span><span class="o">&lt;</span><span class="nx">Container</span><span class="o">/&gt;</span><span class="p">);</span>
</span><span class='line'>    <span class="kd">let</span> <span class="nx">result</span> <span class="o">=</span> <span class="nx">shallowRenderer</span><span class="p">.</span><span class="nx">getRenderOutput</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">assert</span><span class="p">.</span><span class="nx">deepEqual</span><span class="p">(</span><span class="nx">result</span><span class="p">.</span><span class="nx">props</span><span class="p">.</span><span class="nx">children</span><span class="p">,</span> <span class="p">[</span>
</span><span class='line'>      <span class="o">&lt;</span><span class="nx">MenuBar</span> <span class="o">/&gt;</span>
</span><span class='line'>    <span class="p">]);</span>
</span><span class='line'>  <span class="p">});</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>Again like the previous example this passes but how does it work?</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">let</span> <span class="nx">shallowRenderer</span> <span class="o">=</span> <span class="nx">React</span><span class="p">.</span><span class="nx">addons</span><span class="p">.</span><span class="nx">TestUtils</span><span class="p">.</span><span class="nx">createRenderer</span><span class="p">();</span>
</span></code></pre></td></tr></table></div></figure>


<p>We first create the <em><a href="https://facebook.github.io/react/docs/test-utils.html#shallow-rendering">shallowRender</a></em> which handles the rendering of the React components.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">shallowRenderer</span><span class="p">.</span><span class="nx">render</span><span class="p">(</span><span class="o">&lt;</span><span class="nx">Container</span><span class="o">/&gt;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>Then we pass in the component we have under test to the <em><a href="https://facebook.github.io/react/docs/test-utils.html#shallow-rendering">shallowRender</a></em>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">let</span> <span class="nx">result</span> <span class="o">=</span> <span class="nx">shallowRenderer</span><span class="p">.</span><span class="nx">getRenderOutput</span><span class="p">();</span>
</span><span class='line'><span class="nx">assert</span><span class="p">.</span><span class="nx">deepEqual</span><span class="p">(</span><span class="nx">result</span><span class="p">.</span><span class="nx">props</span><span class="p">.</span><span class="nx">children</span><span class="p">,</span> <span class="p">[</span><span class="o">&lt;</span><span class="nx">MenuBar</span><span class="o">/&gt;</span><span class="p">]);</span>
</span></code></pre></td></tr></table></div></figure>


<p>And finally we get the output from the <em><a href="https://facebook.github.io/react/docs/test-utils.html#shallow-rendering">shallowRender</a></em> and
assert that the children contain the menu-bar component.</p>

<p>Is this approach any better than the previous? In my option yes and for the following reasons:</p>

<ul>
<li><p>We don&rsquo;t rely on the inner workings of the menu-bar to know if it has been rendered and therefore the markup can be refactored without
any of the
tests being broken.</p></li>
<li><p>Less dependencies are being used as <em><a href="https://facebook.github.io/react/docs/test-utils.html#shallow-rendering">shallowRender</a></em> does not require
a DOM to render into.</p></li>
<li><p>It&rsquo;s a lot easier to see what is being asserted as we are able to use JSX syntax in assertions.</p></li>
</ul>


<h2>Conclusion</h2>

<p>So is shallow rendering the silver bullet for React testing? Probably not as it still lacking on key feature for me when dealing
with large components and that is the ability to easily query the ReactDOM (libraries like <em><a href="https://github.com/airbnb/enzyme">enzyme</a></em>
are working towards improving this). But it is still a lot better than rendering the component out into HTML and coupling your tests
to the inner components of others.</p>

<p>In this blog post we have just scratched the surface of testing with React and I hope it&rsquo;s food for thought when writing your next set of
React tests.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppet-Community]]></title>
    <link href="http://tech.opentable.co.uk/blog/2015/05/06/puppet-community/"/>
    <updated>2015-05-06T09:00:00+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2015/05/06/puppet-community</id>
    <content type="html"><![CDATA[<p>Puppet is an important tool to us at OpenTable; we couldn’t operate as efficiently without it but Puppet is more than a tool or a vendor, it is a community of people trying to help
each other operate increasing complex and sophisticated infrastructures.</p>

<p>The Puppet community and the open source efforts that drive that community have always been important to us which is why we want to take a step further in our efforts and introduce
you to the &ldquo;Puppet-community&rdquo; project.</p>

<h2>What is Puppet-community</h2>

<p>Puppet-community is a GitHub organisation of like-minded individuals from across the wider Puppet ecosystem and from a diverse set of companies. Its principle aims are to allow the community to synchronise its efforts and to provide a GitHub organisation and Puppet Forge namespace not affiliated with any company.</p>

<p>Its wider aims are to provide a place for module and tool authors to share their code and the burden of maintaining it.</p>

<p>I would like to say that this was our idea, as it’s an excellent one, but actually all credit goes to its founders: <a href="https://github.com/igalic">Igor Galić</a>, <a href="https://github.com/daenney">Daniele Sluijters</a> and <a href="https://github.com/nibalizer">Spencer Krum</a></p>

<h2>Why communities matter</h2>

<p>So why all the fuss about this? Why does it even matter where your code lives?</p>

<p>Well these are the some questions that I asked myself when I first heard about this project at PuppetConf 2014. The answer is that is really does matter and it’s a pattern that is
developing elsewhere (see: <a href="https://github.com/packer-community">packer-community</a>, <a href="https://github.com/terraform-community-modules">terraform-community-modules</a>,
<a href="https://github.com/cloudfoundry-community">cloudfoundry-community</a>) to deal with the problems you’ll face with a large amount of open source code.</p>

<p>Stepping back slightly, if you look at open source then there are three types: product-based (think open-core), corporate/individual sponsored,  and community-driven.</p>

<p>The first is common for businesses (like PuppetLabs) who’s product is a open source product. They make great efforts to build a community, fix bugs and accept changes. They make  their money through extras (add-ons and/or professional services). They control what they will/won’t accept and are driven by the need to build that community as well as support those big paying customers who pay the bills &ndash; it’s a tough balancing act.</p>

<p>The second is what you probably mean when you think about open source. It’s a individual or company that dumps some code they have been working on to GitHub and that’s it &ndash; they own it, they control it, it they don&rsquo;t like your changes they don’t even have to give a reason. They can also choose to close or delete the project whenever they want or more likely they will just let it sit on GitHub and move onto the next thing.</p>

<p>The third is the community approach. Create a GitHub organisation, move your projects and add some new people in there with commit access. This is a different approach because it means
that you don’t own it any more, you don’t have that tight control over the codebase because there are other people with other opinions that you have to take into account. It also means
that on long weeks when you&rsquo;re on-call or on holiday that there is someone else to pick up the slack and merge those pull requests for you. It has massive benefits if you can keep that
ego in check.</p>

<h2>Why we’re moving our modules there</h2>

<p>So why is OpenTable moving its modules there? It is because we care about the community (particularly those using Puppet on Windows) and want to make sure there is good long term
support for the modules that we authored. OpenTable isn’t a company that authors Puppet modules, it is a company that seats diners in restaurants so from time to time we are going
to work on other things.</p>

<p>By being part of the community there will be other people who can help discuss and diagnose bugs, merge pull requests and generally help with any problems that arise when using
the modules we created.</p>

<p>Sometimes when writing a module it’s not about being the best, sometimes it’s just about being first &ndash; we got a bit lucky. What that means though is that we need to recognise that there
are plenty of people out there in the community that have better knowledge than us about a tool or application and might be better suited to guide the project forward &ndash; heck we might
even learn from them in the process.</p>

<p>So let’s lose our egos, loosen that grip and let those modules be free &hellip;</p>

<h2>What that means for you</h2>

<p>Ok, so let’s get practical for a second. What’s happening here? What our support of Puppet-community means is that our code has moved into a new organisation
(<a href="https://github.com/puppet-community">github.com/puppet-community</a>) and our modules have been re-released under the community namespace on the forge
(<a href="https://forge.puppetlabs.com/puppet">forge.puppetlabs.com/puppet</a>). So if you are using our modules then you should go and have a look on the forge and update to the latest versions.
We will continue to provide lots of support to these modules but so will lots of others (including some PuppetLabs employees) so expect the quality of the modules to also start increasing.</p>

<p>If you have any thoughts or questions about this you can reach out to me personally on twitter: <a href="twitter.com/liamjbennett">@liamjbennett</a> or via email at: <a href="mailto:liamjbennett@gmail.com">liamjbennett@gmail.com</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The DNS ABC]]></title>
    <link href="http://tech.opentable.co.uk/blog/2015/03/05/the-dns-abc/"/>
    <updated>2015-03-05T15:00:00+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2015/03/05/the-dns-abc</id>
    <content type="html"><![CDATA[<h2>Introduction to DNS</h2>

<p>Before joining OpenTable I was looking for a software engineer job and I&rsquo;ve done my fair share of interviews. A question that has popped out a lot, and when I say a lot I mean <em>always</em>, is:</p>

<p><em>Could you tell me what happens when I type an URL in a web browser on my computer and press enter?</em></p>

<p>Of course the possible answers could range from &ldquo;MMMHHH, wellll, I&rsquo;m not sure where to start&hellip;&rdquo; to a whole book on computer networks.</p>

<p>After a number of attempts to answer briefly and correctly, I&rsquo;ve concluded that mentioning <strong>DNS</strong> can make a reasonable start.</p>

<p>Let&rsquo;s think about it. When we type the address of the resource we want to browse, we use the alphabet, right? With letters and names easily readable and retainable by a human being.</p>

<p>But a machine needs an <strong>IP address</strong> to recognize another machine connected to a network. An IP address is numerical, for example 192.168.0.1. Less readable, it seems.</p>

<p>And here is where DNS comes to play. DNS stands for <strong>Domain Name System</strong>, and that represents exactly what it is: a system that translates <strong>domain names</strong> (e.g <em>www.opentable.co.uk</em>), into IP addresses. I think of it as a phone book. It is queried with a domain name and, after a lookup, returns an IP.</p>

<p>How does the magic happen? Let&rsquo;s look into it.</p>

<h2>The ABC</h2>

<h3>Some definitions</h3>

<p>So we can define a domain name as a string composed by one or more parts, called <strong>labels</strong>, concatenated and delimited by dots with a <strong>hierarchical</strong> logic.</p>

<p>In the case of www.opentable.co.uk, for instance, we have four labels:</p>

<ul>
<li><p><em>uk</em> is the <strong>top-level</strong> domain. This should sound familiar. Famous top-level domains are also <em>.net</em>, <em>.org</em>, <em>.uk</em>, <em>.it</em>, <em>.gov</em>, etc.</p></li>
<li><p><em>co</em> is the <strong>second level</strong> domain, which in this case specifies the commercial nature of the company.</p></li>
<li><p>Hierarchy goes from right to left, so then we can say that <em>opentable</em> is a <strong>subdomain</strong> of <em>co</em>. And so on.</p></li>
<li><p>A name that can be associated to a specific machine connected to a network with an IP address is called <strong>hostname</strong>. Let&rsquo;s say it&rsquo;s the leftmost label in the domain name.</p></li>
</ul>


<h3>Questions that pop out at this point</h3>

<p>Q: So all the host names reachable via a specific domain have a specific IP address! There must be BILLIONS of them. How do we make sure everyone is unique?</p>

<p>A: There are entities that have the authority to assign and register names under one or more top-level domain, called <strong>registrars</strong>. The registered name then becomes part of a central database known as the <em>whois database</em>.</p>

<p>Q: Now, how do we retrieve this infamous IP address by just knowing a domain name? Who can <strong>resolve</strong> this request?</p>

<p>A: Well, the domain name is resolved into an IP address by querying <strong>authoritative name servers</strong>. These machines are the endpoints of a database that can map domain names to IPs. The authoritative name servers of the top level domain are also called <a href="https://www.iana.org/domains/root/servers"><strong>root level servers</strong></a>.</p>

<p>Q: OK, but wait a second. How in the heavens does my machine know the address of the name server to query? I thought I just entered an address in the browser!</p>

<p>A: Every client machine has a default <strong>DNS resolver</strong>, which is responsible of initiating the sequence of queries that will ultimately lead to the resolution.
It is very important to note that the system&rsquo;s DNS setting can be also overridden by the <a href="http://www.ispreview.co.uk/list.shtml"><strong>Internet Service Provider</strong></a> (ISP) settings, so the DNS lookup process can be very OS-specific and ISP-specific. This would deserve a whole post apart.</p>

<h3>How to resolve an address (ideally)</h3>

<p>Resolving an address via DNS is also called <strong>lookup</strong>, and it is a recursive process. Now that we know the purpose of DNS, and the concepts involved in the process, we can dig a little deeper into its basic mechanism, which is roughly:</p>

<ol>
<li><p>The resolver has knowledge of the addresses of root name servers, from where the search can start.</p></li>
<li><p>The root name server will return a name server which is authoritative for the top-level domain.</p></li>
<li><p>This server will give the address of the name server authoritative for the second level domain.</p></li>
<li><p>If the hostname is resolved, an IP address is returned. Otherwise step 3) is repeated for all the labels of the domain name in sequence, until a result is reached.</p></li>
</ol>


<p>I made a diagram that shows that.</p>

<p><img src="http://federicomaffei.github.io/public/images/dnsbasic.jpg" class="center-image"></img></p>

<h3>Real life problems</h3>

<p>The mechanism explained above is great, but if applied in a real life application, it will lead to a bottleneck. Every lookup would involve root servers and authoritative servers, which would be hit by gazillions of queries every day, putting a huge burden on the system since the start.</p>

<p>To solve this, of course a <a href="http://blog.catchpoint.com/2014/07/15/world-dns-cache-king/"><strong>caching</strong></a> system comes to help. Yes, DNS allows and encourages caching. This way another class of DNS servers comes into play, the <strong>recursive name servers</strong>. They can perform recursive lookups and cache results, returning them when queried even if they don&rsquo;t have the authority to generate the results themselves.</p>

<p>Caching recursive DNS server are usually managed by Internet Service Providers, and are able to resolve addresses without waiting for the &ldquo;authorities&rdquo;. This means that a query will rarely have to hit the root name servers, since there is a very high likelihood that the hostname/IP request is already cached by one of the delegated DNS servers that are called by recursion.</p>

<p>We could say that in reality a root server will be hit as a last resort to track down an authoritative server for a given domain.</p>

<p>The amount of time for which a lookup result is stored on a server is called <a href="http://en.wikipedia.org/wiki/Time_to_live"><strong>time-to-live (TTL)</strong></a> and can vary with the configuration.</p>

<p>One side effect of the heavy caching that involves the DNS is that when a new domain is registered, or there is a change in any domain-related settings, there will be a time lag for the propagation of it to all the cached results.</p>

<p>It is noteworthy that cached DNS results from your browsing could be stored in your router, or somewhere within you browser memory as well. These IP addresses seem to be everywhere these days!</p>

<h2>Conclusion</h2>

<p>I barely scratched the surface of the Domain Name System topic, and that alone took a good day of research and writing.</p>

<p>So I decided to avoid making this post too long, so that beginners that are going to find it will profit, and be encouraged to research on these key concepts. This will allow me to decide which part of DNS is worth more digging, and maybe write a sequel. Stay tuned!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hapi.js and SIGTERM]]></title>
    <link href="http://tech.opentable.co.uk/blog/2015/02/16/hapi-js-and-sigterm/"/>
    <updated>2015-02-16T10:32:42+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2015/02/16/hapi-js-and-sigterm</id>
    <content type="html"><![CDATA[<p>When we first stood up our hapi.js APIs, we wrote init scripts to start/stop them. Stopping the server, was simply a case of sending SIGKILL (causing the app to immediately exit).</p>

<p>Whilst this is fine for most cases, if we want our apps to be good Linux citizens, then they should terminate gracefully. Hapi.js has the handy <code>server.stop(...)</code> command (see docs <a href="http://hapijs.com/api#serverstopoptions-callback">here</a>) which will terminate the server gracefully. It will cause the server to respond to new connections with a 503 (server unavailable), and wait for existing connections to terminate (up to some specified timeout), before stopping the server and allowing the node.js process to exit. Perfect.</p>

<p>This makes our graceful shutdown code really simple:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">process</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;SIGTERM&#39;</span><span class="p">,</span> <span class="kd">function</span><span class="p">(){</span>
</span><span class='line'>  <span class="nx">server</span><span class="p">.</span><span class="nx">stop</span><span class="p">({</span> <span class="nx">timeout</span><span class="o">:</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">},</span> <span class="kd">function</span><span class="p">(){</span>
</span><span class='line'>    <span class="nx">process</span><span class="p">.</span><span class="nx">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
</span><span class='line'>  <span class="p">});</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>When we see a SIGTERM, call <code>server.stop()</code>, then once the server has stopped, call <code>process.exit(0)</code>. Easy peasy.</p>

<h3>Throw a spanner in the works</h3>

<p>Whilst <code>server.stop()</code> is really useful, it has the problem that it immediately prevents the server from responding to new requests. In our case, that isn&rsquo;t particularly desirable. We use service-discovery, which means that the graceful termination of our app should run like this:</p>

<ul>
<li>SIGTERM</li>
<li>Unannounce from Service-Discovery</li>
<li><code>server.stop(...)</code></li>
<li><code>process.exit(0)</code></li>
</ul>


<p>Ideally we want the unannounce to happen before the server starts rejecting connections, in order to reduce the likelihood that clients will hit a server that is shutting down.</p>

<h3>Plugins to the rescue!</h3>

<p>Thanks to hapi.js&rsquo;s awesome plugin interface (<a href="http://t.co/GDw44SETfS">shameless self promotion</a>), we can do some magic to make the above possible.</p>

<p>I created a really simple plugin called <a href="https://www.npmjs.com/package/hapi-shutdown">hapi-shutdown</a> which will handle SIGTERM and then run triggers before calling <code>server.stop(...)</code>.</p>

<p>The idea is that it allows us to run the &lsquo;unannounce&rsquo; step, before <code>server.stop(...)</code> is called.</p>

<h3>How to use hapi-shutdown</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">server</span><span class="p">.</span><span class="nx">register</span><span class="p">([</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nx">plugin</span><span class="o">:</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;hapi-shutdown&#39;</span><span class="p">),</span>
</span><span class='line'>    <span class="nx">options</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">serverSpindownTime</span><span class="o">:</span> <span class="mi">5000</span> <span class="c1">// the timeout passed to server.stop(...)</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}],</span>
</span><span class='line'>  <span class="kd">function</span><span class="p">(</span><span class="nx">err</span><span class="p">){</span>
</span><span class='line'>    <span class="nx">server</span><span class="p">.</span><span class="nx">start</span><span class="p">(</span><span class="kd">function</span><span class="p">(){</span>
</span><span class='line'>
</span><span class='line'>      <span class="nx">server</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="s1">&#39;hapi-shutdown&#39;</span><span class="p">].</span><span class="nx">register</span><span class="p">({</span>
</span><span class='line'>        <span class="nx">taskname</span><span class="o">:</span> <span class="s1">&#39;do stuff&#39;</span><span class="p">,</span>
</span><span class='line'>        <span class="nx">task</span><span class="o">:</span> <span class="kd">function</span><span class="p">(</span><span class="nx">done</span><span class="p">){</span>
</span><span class='line'>          <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s1">&#39;doing stuff before server.stop is called&#39;</span><span class="p">);</span>
</span><span class='line'>          <span class="nx">done</span><span class="p">();</span>
</span><span class='line'>        <span class="p">},</span>
</span><span class='line'>        <span class="nx">timeout</span><span class="o">:</span> <span class="mi">2000</span> <span class="c1">// time to wait before forcibly returning</span>
</span><span class='line'>      <span class="p">})</span>
</span><span class='line'>    <span class="p">});</span>
</span><span class='line'>  <span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>The plugin exposes a <code>.register()</code> function which allows you to register your shutdown tasks. The tasks are named (to prevent multiple registrations), and each task must call the <code>done()</code> function. The <code>timeout</code> parameter is provided so that a task which never completes won&rsquo;t block the shutdown of the server.</p>

<p> Neat, huh?</p>

<h3>Hooking up unannounce using hapi-shutdown</h3>

<p>We now have a place to register our &lsquo;unannounce&rsquo; task. Our service-discovery code is wrapped in another plugin, which means we can use <code>server.dependency(...)</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// inside the plugin&#39;s register function</span>
</span><span class='line'>
</span><span class='line'><span class="nx">server</span><span class="p">.</span><span class="nx">dependency</span><span class="p">(</span><span class="s1">&#39;hapi-shutdown&#39;</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">_</span><span class="p">,</span> <span class="nx">cb</span><span class="p">){</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">err</span> <span class="o">=</span> <span class="nx">server</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="s1">&#39;hapi-shutdown&#39;</span><span class="p">].</span><span class="nx">register</span><span class="p">({</span>
</span><span class='line'>    <span class="nx">taskname</span><span class="o">:</span> <span class="s1">&#39;discovery-unannounce&#39;</span><span class="p">,</span>
</span><span class='line'>    <span class="nx">task</span><span class="o">:</span> <span class="kd">function</span><span class="p">(</span><span class="nx">done</span><span class="p">){</span>
</span><span class='line'>      <span class="nx">discovery</span><span class="p">.</span><span class="nx">unannounce</span><span class="p">(</span><span class="kd">function</span><span class="p">(){</span>
</span><span class='line'>        <span class="nx">done</span><span class="p">();</span>
</span><span class='line'>      <span class="p">});</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="nx">timeout</span><span class="o">:</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">1000</span>
</span><span class='line'>  <span class="p">});</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">cb</span><span class="p">(</span><span class="nx">err</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>server.dependency(...)</code> allows us to specify that this plugin relies on another plugin (or list of plugins). If the dependent plugin is not registered before the server starts, then an exception is thrown.</p>

<p>Handily, <code>server.dependency(...)</code> also takes a callback function, which is invoked after all the dependencies have been registered, which means that you don&rsquo;t need to worry about ordering inside your <code>server.register(...)</code> code.</p>

<p>This allows our unannounce code to be decoupled from the actual business of shutting down the server.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dismantling the monolith - Microsites at Opentable]]></title>
    <link href="http://tech.opentable.co.uk/blog/2015/02/09/dismantling-the-monolith-microsites-at-opentable/"/>
    <updated>2015-02-09T09:43:03+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2015/02/09/dismantling-the-monolith-microsites-at-opentable</id>
    <content type="html"><![CDATA[<p>A couple of years ago we started to break-up the code-base behind our consumer site <a href="http://www.opentable.com">opentable.com</a>, to smaller units of code, in order to improve our productivity. New teams were created with the goal of splitting up the logic that was powering the back-end and then bring to life new small services. Then, we started working on what we call <em>Microsites</em>.</p>

<h3>Microsites</h3>

<p>A microsite is a very small set of web-pages, or even a single one, that takes care of handling a very specific part of the system&rsquo;s domain logic. Examples are the <em>Search Results</em> page or the <em>Restaurant&rsquo;s Profile</em> page. Every microsite is an independently deployable unit of code, so it is easier to test, to deploy, and in consequence more resilient. Microsites are then all connected by a front-door service that handles the routing.</p>

<h3>Not a free ride</h3>

<p>When we deployed some microsites to production we immediately discovered a lot of pros:</p>

<ul>
<li>Bi-weekly deployments of the monolith became hundreds of deployments every week.</li>
<li>Not anymore a shared codebase for hundreds of engineers. Pull requests accepted, merged, and often deployed on the same day.</li>
<li>Teams experimenting and reiterating faster: product was happy.</li>
<li><em>Diversity</em> on tech stacks: teams were finally able to pick their own favourite web-stack, as soon as they were capable of deploying their code and taking care of it in terms of reliability and performance.</li>
<li>Robustness: when something was wrong with a microsite, everything else was fine.</li>
</ul>


<p>On the other hand, we soon realised that we introduced new problems on the system:</p>

<ul>
<li>Duplication: teams started duplicating a lot of code, specifically front-end components such as the header, the footer, etc.</li>
<li>Coordination: when we needed to change something on the header, for example, we were expecting to see the change live in different time frames, resulting in inconsistencies.</li>
<li>Performance: every microsite was hosting its own duplicated css, javascript libraries, and static resources; resulting as a big disadvantage for the end-user in terms of performance.</li>
</ul>


<h3>SRS &ndash; aka Site Resources Service</h3>

<p>To solve some of these problems we created a REST api to serve html snippets, that soon we started to call <em>components</em>. Main characteristics of the system are:</p>

<ul>
<li>We have components for shared parts of the website such as the header, the footer, and the adverts. When a change has to go live, we apply the change, we deploy, and we see the change live everywhere.</li>
<li>Output is in HTML format, so the integration is possible if the microsite is either a .NET MVC site or a node.js app.</li>
<li>We have components for the core CSS and the JS common libraries, so that all the microsites use the same resources and the browser can cache them making the navigation smooth.</li>
<li>The service takes care of hosting all the static resources in a separate CDN, so microsites don&rsquo;t have to host that resources.</li>
</ul>


<p>This is an example of a request to the <em>core</em> css component:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>curl http://srs-sc.otenv.com/v1/com-2014/resource-includes/css
</span><span class='line'>
</span><span class='line'><span class="o">{</span>
</span><span class='line'>  <span class="s2">&quot;href&quot;</span>: <span class="s2">&quot;http://srs-sc.otenv.com/v1/com-2014/resource-includes/css&quot;</span>,
</span><span class='line'>  <span class="s2">&quot;html&quot;</span>: <span class="s2">&quot;&lt;link rel=\&quot;stylesheet\&quot; href=\&quot;//na-srs.opentable.com/content/static-1.0.1388.0/css-new-min/app.css\&quot; /&gt;&lt;!--[if lte IE 8]&gt;&lt;link rel=\&quot;stylesheet\&quot; href=\&quot;//na-srs.opentable.com/content/static-1.0.1388.0/css-new-min/app_ie8.css\&quot; /&gt; &lt;![endif]--&gt;&quot;</span>,
</span><span class='line'>  <span class="s2">&quot;type&quot;</span>:<span class="s2">&quot;css&quot;</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The downside of this approach is that there is a strict dependency with SRS for each microsite. On every request, a call to SRS has to be made, so <strong>we had to work hard to guarantee reliability and good performance</strong>.</p>

<h2>Conclusions</h2>

<p>When we tried the microsite approach we “traded” some of our code problems with some new cultural problems. We became more agile and we were working in a new different way, with the downside of having the <strong>need to more effectively coordinate more people</strong>. The consequence is that the <strong>way we were approaching the code</strong> evolved over time.</p>

<p>One year later, with the front-end (almost completely) living on micro-sites, and with the help of SRS, we are experimenting more effective ways to be resilient and robust, with the specific goal to allow teams to create their own components and share them with other teams in order to be independent, and use them to easily approach to A/B experiments.</p>

<p>In the next post I&rsquo;ll write about <a href="https://github.com/opentable/oc">OpenComponents</a>, an experimental framework we just open-sourced that is trying to address some of this needs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Beginner's guide to REST services]]></title>
    <link href="http://tech.opentable.co.uk/blog/2015/02/02/a-beginners-guide-to-rest-services/"/>
    <updated>2015-02-02T11:53:25+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2015/02/02/a-beginners-guide-to-rest-services</id>
    <content type="html"><![CDATA[<h2>Why this post?</h2>

<p>As a junior, I always find it easier to just sit and write code than actually stop to think about the theoretical basis that lie under the applications I work on. <strong>REST</strong>  is one of those terms I heard a lot about, so I decided to try to sum up what it means and how it affects the choices we make everyday as software engineers.</p>

<h2>Introduction to REST</h2>

<p>REST stands for Representational State Transfer, and it can be defined as an architectural style used to build Web Services that are lightweight, maintainable, and scalable. A service that is designed by REST principles can be called a <strong>RESTful service</strong>.</p>

<p>It has been described first in 2000 by Roy Fielding, in a <a href="http://www.ics.uci.edu/~fielding/pubs/webarch_icse2000.pdf">dissertation</a> called &ldquo;Architectural Styles and the Design of Network-based Software Architectures&rdquo;. The basic idea was to describe the interactions between the components of a distributed system, putting constraints on them and emphasizing the importance of an uniform interface, that is abstracted from the single components.</p>

<p>REST is often applied to the design and development of web services, which is the scenario I&rsquo;ll try to address in this post.</p>

<p>The purpose of a web service can be summed up as follows: it exposes <strong>resources</strong> to a <strong>client</strong> so that it can have access to them (examples of typical resources include pictures, video files, web pages and business data).</p>

<p>Common features of a service that is built in a REST style are:</p>

<ul>
<li>Representations</li>
<li>Messages</li>
<li>URIs</li>
<li>Uniform Interface</li>
<li>Statelessness</li>
<li>Links between resources</li>
<li>Caching</li>
</ul>


<h2>Representations &ndash; what are they?</h2>

<p>REST style does not put a constraint into the way resources are represented, as long as their format is understandable by the client.</p>

<p>Good examples of data formats in which a resource could be returned from a service are <a href="http://www.json.org/"><strong>JSON</strong></a> (JavaScript Object Notation, which nowadays is the coolest one) and <a href="http://www.w3.org/XML/"><strong>XML</strong></a> (Extensible Markup Language, used for more complex data structures). Say for instance a REST service has to expose the data related to a song, with its attributes. A way of doing it in JSON could be:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;ID&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;title&quot;</span><span class="p">:</span> <span class="s2">&quot;(You gotta) Fight for your right (To party)&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;artist&quot;</span><span class="p">:</span> <span class="s2">&quot;Beastie Boys&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;album&quot;</span><span class="p">:</span> <span class="s2">&quot;Licensed To Ill&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;year&quot;</span><span class="p">:</span> <span class="mi">1986</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;genre&quot;</span><span class="p">:</span> <span class="s2">&quot;Hip-Hop&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Easy, huh?</p>

<p>Anyway, a service can represent a resource in a number of ways at the same time, leaving the client to choose which one is better suited for its needs. The important thing is that there is agreement on what format to send/expect.</p>

<p>The format that the client needs will be part of the <strong>request</strong> sent by the client.</p>

<p>The resource will be eventually sent by the service as part of what we call a <strong>response</strong>.</p>

<p>It has to be kept in mind that a resource should be completely described by the representation, since this is the only information the client will have. It has to be exaustive, but without exposing classified or useless information about the entity at the same time.</p>

<h2>Messages A.K.A. client and service chatting</h2>

<p>Q: So, how exactly do client and service exchange requests and responses?</p>

<p>A: They send messages.</p>

<p>In fact, to be more specific, the client will send an <strong>HTTP request</strong> to the service, specifying the following details:</p>

<ul>
<li>The <strong>method</strong> that is called on the resource. It can correspond to a <em>GET</em>, a <em>POST</em>, a <em>PUT</em>, a <em>DELETE</em>, an <em>OPTIONS</em> or a <em>HEAD</em> operation.</li>
<li>The <strong>URI</strong> of the request. It identifies what is the resource on which the client wants to use the method. More on that later. For now let&rsquo;s say it is the only way the client knows how to call the needed resource.</li>
<li>The <strong>HTTP version</strong>, which is usually <a href="http://tools.ietf.org/html/rfc2616"><em>HTTP/1.1</em></a>.</li>
<li>The <strong>request headers</strong>, which are the additional information passed, with the request, to the service. These fields are basically request modifiers, similar to the parameters sent to a programming language method, and they depend on the type of request sent. More on that later.</li>
<li>The <strong>request body</strong>: is the actual content of a message. In a RESTful service, it’s where the representation of resources sit. A body will not be present in a GET request, for instance, since it is a request to retrieve a resource rather than to create one, whereas a POST request will most likely have one.</li>
</ul>


<p>The request will then generate an <strong>HTTP response</strong> to the client, that will contain the following elements:</p>

<ul>
<li>The <strong>HTTP version</strong>, same as above.</li>
<li>The <strong>response code</strong>: which is a three-digit status code sent back to the client. Can be of the <strong>1xx</strong> format (informational), <strong>2xx</strong> (success), <strong>3xx</strong> (redirect), <strong>4xx</strong> (client error), <strong>5xx</strong> (server error).</li>
<li>The <strong>response header</strong>, which contains metadata and settings related to the message.</li>
<li>The <strong>response body</strong>: contains the representation (if the request was successful).</li>
</ul>


<h2>URIs, home of the resources</h2>

<p>A requirement of REST is that each resource has to correspond to an <a href="http://en.wikipedia.org/wiki/Uniform_resource_identifier">URI</a> address, which unsurprisingly stands for Uniform Resource Identifier. Having URIs associated to resources is key, because they are the addresses on which the client is allowed to perform the operations on the resources. It is important to stress that according to REST an URI should describe a resource, but never the operation performed on it.</p>

<p>The addresses are usually constructed hierarchically, to allow readability. A typical resource URL could be written as: <code>http://serviceName/resourceName/resourceID</code></p>

<p>Basic guidelines to build well-structured URIs are:</p>

<ul>
<li>Resources should be named with plural nouns, no verbs, using conventions throughout the whole service.</li>
<li>Query URIs <code>http://serviceName/resourceName?id=resourceID</code> should be used only when really necessary. They are not deprecated by REST style, but they are less readable than the normal URIs, and are ignored by search engines. On the upside, they allow the client to send parameters to the service, to refine the request for a specific subset of resources, or resources in a specific format.</li>
</ul>


<h2>Uniform interface, various operations</h2>

<p>Ok, so now that a client knows where a resource is reachable, how is it going to handle the resource? What are the operations that it can perform?</p>

<p>HTTP provides a set of methods that allow the client to perform standard operations on the service:</p>

<table style="margin-bottom:16px;">
    <tr>
        <th style="font-weight:bold;padding:5px 10px;border-bottom:1px solid #ccc;">Method</th>
        <th style="font-weight:bold;padding:5px 10px;border-bottom:1px solid #ccc;">Operation performed</th> 
        <th style="font-weight:bold;padding:5px 10px;border-bottom:1px solid #ccc;">Quality</th>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">GET</td>
        <td style="padding:5px 10px;">Read a resource</td> 
        <td style="padding:5px 10px;">Safe</td>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">POST</td>
        <td style="padding:5px 10px;">Insert a new resource, or update an existing one</td> 
        <td style="padding:5px 10px;">Not idempotent</td>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">PUT</td>
        <td style="padding:5px 10px;">Insert a new resource, or update an existing one</td> 
        <td style="padding:5px 10px;">Idempotent (see below)</td>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">DELETE</td>
        <td style="padding:5px 10px;">Delete a resource</td> 
        <td style="padding:5px 10px;">Idempotent</td>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">OPTIONS</td>
        <td style="padding:5px 10px;">List allowed operations on a resource</td> 
        <td style="padding:5px 10px;">Safe</td>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">HEAD</td>
        <td style="padding:5px 10px;">Return only the response header, no body</td> 
        <td style="padding:5px 10px;">Safe</td>
    </tr>
</table>


<p>The key difference between <em>POST</em> and <em>PUT</em> is that no matter how many times a <em>PUT</em> operation is performed, the result will be the same (this is what <em>idempotent</em> means), whereas with a <em>POST</em> operation a resource will be added or updated multiple times.</p>

<p>Another difference is that a client that sends a <em>PUT</em> request always need to know the exact URI to operate on, I.E. assigning a name or an ID to a resource. If the client is not able to do so, it has no choice but to use a POST request.</p>

<p>Finally, if the resource already exists, <em>POST</em> and <em>PUT</em> will update it in an identical fashion.</p>

<p>These operations, according to REST, should be available to the client as hyperlinks to the above described URIs, and that is how the client/service interface is constrained to be <em>uniform</em>.</p>

<h2>Statelessness of the client side</h2>

<p>A RESTful service does not maintain the application state client-side. This only allows the client to perform requests that are resource specific, and does not allow the client to perform operations that assume prior knowledge of past requests. The client only knows what to do based on the ability to read the hypertext it receives, knowing its media type.</p>

<p>This leads me to mention an important constraint of REST, that was also <a href="http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven">enforced by Fielding</a> after publishing his dissertation: hyperlinks within hypertext are the only way for the client to make state transitions and perform operations on resources. This constraint is also known as <strong>HATEOAS</strong> (Hypermedia As The Engine Of Application State).</p>

<h2>Links between resources</h2>

<p>In the case of a resource that contains a list of resources, REST suggests to include links to the single resources on the representation, to keep it compact and avoid redundant data.</p>

<h2>Caching to optimize time and efficiency</h2>

<p>Allows to store responses and return them if the same request is performed again. It has to be handled carefully to avoid returning stale results. The headers that allow us to perform controls over caching are:</p>

<table style="margin-bottom:16px;">
    <tr>
        <th style="font-weight:bold;padding:5px 10px;border-bottom:1px solid #ccc;">Header</th>
        <th style="font-weight:bold;padding:5px 10px;border-bottom:1px solid #ccc;">Application</th>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">Date</td>
        <td style="padding:5px 10px;">Finding out when this representation was generated</td>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">Last Modified</td>
        <td style="padding:5px 10px;">Date and time when the server modified the representation</td>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">Cache-Control</td>
        <td style="padding:5px 10px;">HTTP 1.1 header used to control caching, can contain directives</td>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">Expires</td>
        <td style="padding:5px 10px;">Expiration date (supports HTTP 1.0)</td>
    </tr>
    <tr>
        <td style="padding:5px 10px;font-weight:bold;">Age</td>
        <td style="padding:5px 10px;">Duration since the resource was fetched from server</td>
    </tr>
</table>


<p>Cache-Control values can be tweaked to control if a cached result is still valid or stale. For example, the <em>max-age</em> value indicates for how many seconds from the moment expressed by the Date header a cached result will be valid.</p>

<h2>Conclusion</h2>

<p>REST is a language-agnostic style that abstracts over components and allows to build scalable, reusable and relatively lightweight web services. Thinking about it, it seems that REST is very close to an accurate description of the characteristics that made the World Wide Web so popular.</p>

<p>That of course is encouraging developers from all over the world to comply to these very basic ideas, owned by no one but at the same time used by everyone. Fascinating!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Strongly Typed Logging]]></title>
    <link href="http://tech.opentable.co.uk/blog/2015/01/23/on-strongly-typed-logging/"/>
    <updated>2015-01-23T13:13:13+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2015/01/23/on-strongly-typed-logging</id>
    <content type="html"><![CDATA[<p>Logging is a crucial element of monitoring highly available systems. It allows not only to find out about errors but also quickly identify their cause. Logs are often used to generate metrics that help business and engineering make informative decisions on future development directions.</p>

<p>At OpenTable we have a central logging infrastructure, that means all logs are stored in the same shared database (ElasticSearch for us). And everybody can access any logs they want without having very specialized knowledge (thanks Kibana!).</p>

<p>ElasticSearch, though living in a NoSQL world, is not actually a schema-free database. Sure, you do not need to provide schema to it but instead ES will infer schema for you from documents you send to it. This is very similar to type inference you can find in many programming languages. You do not need to specify type of field, but if you later on try to assign inappropriate value to it you will get an exception.</p>

<p>This trait of our database goes all the way to the root of our logging system design. Let me explain why I say that we have &lsquo;strongly typed logs&rsquo;.</p>

<h2>In The Beginning There Was String</h2>

<p>Before centralization we just logged a single message along with its importance. In code it looked something like:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>logger.ERROR(“Kaboom!”)</span></code></pre></td></tr></table></div></figure>


<p>which resulted in logline on disk having timestamp, severity and message.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{2014-10-10T07:33:04Z [ERROR] Kaboom!}</span></code></pre></td></tr></table></div></figure>


<p>That worked pretty well. As time passed we often started making log messages more generic to hold relevant data:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>logger.INFO(string.Format(“Received {0} from {1}. Status: {2}. Took {3}”, httpMethod, sourceIp, statusCode, durationms));</span></code></pre></td></tr></table></div></figure>


<p>When we decided to centralize logs we moved the same logs from local disk to a central database. Suddenly things that used to live on single server in a file called &lsquo;application.log&rsquo; become part of one huge lump of data. Instead of easing access to logs they were really hard to filter, without even speaking about aggregation, or any simple form of operations to find the source of the problem. ElasticSearch is really good at free text searching, but frankly speaking FTS is never as precise as a good filter.</p>

<h2>Then There Was Dictionary Of Strings</h2>

<p>Wherever there is problem there is also a solution. So we changed the way our logging works. We created a custom logger and started sending logs more like documents than single string.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>customLogger.send(‘info’, new Dictionary&lt;string, string&gt; {
</span><span class='line'>{‘method’, httpMethod.ToString()},
</span><span class='line'>{‘sourceIp’, sourceIp.ToString()},
</span><span class='line'>{‘statusCode’, statusCode.ToString()},
</span><span class='line'>{‘duration’, durationms.ToString()},
</span><span class='line'>{‘requestId’, requestId.ToString()},
</span><span class='line'>{‘service’, ‘myservice’}
</span><span class='line'>{‘message’, string.Format(“Received {0} from {1}. Status: {2}. Took {3}”, httpMethod, sourceIp, statusCode, durationms)}
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong>That helped a lot.</strong></p>

<p>You might wonder why we serialized everything to string? The answer is ElasticSearch mapping as I described above. Mapping, once it is inferred, cannot be changed. So from time to time we used to have conflicts (e.g. one application logging requestId as number, other as guid). Those conflicts were costly &ndash; logs were lost &ndash; so we simply applied the simplest solution available and serialized everything.</p>

<p>Now filtering was working fine. We were even able to group requests based on a single field and count them. You cannot imagine how useful it is to simply count the different status codes returned by a service. Also you may have noticed we introduced some extra fields like &lsquo;service&rsquo; which helped us group logs coming from a single application. We did the same with hostname etc.</p>

<p>With this easy success our appetite has grown and we wanted to log more. And being lazy programmers we found a way to do it quickly so our logs often included just relevant objects.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>customLogger.log(‘info’, request)
</span><span class='line'>customLogger.log(‘error’, exception)</span></code></pre></td></tr></table></div></figure>


<p>Our custom logging library did all the serialization for us. This worked really well. Now we were actually logging whole things that mattered without having to worry about serialization at all. What&rsquo;s even better, whenever the object in question changed (e.g. a new field was added to request), it was automagically logged.</p>

<p>However one thing was still missing. We really wanted to see performance of our application in real time or do range queries (e.g. &ldquo;show me all requests that have 5xx status code&rdquo;). We also were aware that both ES and Kibana can deliver it but our logging is not yet good enough.</p>

<h2>Strongly Typed Logs</h2>

<p>So we looked at our logging and infrastructure and at what needs to be done to allow different types of fields to live in ElasticSearch. And you can imagine that it was a pretty simple fix; we just started using types. Each log format was assigned its own type. This type was then used by ElasticSearch to put different logs into separate buckets with separate mapping. The type is equivalent in meaning to classes in OO programming. If we take this comparison further then each log entry would be an object in OO programming. ElasticSearch supports searches across multiple types, which is very convenient when you don&rsquo;t know what you are looking for. On the other hand, when you know, you can limit your query to single type and take advantage of fields types.</p>

<p>It was a big application change as we needed to completely change our transport mechanism to LogStash. We started with Gelf and switched to Redis, which allowed us to better control format of our logs.</p>

<p>We also agreed on a first standard. The standard defined that type will consist of three parts:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;serviceName&gt;-&lt;logName&gt;-&lt;version&gt;</span></code></pre></td></tr></table></div></figure>


<p>This ensures that each team can use any logs they want to (thus serviceName). Each log will have its own format (thus logName). But they can also change in the future (thus version). One little word of caution, ES doesn&rsquo;t like dots in type name, so don&rsquo;t use them.</p>

<p>So our logs look now like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>customLogger.log(new RequestLog {
</span><span class='line'>Request = request,
</span><span class='line'>Headers = headers,
</span><span class='line'>Status = status})</span></code></pre></td></tr></table></div></figure>


<p>RequestLog is responsible for providing valid type to the logging library.</p>

<p>With sending serialized objects as logs and assigning each class unique type our logs have become strongly typed.</p>

<p>We are already couple steps further down the path of improving our logs. We standardized some common fields and logtypes. That, however, is a completely different tale. ​</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building a living styleguide at OpenTable]]></title>
    <link href="http://tech.opentable.co.uk/blog/2015/01/19/building-a-living-styleguide-at-opentable/"/>
    <updated>2015-01-19T17:00:00+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2015/01/19/building-a-living-styleguide-at-opentable</id>
    <content type="html"><![CDATA[<p>If you&rsquo;re reading this you&rsquo;ve probably built yourself a website.  A site &ndash; large or small &ndash; that&rsquo;s thrown together or crafted over many months.  And if you have, you’ve probably kept all your CSS class names in your head, or at least been able to go straight to the relevant stylesheets to retrieve them.</p>

<p>Well OpenTable is unsurprisingly built by many engineering teams across multiple continents, and was completely redesigned last year.  And as soon as you have more than a handful of people working on your front-end you will quickly find a well-intentioned developer causing one or both of these problems:</p>

<ul>
<li>Well-intentioned developer adds a new submission form but, like the design Philistine he is, his buttons are <span style="font-family:verdana;font-size:18px;color:#E40000;">18px Verdana #E40000</span>, not the correct <span style="font-family:arial;font-size:16px;color:#DA3743;">16px Arial #DA3743</span></li>
<li>Your good old developer knows which font size and colour it should be, but bungs a duplicate class into a random stylesheet (or worse still, inline)</li>
</ul>


<p>Despite these risks, a single front-end dev (or a team of them) cannot check every new piece of code or they will quickly become a bottleneck.</p>

<h3>You need some guidelines</h3>

<p>Offline designers regularly create ‘brand guidelines’ or ‘design standards&#8217; to document the precise way their brand or product should be recreated when outside of their control.  Online, such guidelines are similarly invaluable for maintaining brand and code consistency with multiple engineers and designers, but it is blindingly obvious that a printed or ‘static’ set of guidelines is completely unsuitable for a constantly changing website.</p>

<p>Step forward a ‘living’ styleguide.</p>

<p>A living styleguide gives a visual representation of a site’s UI elements using <strong>the exact same code</strong> as on the website, in most cases via the live CSS.  A living styleguide may also provide reusable CSS and HTML code examples and they are not just for engineers new to the code; I frequently use ours at OpenTable and I wrote the stylesheets in the first place (I can’t be expected to remember everything).</p>

<p>Providing reusable code improves collaboration, consistency and standards, and reduces design and development time &ndash; but like most documentation it is essential your guide is always up-to-date and trustworthy.  So if a living styleguide is (theoretically) always up-to-date, how did we build ours?</p>

<h2>How we built our styleguide</h2>

<p>Living styleguides are not new (although they were <a href="http://sideproject.io/an-exhaustive-look-at-the-year-in-web-design/#styleguides">one of the trends of 2014</a>) and as such many frameworks have been built over the years.  We chose to use <a href="http://kaleistyleguide.com/">Kalei</a> by <a href="https://github.com/thomasdavis">Thomas Davis</a> &ndash; I forget the exact reasons why but it was probably the easiest at the time to set up and customise.</p>

<p>Generating a Kalei styleguide is as simple as adding comments to your stylesheet; Kalei uses a variety of frameworks, including <a href="http://backbonejs.org/">Backbone.js</a>, <a href="http://www.glazman.org/JSCSSP/">JSCSSP</a> and <a href="https://github.com/chjj/marked">Marked</a> to convert these comments into HTML mark-up, generate a list of your individual stylesheets as navigation and present these as a single page web app.</p>

<p>For example in your <code>buttons.css</code> file it is as simple as adding the following comments:</p>

<pre><code>/*!
# Primary buttons
Primary buttons are only used when there is an exceedingly distinct and clear call-to-action.
```
&lt;a href="#" class="button"&gt;Button&lt;/a&gt;
&lt;a href="#" class="button secondary"&gt;Button secondary&lt;/a&gt;
&lt;a href="#" class="button success"&gt;Button success&lt;/a&gt;
&lt;a href="#" class="button alert"&gt;Button alert&lt;/a&gt;
```
*/
</code></pre>

<p>Which, by using the CSS in the file itself, Kalei would visually render like so:</p>

<p><img src="http://tech.opentable.co.uk/images/posts/styleguide-buttons-screenshot.png" alt="styleguide-buttons-screenshot" /></p>

<h3>Customising Kalei</h3>

<p>Kalei works well out-of-the-box but we had to make a few customisations.  These were mostly cosmetic changes, but a fundamental changes was to <strong>add support for Sass</strong>.  For this we wrote a Grunt task imaginatively called <code>grunt styleguide</code> in which we combined <em>Clean</em>, <em>Copy</em>, <em>Scss</em> and <em>Replace</em> tasks.  Unsatisfactorily it took a little while to set up and involved a number of steps, but below is simplification of the process.</p>

<ol>
<li>Clean all CSS files from the styleguide, excluding Kalei specific stylesheets</li>
<li>Copy our partial scss files into a temporary folder and rename them to remove the underscore (partial scss files begin with an underscore are are <a href="http://sass-lang.com/documentation/file.SASS_REFERENCE.html#partials">not compiled by default</a>)</li>
<li>Compile the scss files into CSS in the styleguide directory</li>
<li>Copy across dependent fonts and images, using <em>Replace</em> to update the relative paths</li>
<li>Delete the temporary directory</li>
</ol>


<p>This task is run as a deployment step and can be run locally when developing the guide.</p>

<p>Other that a few small UI tweaks we made one significant changes to the look and feel.  By default the navigation lists stylesheets using their full file name, e.g. <strong>breadcrumbs.css</strong> and <strong>buttons.css</strong>.  Using a regex function in the <code>menu.js</code> file and <code>text-transform: capitalize</code> in the Kalei stylesheet we modify the navigation to display the more attractive headings <strong>Breadcrumbs</strong> and <strong>Buttons</strong>.</p>

<p>View our styleguide at <a href="http://www.opentable.com/styleguide" target="_blank">opentable.com/styleguide</a>.</p>

<h2>What&rsquo;s next?</h2>

<p>Our living styleguide is intended to be an organic resource that we will grow and refine into an integral part of our software development.  We have many ideas for how we want to develop the guide &ndash; at the very least it is currently incomplete insomuch as we have not documented every one of our stylesheets.</p>

<p>There is also a fundamental weakness to this type of styleguide, which is duplication of code.  Whilst we use the exact same CSS as our live site, we are copying and pasting mark-up into these files and this content can go out of date without deliberate upkeep.  At OpenTable we have a <em>site resource service</em> which serves HTML snippets to different internal microsites so one option could be to use this service to integrate these snippets into the styleguide.  We may also investigate a solution using <a href="http://webcomponents.org/">web components</a> as cross-browser support is not a concern.</p>

<p>We are also interested to see whether it would be useful to run UI tests against the styleguide. We have used <a href="http://pdiff.sourceforge.net/">pDiff</a> in the past for visual regression on specific microsites, but the styleguide could be an opportunity to catch accidental, global UI changes.  We are going to look at running <a href="https://garris.github.io/BackstopJS/">BackstopJS</a> against each section of the guide to see if this increases its usefulness.</p>

<p>Finally, as one of the developers who created the styleguide I want it to be widely adopted across OpenTable. I want designers and engineers to contribute to the code and use it for their day-to-day designing and developing, and I want product owners and marketing folks to use it when creating promotional material and A/B tests.  My ultimate goal is for it to be an integral tool enabling everyone to work faster, avoid duplication and maintain a consistent brand identity.</p>

<h2>Read more</h2>

<ul>
<li>View an online directory <a href="http://styleguides.io/">of styleguide articles and examples</a></li>
</ul>


<!-- - Join us - [apply for our senior front-end engineer role at OpenTable, London.](https://hire.jobvite.com/Jobvite/Job.aspx?b=nlsWXpwA&j=oXeiYfwb) -->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Explaining Flux architecture with macgyver.js]]></title>
    <link href="http://tech.opentable.co.uk/blog/2015/01/01/explaining-flux-architecture-with-macgyver-dot-js/"/>
    <updated>2015-01-01T15:33:46+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2015/01/01/explaining-flux-architecture-with-macgyver-dot-js</id>
    <content type="html"><![CDATA[<h2>What is Flux?</h2>

<p><a href="https://github.com/facebook/flux">Flux</a> is an application architectural pattern developed by Facebook. It was developed to solve some of the complexities of the MVC pattern when used at scale by favouring a uni-directional approach. It is a pattern and not a technology or framework.</p>

<p><img src="http://tech.opentable.co.uk/images/posts/mvc-scale.png" alt="MVC scale issue" /></p>

<p>When applications that use the model-view-controller (MVC) pattern at any scale it becomes difficult to maintain consistent data across multiple views. In particular the case whereby flow between models and views is not uni-directional and may require increasing logic to maintain parity between views when model data is updated. Facebook hit this issue several times and in particular with their unseen count (an incremented value of unseen messages which is updated by several UI chat components). It wasn&rsquo;t until they realised that the MVC pattern accomodated the complexity that they stepped back from the problem and addressed the architecture.</p>

<p>Flux is intentionally unidirectional.</p>

<p><img src="http://tech.opentable.co.uk/images/posts/flux.png" alt="flux" /></p>

<p>Key to this architecture is the dispatcher. The dispatcher forms the gatekeeper that all actions must go through. When a view, or views, wish to do something they fire an action which the dispatcher correctly routes via registered callbacks made by the stores.</p>

<p>Stores are responsible for the data and respond to callbacks from the dispatcher. When data is changed they emit change events that views listen to to notify them that data has changed. The view can then respond accordingly (for example to update/rebind).</p>

<p>This will become more obvious when we go through the macgyver.js example.</p>

<h2>What is macgyver.js?</h2>

<p><a href="https://github.com/stevejhiggs/macgyver">Macgyver</a> is a project fork of <a href="http://mullet.io/">mullet.io</a> by <a href="https://github.com/stevejhiggs">Steve Higgs</a>. Mullet is an aggregate stack to get started using Node.js with Facebook&rsquo;s <a href="http://facebook.github.io/react/">React</a> framework on the client and Walmart&rsquo;s <a href="http://walmartlabs.github.io/hapi/">hapi.js</a> on the server.</p>

<p>Steve initially swapped out Grunt for Gulp, updated hapi and React and fixed some issues with the React dev tools. I then added another example to incorporate the Flux architecture, which you can see <a href="https://github.com/stevejhiggs/macgyver/tree/master/reactPlusFlux">here</a>. As React was also developed by Facebook you can begin to see how flux compliments its design and component based model.</p>

<h2>The macgyver.js Flux example</h2>

<p>The demo is a very simple quiz. In true Macgyver style he is faced with abnormally unrealistic situations armed with impossibly useless &ldquo;every-day&rdquo; items to escape the situation. If you select the correct tool, you proceed to the next situation.</p>

<p><img class="left" src="http://tech.opentable.co.uk/images/posts/structure.png" width="200"></p>

<p>Let&rsquo;s start by going through the uni-directional flow above and at the same time look at the code and its structure.</p>

<p>When the game is first loaded the view fires an action to get the next situation. This is then fired off to the dispatcher, as are all actions.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">receiveSituations</span><span class="o">:</span> <span class="kd">function</span><span class="p">(</span><span class="nx">data</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">AppDispatcher</span><span class="p">.</span><span class="nx">handleViewAction</span><span class="p">({</span>
</span><span class='line'>          <span class="nx">actionType</span><span class="o">:</span> <span class="nx">MacgyverConstants</span><span class="p">.</span><span class="nx">RECEIVE_SITUATIONS_DATA</span><span class="p">,</span>
</span><span class='line'>          <span class="nx">data</span><span class="o">:</span> <span class="nx">data</span>
</span><span class='line'>      <span class="p">});</span>
</span><span class='line'><span class="p">},</span>
</span></code></pre></td></tr></table></div></figure>


<p>The store registers to listen for events from the dispatcher with a registered callback. It has the job of loading the situation data and emitting an event when this data is changed. In this case the SituationStore.js has the job of setting the current situation for the view to render.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">AppDispatcher</span><span class="p">.</span><span class="nx">register</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">payload</span><span class="p">){</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">action</span> <span class="o">=</span> <span class="nx">payload</span><span class="p">.</span><span class="nx">action</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">switch</span><span class="p">(</span><span class="nx">action</span><span class="p">.</span><span class="nx">actionType</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="k">case</span> <span class="nx">MacgyverConstants</span><span class="p">.</span><span class="nx">RECEIVE_SITUATIONS_DATA</span><span class="o">:</span>
</span><span class='line'>          <span class="nx">loadSituationsData</span><span class="p">(</span><span class="nx">action</span><span class="p">.</span><span class="nx">data</span><span class="p">);</span>
</span><span class='line'>          <span class="k">break</span><span class="p">;</span>
</span><span class='line'>      <span class="k">case</span> <span class="nx">MacgyverConstants</span><span class="p">.</span><span class="nx">CHECK_ANSWER</span><span class="o">:</span>
</span><span class='line'>          <span class="nx">checkAnswer</span><span class="p">(</span><span class="nx">action</span><span class="p">.</span><span class="nx">data</span><span class="p">);</span>
</span><span class='line'>          <span class="k">break</span><span class="p">;</span>
</span><span class='line'>      <span class="k">default</span><span class="o">:</span>
</span><span class='line'>          <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">SituationStore</span><span class="p">.</span><span class="nx">emitChange</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>The React view (in this case Game.jsx) registers an event listener for these changes in the SituationStore using the React &ldquo;componentDidMount&rdquo; function. When the situation is received by the component it rebinds to the data by loading the sitution and the possible answers.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">var</span> <span class="nx">Game</span> <span class="o">=</span> <span class="nx">React</span><span class="p">.</span><span class="nx">createClass</span><span class="p">({</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">componentDidMount</span><span class="o">:</span> <span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">SituationStore</span><span class="p">.</span><span class="nx">addChangeListener</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">_onChange</span><span class="p">);</span>
</span><span class='line'>      <span class="nx">ToolStore</span><span class="p">.</span><span class="nx">addChangeListener</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">_onChange</span><span class="p">);</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="nx">componentWillUnmount</span><span class="o">:</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">SituationStore</span><span class="p">.</span><span class="nx">removeChangeListener</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">_onChange</span><span class="p">);</span>
</span><span class='line'>      <span class="nx">ToolStore</span><span class="p">.</span><span class="nx">removeChangeListener</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">_onChange</span><span class="p">);</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="nx">render</span><span class="o">:</span> <span class="p">...</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>When the user selects an answer this fires off another &ldquo;CHECK_ANSWER&rdquo; event to the dispatcher. The situation store recieves this event with the answer in the payload and checks whether the answer selected is the correct one. If it is it updates the situation and emits a changes event to which the view receives and rebinds the view to the new situation.</p>

<h2>Conclusion</h2>

<p>Flux can be quite difficult to fathom eventhough it is quite a simple architectural pattern. In this small example it does initially feel overly complex and indeed it probably is. The pattern was designed to solve issues that occur at large scale in MVC applications due to the increased amound of bi-directional dependencies between views and models. For smaller applications it could be seen as over-engineered, however I really like the simplicity in the uni-directional flow and the assurance that unit tests are almost always going to mimic the state changes possible in your application because of the guarantee of a simple flow of data.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Supporting IE8 in the OpenTable redesign]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/12/08/supporting-ie8-in-the-opentable-redesign/"/>
    <updated>2014-12-08T21:14:57+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/12/08/supporting-ie8-in-the-opentable-redesign</id>
    <content type="html"><![CDATA[<p>We&rsquo;re really <a href="http://blog.opentable.com/2014/opentables-website-re-designed-re-architected-re-imagined/">proud to have released</a> last week our redesigned <a href="http://www.opentable.co.uk">OpenTable</a> site, the culmination of months of hard work from many talented people here in London and in San Francisco.</p>

<p>However despite killing off our old site and its 2004 design, 2.8% of our visitors could have been crying into their keyboard as a far worse opentable.co.uk filled their screen.</p>

<p>That version of OpenTable was our new responsive site viewed in Internet Explorer 8.</p>

<p><img src="http://tech.opentable.co.uk/images/posts/redesign-ie8.png" alt="Our redesign before we optimised for IE8" /></p>

<p>The fundamental issue is that IE8 doesn&rsquo;t support media queries so the age-old browser would try to stretch our <em>mobile-first</em> responsive design as wide as it could go &ndash; not great across a 27&#8221; Thunderbolt.</p>

<p>To solve the problem we first tried the <a href="https://github.com/scottjehl/Respond">Respond.js</a> polyfill but this didn&rsquo;t work as we&rsquo;d hoped.  The main issue appeared to be that because we serve our CSS and JS on a separate sub-domain we fell foul of the browser&rsquo;s cross-domain security.  We followed the Respond.js instructions to solve this but having no luck we looked for alternatives.</p>

<h2>Legacssy</h2>

<p>Further Googling lead us to <a href="https://github.com/robinpokorny/grunt-legacssy">Legacssy</a>. With this Grunt task we could create a IE8-only stylesheet and not have to serve extra JS and cross-domain proxy files to all visitors.</p>

<p>Our existing process is to create our core CSS with an <code>app.scss</code> file and <a href="https://github.com/sindresorhus/grunt-sass">grunt-sass</a>.  Our additional step was to create an <code>app_ie8.scss</code> file, parse it with <code>grunt-sass</code> like before, but then also run it through Legacssy.</p>

<h3>Our app.scss file</h3>

<pre><code>@import 'normalize';

@import 'components/global';

@import
  'components/icons',
  'components/buttons',
  'components/calendar',
  'components/forms',
  'components/pagination',
  'components/star-rating';

@import
  'partials/footer',
  'partials/header',
  'partials/location-picker';
</code></pre>

<h3>And our app_ie8.scss file</h3>

<pre><code>@import ‘app';
@import 'browsers/_ie8.scss';
</code></pre>

<p>This process left us with a duplicate of the main site CSS that would be IE8 friendly &ndash; and as you can see we are also able to merge in an IE8 specific stylesheet with further overrides.  All we now needed to was serve this inside conditional comments after the main stylesheet, and CSS specificity would ensure our IE rules overwrite the media queries.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;!--[if lte IE 8]&gt;
</span><span class='line'>&lt;link rel="stylesheet" href="//eu-srs.opentable.com/content/static/css/app_ie8.css" /&gt;
</span><span class='line'>&lt;![endif]—&gt;</span></code></pre></td></tr></table></div></figure>


<h2>Drawbacks</h2>

<p>We are very happy with this solution as it generates the IE8 fixes as part of our automated build with no extra effort.  The only obvious negative is for the IE8 visitors who will effectively be downloading the same stylesheet twice, but if they are routinely browsing the web with IE8 this could be the least of their worries.</p>

<h2>Conclusion</h2>

<p>We&rsquo;re really proud of our new site; we&rsquo;re still ironing out some kinks but we hope that it&rsquo;s good enough for those of you who visit us with Internet Explorer 8 (probably through no fault of your own).</p>

<p>For the record, here a couple of other issues we found which may help other intrepid developers with their IE debugging in 2015 and beyond.</p>

<h3>Other IE8 issues</h3>

<ul>
<li>The other unsupported CSS values were rem units and RGBA colours.  After running Legacssy we used <a href="https://github.com/robwierzbowski/grunt-pixrem">pixrem.js</a> to replace rems with pixels and a custom task to replace RGBA values with their HEX equivalents.</li>
<li>IE11&rsquo;s F12 developer tools don&rsquo;t render identically to native IE8. We used Microsoft&rsquo;s excellent <a href="http://www.modern.ie">modern.ie</a> site to download virtual machines with Windows 7 and IE8.</li>
<li>We only tested on Windows 7 as this makes up 66% of our IE8 visitors. The remainder are on different operating systems which collectively only make up 0.95% of our total visitors; this is below our threshold for support.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Proxying Services With Hapi.js]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/11/28/proxying-with-hapi/"/>
    <updated>2014-11-28T10:32:42+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/11/28/proxying-with-hapi</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve raved in the past about how awesome <a href="http://hapijs.com">hapi.js</a> is, but I&rsquo;m going to talk about just a specific case today.</p>

<p>We started off with just a couple of hapi.js apis. This was at a time when standing up new infrastructure was still a bit painful, so inevitably those apis ended up having more functionality in them than they should have. Now it&rsquo;s easy for us to get infrastructure, so we want to do more of it.</p>

<p>Our goal is to have lots of small(er) apis that just look after one specific piece (skillfully avoiding using the buzzword &lsquo;microservices&rsquo;).</p>

<p>When you want to split out functionality from one api to another, it can be a pain, especially if you have a lot of consumers who aren&rsquo;t particularly fast-moving or communicative. Or maybe you don&rsquo;t know all your consumers up front.</p>

<p>You&rsquo;ve got a couple of options here:</p>

<ul>
<li><p>Maintain the functionality in two places and slowly migrate consumers across</p></li>
<li><p>Use a proxy or routing layer in-front of the api to rewrite or redirect requests</p></li>
<li><p>Write code in your api to proxy requests to a different server</p></li>
</ul>


<p>The first two options are pretty icky, and frankly the third isn&rsquo;t all that great either. It all depends on you having the right framework. Do you see where I&rsquo;m going here?</p>

<h3>Enter Hapi.js</h3>

<p>Hapi.js has the concept of a &lsquo;proxy&rsquo; handler, which can transparently proxy requests to a different server.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">server</span><span class="p">.</span><span class="nx">route</span><span class="p">([</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nx">method</span><span class="o">:</span> <span class="s1">&#39;GET&#39;</span><span class="p">,</span>
</span><span class='line'>    <span class="nx">path</span><span class="o">:</span> <span class="s1">&#39;/foo&#39;</span><span class="p">,</span>
</span><span class='line'>    <span class="nx">handler</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">proxy</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>        <span class="nx">host</span><span class="o">:</span> <span class="s1">&#39;my-other-service.mydomain.com&#39;</span><span class="p">,</span>
</span><span class='line'>        <span class="nx">port</span><span class="o">:</span> <span class="mi">80</span><span class="p">,</span>
</span><span class='line'>        <span class="nx">protocol</span><span class="o">:</span> <span class="s1">&#39;http&#39;</span><span class="p">,</span>
</span><span class='line'>        <span class="nx">passThrough</span><span class="o">:</span> <span class="kc">true</span><span class="p">,</span>
</span><span class='line'>        <span class="nx">xforward</span><span class="o">:</span> <span class="kc">true</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">]);</span>
</span></code></pre></td></tr></table></div></figure>


<p>And boom, you&rsquo;re done. You can now safely delete <em>all</em> of that code from your api and move it. The <em>only</em> thing you need to have kicking about is that proxy handler code.</p>

<p>The <code>passthrough</code> setting specifies whether or not to preserve headers on the original request, and <code>xforward</code> tells hapi to add (or append) an &lsquo;x-forwarded-for&rsquo; header to the request.</p>

<p>The proxy handler is really powerful. It can rewrite the request (using <code>mapUri</code>), pass local-state (from the hapi instance) along, reject unauthorised requests, you can even hook into the response and monkey about with it if you want (using <code>onResponse</code>).</p>

<p>For full details, see the <a href="http://hapijs.com/api/v7.5.2#route-options">proxy section</a> of the route options.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hobknob v2.0: A new dimension]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/11/26/hobknob-v2-dot-0-a-new-dimension/"/>
    <updated>2014-11-26T10:11:37+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/11/26/hobknob-v2-dot-0-a-new-dimension</id>
    <content type="html"><![CDATA[<p>Sometimes there is the requirement for more granularity when toggling a feature switch.
Version 2.0 of <a href="https://github.com/opentable/hobknob">Hobknob</a> hopes to address this with feature categories.</p>

<h3>TL;DR.</h3>

<p>Hobknob now allows you to define categories of features that have multiple toggles per feature.</p>

<p>For example, you can define the &lsquo;Domain Features&rsquo; category which allows you to toggle a feature OFF in <code>your-website.com</code>, but ON in <code>your-website.co.uk</code>.</p>

<p><img src="http://tech.opentable.co.uk/images/posts/hobknob-domain-features.png" alt="Domain Features" /></p>

<h2>Categories</h2>

<p>Feature categories are configured with a few pieces of information. For example:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;categories&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Simple Features&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Use when you want your feature to be either on or off&quot;</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Domain Features&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Use when you want your features to be toggled separately for different domains&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;values&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;com&quot;</span><span class="p">,</span> <span class="s2">&quot;couk&quot;</span><span class="p">,</span> <span class="s2">&quot;de&quot;</span><span class="p">,</span> <span class="s2">&quot;commx&quot;</span><span class="p">,</span> <span class="s2">&quot;jp&quot;</span><span class="p">,</span> <span class="s2">&quot;ca&quot;</span><span class="p">]</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;id&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Locale Features&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Use when you want your features to be toggled separately for different locales&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;values&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;en-GB&quot;</span><span class="p">,</span> <span class="s2">&quot;en-US&quot;</span><span class="p">,</span> <span class="s2">&quot;fr-CA&quot;</span><span class="p">,</span> <span class="s2">&quot;de-DE&quot;</span><span class="p">,</span> <span class="s2">&quot;ja-JP&quot;</span><span class="p">,</span> <span class="s2">&quot;es-MX&quot;</span><span class="p">]</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Notice that each category (except the simple feature category) provides an array of accepted toggle values.</p>

<p>All non-simple feature toggles will have the key <code>application-name/feature-name/toggle-name</code>.
For example, <code>main-website/show-user-section/com</code>.</p>

<p>Simple features will continue to have the key <code>application-name/feature-name</code>.</p>

<h2>Setting Toggles</h2>

<p>Both simple and non-simple features are added via the application view (which is accessed via the left-hand navigation menu). Simple features are automatically set to false, this value can be changed in the feature view (by clicking the feature name).</p>

<p>A newly added non-simple feature will be initialised with no toggles values. You can add a toggle by clicking the Add Toggle button in the feature view, and choosing which toggle to add.</p>

<p><img src="http://tech.opentable.co.uk/images/posts/hobknob-adding-toggle.png" alt="Adding a toggle" /></p>

<p>New toggles are initially set to OFF. The toggle can be switched in the usual way by clicking the toggle button. You should also see an audit of the change in the panel below.</p>

<h2>Getting Toggles</h2>

<p>All of the Hobknob <a href="https://github.com/opentable/hobknob#hobknob-clients">clients</a> now support getting non-simple features toggles. The only requirement is to pass the name of the toggle, so for example in node:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">var</span> <span class="nx">nonSimpleFeatureInCom</span> <span class="o">=</span> <span class="nx">hobknobClient</span><span class="p">.</span><span class="nx">getOrDefault</span><span class="p">(</span><span class="s1">&#39;feature-name&#39;</span><span class="p">,</span> <span class="s1">&#39;com&#39;</span><span class="p">,</span> <span class="kc">false</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>It is highly reccommended that you use the get or default methods when accessing non-simple features. Getting a toggle that does not exist for a non-simple feature could be a likely scenario, since you might want to only set a feature for a few toggles explicitly (e.g. com and couk) and then use the default value for the rest (e.g. jp and de).</p>

<p>The behaviour for simple features has not changed, and is backwards compatible in all client libraries.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">var</span> <span class="nx">simpleFeature</span> <span class="o">=</span> <span class="nx">hobknobClient</span><span class="p">.</span><span class="nx">getOrDefault</span><span class="p">(</span><span class="s1">&#39;simple-feature&#39;</span><span class="p">,</span> <span class="kc">true</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interacting with ElasticSearch using Hubot]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/11/08/interacting-with-elasticsearch-using-hubot/"/>
    <updated>2014-11-08T10:32:42+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/11/08/interacting-with-elasticsearch-using-hubot</id>
    <content type="html"><![CDATA[<p>At OpenTable, we use a few <a href="">ElasticSearch</a> clusters. Our aim was to be able to interact with our ElasticSearch clusters via <a href="http://www.hipchat.com">HipChat</a> so that we could troubleshoot easily and without having to log into our VPN. We already use <a href="http://hubot.github.com">Hubot</a> as part of our systems workflow, so it made sense to be able to interact with ElasticSearch with it.</p>

<h3>Setting a cluster alias</h3>

<p>When a pager wakes me at 3am, I really do not want to have to try and type the cluster URL into my mobile hipchat client. So the first thing that was added to the script was the ability to give a cluster an alias.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>elasticsearch add alias my-test-alias http://my-cluster.com:9200</span></code></pre></td></tr></table></div></figure>


<p><img src="http://tech.opentable.co.uk/images/posts/elasticsearch-add-alias.png" alt="add-alias" /></p>

<p>This allows us to use that alias for all commands going forward. Please note that you can remove and query aliases as well:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>elasticsearch show aliases</span></code></pre></td></tr></table></div></figure>


<p><img src="http://tech.opentable.co.uk/images/posts/elasticsearch-show-aliases.png" alt="show-alias" /></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>elasticsearch clear alias my-test-alias</span></code></pre></td></tr></table></div></figure>


<p><img src="http://tech.opentable.co.uk/images/posts/elasticsearch-clear-alias.png" alt="clear-alias" /></p>

<h3>Using the ElasticSearch Cat API</h3>

<p>A lot of what we do with ElasticSearch can be done via the <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/cat.html">cat</a> API. This has proved extremely useful to get node status, cluster health and index status.</p>

<h4>Cat Health</h4>

<p>As documented <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/cat-health.html#cat-health">here</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>elasticsearch cluster health my-test-alias</span></code></pre></td></tr></table></div></figure>


<h4>Cat Nodes</h4>

<p>As documented <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/cat-nodes.html">here</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>elasticsearch cat nodes my-test-alias</span></code></pre></td></tr></table></div></figure>


<p></p>

<h4>Cat Indices</h4>

<p>As documented <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/cat-indices.html">here</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>elasticsearch cat indexes my-test-alias</span></code></pre></td></tr></table></div></figure>


<h4>Cat Allocation</h4>

<p>As documented <a href="">here</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>elasticsearch cat allocation my-test-alias</span></code></pre></td></tr></table></div></figure>


<h3>Getting the Cluster Settings</h3>

<p>Sometimes when we are rebalancing shards or recycling nodes, we want to be able to control the cluster settings. By using the cluster settings API, can have some insight into the settings currently set on the cluster:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>elasticsearch cluster settings my-test-alias</span></code></pre></td></tr></table></div></figure>


<p>More information about the cluster settings API can be found <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/cluster-update-settings.html#cluster-settings">here</a></p>

<h3>Getting the Settings for an Index</h3>

<p>Should we want to start to understand the actual settings that are attributed to an index, we can use the Cat Indices settings API. More information can be found <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/indices-get-settings.html">here</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>elasticsearch index settings my-test-alias my-index-name-2014-11-07</span></code></pre></td></tr></table></div></figure>


<h3>Clearing the cluster Cache</h3>

<p>The last piece of the puzzle we are able to do, is to clear the cache of the ElasticSearch cluster. This can be done as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hubot elasticsearch clear cache my-test-alias</span></code></pre></td></tr></table></div></figure>


<h3>Where can I find the code?</h3>

<p>The code is available on <a href="https://github.com/stack72/hubot-elasticsearch">github</a> or also as an <a href="https://www.npmjs.org/package/hubot-elasticsearch">NPM package</a>. Please feel free to send PRs or create issues on our repository. All feedback is useful.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Coach don't rescue]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/10/31/coach-dont-rescue/"/>
    <updated>2014-10-31T10:14:04+00:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/10/31/coach-dont-rescue</id>
    <content type="html"><![CDATA[<p>I recently attended a fascinating and emotionally-charged talk by <a href="https://twitter.com/sisoma">Samantha Soma</a> at <a href="https://2014.dareconf.com">DareConf 2014</a>, <a href="http://vimeo.com/108047198">&lsquo;How to stop rescuing people&rsquo;</a>. It strongly mirrored my experience of moving into a leadership role and I&rsquo;d recommend anyone with a spare 30mins to watch it.</p>

<p>Samantha&rsquo;s talk made me reflect on how I struggle to coach talented individuals; how I can identify when it&rsquo;s going wrong and what steps I can take to remedy the situation.</p>

<h2>Gold star syndrome</h2>

<p>A new concept for me and a recurring theme throughout the sessions at DareConf, &lsquo;Gold Star Syndrome&rsquo; is a fixation on finding validation for your work. I feel this is a result of early childhood values spinning the perception of working life away from the actual reality. As a child, especially during our school years, we discovered that when we do good things, good things happen to us. Remember how it felt to get that gold star in your spelling test or that A+ on an English essay?</p>

<p>That was great in school and even through to University but working life is a much more terse environment and getting positive reenforcement is much less common. As professionals, the majority of our work goes unnoticed &ndash; until there is a problem or issue to solve. Then we feel open to the stinging criticism but resentful that months of good work went unnoticed.</p>

<p>When we continue to search for a gold star or continually strive for perfectionism we, as individuals, become much more insular and isolated. We tend to avoid showing our work until it is 100% ready and put up a shield to protect us from any feedback, in fear of being made to look stupid or being called a fraud.</p>

<h2>Empowerment</h2>

<p>There is a considerable amount of <a href="http://whatworksforhealth.wisc.edu/program.php?t1=20&amp;t2=6&amp;t3=84&amp;id=311">research</a> to suggest children who have bad experiences and manage to overcome them tend to grow up to become more rounded adults. By encouraging grit and allowing kids to solve their own problems, children learn they are empowered. They become more creative, more respectful, less dependant on others and display less problem behaviour.</p>

<p>This is also relatively easy to implement and can be as simple as involving children in a decision-making process. &lsquo;What do you want to eat with dinner; carrots or broccoli&rsquo;? This might progress to &lsquo;What colour socks do you want to wear?&rsquo; or &lsquo;Which swing do you want to play on?&rsquo;</p>

<p>The concept of preventing yourself from controlling a situation is really key to successful coaching. Rescuing people by dictating an outcome  requires one weak person and one strong person. This propagates itself so people drift towards being a victim or a rescuer. A much better outcome would be a group of confident, empowered individuals who are able to work together.</p>

<h2>Provide tools not solutions</h2>

<p>Even if they are unaware themselves, individuals we coach don&rsquo;t want a solution to their problem. What they want is for you to help them find their own solution. To paraphrase a great line in Samantha&rsquo;s presentation &ndash; &lsquo;Our role is to give people a view of the life they want instead of giving them the life we think they want.&rsquo;</p>

<p>And how can we start doing that? I have started to adopt Samantha&rsquo;s principles and have been staggered by how effective they are in practice:</p>

<ol>
<li><p><a href="http://outsmartyourbrain.com/find-your-emotional-triggers-on-this-list/">Know your triggers</a> &ndash; what words and situations make you race to help a colleague in distress? Are there patterns you can spot and say &lsquo;Hang on I&rsquo;ve been here before&rsquo;?</p></li>
<li><p><a href="http://www.successrockets.com/Blog-Professional-Personal-Development/bid/51210/Leadership-Development-Skill-Detached-Involvement">Maintain engaged detachment</a> &ndash; this is tough and requires us to build and nurture a certain skill set; if all else fails remember <a href="http://www.huffingtonpost.com/karen-ann-kennedy/not-my-circus-not-my-monk_b_5390455.html">&lsquo;Not my circus, not my monkeys&rsquo;</a>.</p></li>
<li><p><a href="http://www.mindtools.com/pages/article/newTMC_85.htm">Appreciative Inquiry</a> &ndash; there are lots of models and frameworks out there but in essence Appreciative Inquiry  boils down to asking someone lots of questions and listening intently to their response, however difficult!</p></li>
<li><p><a href="http://centerx.gseis.ucla.edu/xchange/teacher-leadership/teacher-workroom/reflecting-conversation">Challenge them to reflect on what happened</a> &ndash; before an individual can see past the problem, they need to acknowledge the problem and the events that lead them there.</p></li>
<li><p><a href="http://www.reallifecoaching.net/tips-on-committing-to-your-goals/">Ask them to articulate what they want to happen next</a> &ndash; coach them through how this problem can be solved and what steps they might take to resolve it. This commitment helps to clarify any misunderstanding and sets a clear path forward for coach and coachee.</p></li>
<li><p><a href="http://www.myinternalgps.com/?p=1149">Celebrate their success</a> &ndash; a pat on the back (mentally or physically) can go a long way. Why should individuals receive feedback when there is a problem? Loop back with people and celebrate the small wins as much as possible.</p></li>
</ol>


<h2>Leaders are not lifeguards!</h2>

<p>While not exactly child&rsquo;s play, I hope you have read enough here to spot the danger signs and modify your approach away from the rescuer role that ultimately helps no one.</p>

<p>Effective leaders stop jumping to the rescue and start coaching people through a bad experience, empowering individuals by providing them with the tools to come to their own conclusions and solve their own problems.</p>

<h2>Further reading</h2>

<p><a href="http://outsmartyourbrain.com/stop-fixing-people-what-to-do-when-your-brilliant-ideas-arent-helping/">http://outsmartyourbrain.com/stop-fixing-people-what-to-do-when-your-brilliant-ideas-arent-helping/</a></p>

<p><a href="http://www.huffingtonpost.com/nora-t-akins/resist-the-rescue-management_b_5537309.html">http://www.huffingtonpost.com/nora-t-akins/resist-the-rescue-management_b_5537309.html</a></p>

<p><a href="http://teambuildersplus.com/articles/heroic-leaders-dont-always-save-the-day">http://teambuildersplus.com/articles/heroic-leaders-dont-always-save-the-day</a></p>

<p><a href="http://www.dialogueworks.com/pages/blogs.php?blog_id=52#.VDery9TF87d">http://www.dialogueworks.com/pages/blogs.php?blog_id=52#.VDery9TF87d</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hobknob v1.0: Now with authorization]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/10/22/hobknob-v1-dot-0-now-with-authorization/"/>
    <updated>2014-10-22T14:00:31+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/10/22/hobknob-v1-dot-0-now-with-authorization</id>
    <content type="html"><![CDATA[<p>We are pleased to announce the version 1.0 release of <a href="https://github.com/opentable/hobknob">Hobknob</a>, our open-source feature toggle management system. With it comes a few additions and several improvements.</p>

<p>This post will expand on some of the changes, in particular, authorisation via access control lists.
For an introduction to Hobknob, see our previous post: <a href="http://tech.opentable.co.uk/blog/2014/09/04/introducing-hobknob-feature-toggling-with-etcd/">Introducing Hobknob: Feature toggling with etcd</a>.</p>

<h2>Authorisation with ACLs</h2>

<p>A much requested feature was the ability to control who can add/update/delete toggles on an application by application basis. We achieve this via the use if an Access Control List for each application. Users that are part of the ACL for an application are known as application owners.</p>

<p><img src="http://tech.opentable.co.uk/images/posts/hobknob-owners.png" alt="Hobknob Owner List" /></p>

<p>Application owners can (for an owned application):</p>

<ul>
<li>Add toggles</li>
<li>Set the value of a toggle</li>
<li>Delete toggles</li>
<li>Add additional owners</li>
<li>Remove owners</li>
</ul>


<p>Everyone can:</p>

<ul>
<li>Add an application</li>
<li>See toggles</li>
<li>See application owners</li>
<li>See the audit trail for a toggle</li>
</ul>


<p>When a user creates an new application, they are automatically added as an owner for that application.
The user can then add other application owners by clicking the &lsquo;Add user&rsquo; button in the Owners panel and entering the users email address.</p>

<p><strong>Note:</strong> this feature is only available when authentication is enabled. If Hobknob is not configured to require authentication, everyone has owner permissions to all applications. See the <a href="https://github.com/opentable/hobknob#configuring-authentication">readme</a> for more information on how to configure authentication.</p>

<h2>Deleting Toggles</h2>

<p>Feature toggles can now be deleted. This ability is available on the toggle view (get there by clicking a toggle name in the application view).</p>

<p><img src="http://tech.opentable.co.uk/images/posts/hobknob-delete.png" alt="Hobknob Toggle Delete" /></p>

<p>You&rsquo;ll notice the delete toggle button in the Danger Zone panel (we didn&rsquo;t steal that idea from Github, honest). You&rsquo;ll need to confirm the delete by clicking the delete button a second time.</p>

<p><strong>Warning:</strong> Deleting a toggle will perform a &lsquo;hard&rsquo; delete, that is, the key is deleted in etcd. The audit will persist however, and can be accessed via this route: <code>/#!/applications/app-name/toggle-name</code>. You are also allowed to re-add a toggle, and the audit will be appended to an existing audit for that toggle name.</p>

<p><strong>Note:</strong> If authentication is enabled, you must be an application owner to delete a toggle.</p>

<h2>Makeover</h2>

<p>Gone is the &lsquo;Add Toggle&rsquo; modal dialog from the previous version. This is replaced by two separate inline forms.</p>

<p>Applications are now added by clicking &lsquo;Add&rsquo; in the sidebar.</p>

<p><img src="http://tech.opentable.co.uk/images/posts/hobknob-newapplication.png" alt="Hobknob New Application" /></p>

<p>Toggles are added by clicking &lsquo;New Toggle&rsquo; in the Toggles panel for an application.</p>

<p><img src="http://tech.opentable.co.uk/images/posts/hobknob-newtoggle-v2.png" alt="Hobknob New Toggle" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PuppetConf 2014 - Part 3]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/10/06/puppetconf-2014-part-3/"/>
    <updated>2014-10-06T13:43:36+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/10/06/puppetconf-2014-part-3</id>
    <content type="html"><![CDATA[<h2>Day 2</h2>

<p>This is our summary of PuppetConf 2014. In our <a href="http://tech.opentable.co.uk/blog/2014/10/06/puppetconf-2014-part-2/">previous post</a> we gave an overview of the first day of the conference. This post will provide an
overview of the final day.</p>

<p>There were even more inspiring keynotes and lots more talks which have given us plenty of ideas to go home and think about.</p>

<h3>Key Notes</h3>

<h4>Animating the Puppet: Creating a Culture of Puppet Adoption &ndash; Dan Spurling (<a href="https://twitter.com/spurling">@spurling</a>), Getty Images &ndash; <a href="http://www.slideshare.net/PuppetLabs/keynote-animating-the-puppet-creating-a-culture-of-puppet-adoption-puppetconf-2014">Slides</a></h4>

<div style="float:right;margin:0 10px 10px 10px;width:50%">
  <img src="http://tech.opentable.co.uk/images/posts/puppetconf-dan.jpg">
</div>


<p>Dan Spuring, VP of Tech Services at Getty came out of the gate with a strong message. His <a href="http://www.urbandictionary.com/define.php?term=GSD">GSD</a> t-shirt
giving you a clear understanding of who he is. His talk about creating a culture of Puppet adoption at his company was a great story of how challenging it
can be to move various business units with projects of various ages to a configuration-management (with Puppet) ethos.</p>

<p>I think it is good to hear that they are rolling cm out into that huge backlog of legacy infrastructure that we all try to pretend isn’t there.
How do you make it integrate into existing processes? How do you sell the DevOps message at the same time as introducing a tool like Puppet into the mix as
part of that message? Dan gave some thoughts on this and it was good to hear some of that from someone who appears to be on the other side of that challenge.</p>

<p>One of the analogies that he used I that found quite useful was that undertaking a project like this is like moving a boulder. It requires an executive sponsor to
get the thing moving at all and then it requires everyone pulling in the same direction if it’s ever doing to get anywhere.</p>

<p>The big take-away was that you need to puppetize right away &ndash; that you can’t wait for the right environment or conditions to start doing it, you just need
start now and demonstrate it. This echo’s the Continuous Delivery ideal of &ldquo;if it hurts, then do it more often&rdquo;.</p>

<h4>Decentralize Your Infrastructure &ndash; Alan Green, Sony Computer Entertainment America &ndash; <a href="http://www.slideshare.net/PuppetLabs/keynote-decentralize-your-infrastructure-alan-green-sony-computer-entertainment-america">Slides</a></h4>

<div style="float:right;margin:0 10px 10px 10px;width:50%">
  <img src="http://tech.opentable.co.uk/images/posts/puppetconf-alan.jpg">
</div>


<p>Alan’s talk posed an interesting argument: decentralise and let your developers choose the tools and services that they want &ndash; just make it easy for them to
do so. This obviously flies in the face of conventional sysadmin wisdom of trying to centralise, standardise and control everything but for an organisation the
size of scale of SCEA this is just never going to work. Sony has many different studios, each has their own special requirements and tooling that they need to
try and support.</p>

<p>The story of the interaction with these studios is a great classic sysadmin story that is worth repeating. It starts with something we have all heard before &ldquo;I
need to X right now because it’s preventing me from releasing this game on time”. The reaction here is to either say Yes and risk burning out your people getting
it done or No risk your career if the release date gets pushed. As a sysadmin you&rsquo;re on the back-foot at this point &ndash; you pretty much have to do whatever it takes.
If you decentralize your infrastructure you get to turn the tables &#8220;No I don’t have tool X but we do have tool Y and Z that will meet your needs&rdquo;. This gives
the engineers/managers the choice to make rather than you &ndash; they can go out on their own and implement their first choice tool and it will take a bit longer or
they can have something supported by the team right now. Alan also made a interesting call-back to Kate Matsudaira’s keynote of the previous day when he said that
it’s all about honesty and trust. Be truthful with your engineers about what you are capable of achieving or not.</p>

<p>This is the sort of thing we do here at OpenTable and it’s been working very well. You need to design puppet to be as flexible as possible and to support those
teams that need support in their puppet implementations. Having a diverse set of tools is not a bad thing &ndash; especially when you are dealing with creative people &ndash;
it keeps them creative and you can push that creativity back into the product. You&rsquo;re also decentralising control, giving teams the ability to move their
infrastructure as fast as they need to move the product &ndash; meaning that your business is going to move faster get meet it’s ROI (because managers care about that
sort of thing)</p>

<h4>Q&amp;A with Luke Kanies</h4>

<div style="float:right;margin:0 10px 10px 10px;width:50%">
  <img src="http://tech.opentable.co.uk/images/posts/puppetconf-luke-2.jpg">
</div>


<p>The last &ldquo;keynote&rdquo; of the conference brought Luke back to the stage for a Q&amp;A with the audience. Allowing people to text in questions live led to some amusement
and once the silly questions were out of the way ( what is your favourite book?, what is your favourite animal? ) we got down to some of the big questions that
people really wanted answers to.</p>

<p><strong>Q</strong>: What is the roadmap for Puppet Apps?<br/>
<strong>A</strong>: I would be surprised if we release more than one per quarter, I’d rather put out four than 20, with five releases for each app. We are a small company,
and we have to try not to get overextended to the point where we can’t evolve the apps. They have to be evolved to be successful.</p>

<p>This seems fair, they is a lot of work involved in putting together something that is polished and tested and ready for market.</p>

<p><strong>Q</strong>: What is the future of Open Source Puppet?<br/>
<strong>A</strong>: My goal is to keep the two products complementary, and to understand each is used for different reasons .. We’re trying to change how the market works
and thinks and this is done better with software that’s absolutely everywhere.</p>

<p>He probably gets asked this all the time. The more features that are poured into Enterprise it would be easy to think that the OSS efforts are diminishing and
that there is even motivation for them to close-source. My conversations with various parties suggest that this is far from the case and I think that open source
puppet community will continue to be vibrant for a long time yet.</p>

<p><strong>Q</strong>: Where does Puppet fit into environments that don’t require convergence, where instead of adjusting the container you just re-provision?<br/>
<strong>A</strong>: Containers are a result of 10 to 15 years of investment in virtualization, so it’s easy to switch from the virtualization world to the containers world —
but a container can’t do everything.</p>

<p>This is a very pragmatic argument and he’s right. Containers are a very exciting space right now and there is no doubt that it will be a big part of the future
but the community and tooling needs to mature and there is also going to be a very long tail of “traditional” virtualisation technologies around for a very
long time yet.</p>

<p><strong>Q</strong>: Are there any plan to integration remote orchestration into Puppet?<br/>
<strong>A</strong>: It’s an area we are investing heavily in, and I’m personally investing heavily in. … I’m a big fan of small independent tools that do one job and do it
correctly, rather than big huge tools that do a lot. I want to make our orchestration better, not by adding to Puppet, but by adding tools. I don’t want to add
more functionality to Puppet, but add functionality to the Puppet ecosystem.</p>

<p>MCollective has been in the puppet eco-system for a while now. It’s going to be getting a lot more attention over the next year so I am very excited to see how
this evolves.</p>

<h3>Tech Talks</h3>

<h4>Continuous Integration for Infrastructure as Code &ndash; Gareth Rushgrove, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/continuouslytestinginfrastructure">Slides</a></h4>

<p>Arguable one of the most interesting talks of the conference. This talk took the idea of infrastructure TDD to the next level. What would it be like to be able
to test common expectations of your infrastructure (monitoring, backups, machines in each region, budget limitations). There are lots of built-in assumptions
that we make about of infrastructure and a lot of business decisions that have been difficult to codify. This talk raising the challenge of providing a complete
API for your infrastructure and then testing against it.</p>

<ul>
<li>usual tools (serverspec, wrecker)

<ul>
<li>for containers</li>
<li>TDD</li>
</ul>
</li>
<li>Policy Driven development</li>
<li>Infrastructure as an API</li>
<li>common expectations (budget etc)</li>
<li>clojure</li>
<li>can you generate serverspec tests from PuppetDB data??? &ndash; yes!</li>
<li>rake test::role::web_server</li>
<li><a href="https://github.com/garethr/serverspec-puppetdb">serverspec-puppetdb</a></li>
<li>rspec outputter &ndash; monitoring &ndash; using it as a bridge</li>
</ul>


<h4>Experiences from Running Masterless Puppet &ndash; Erik Dalén, Spotify &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppetconf-2014-1">Slides</a></h4>

<p>Erik (this years MVP) always has a lot of interesting insights about Puppet from scaling out the infrastructure at Spotify and this talk is no exception.
This talk explains their decision to go masterless and the challenges in doing so. It seems that they have put in a lot of work in writing services to manage
things like hiera data and managing secrets. It is great to see how this approach scales, one can only hope that future work by PuppetLabs with the Apps project
improves this as option for most people.</p>

<ul>
<li>scaling workflow rather than puppet masters</li>
<li>complex modules dependencies make it easy to break things</li>
<li>r10k is still a fixed environment (upgrade apache and progress at the same time)</li>
<li>they use their own tool for secret management</li>
</ul>


<h4>Getting Started with Puppet on Windows &ndash; Josh Cooper, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppetconf2014-gettingstartedwindowsfinal140925174855phpapp01">Slides</a></h4>

<p>This was a basic introduction to Puppet on windows. It covers what is possible and the many edge cases that you might run into. It was also the time to
re-announce the recent support for 64-bit puppet on windows. Thanks to Josh we also got a shout-out for the work we have done with our
<a href="forge.puppetlabs.com/opentable">forge modules</a></p>

<ul>
<li>Basic intro</li>
<li>powershell, registry_key</li>
<li>installing &ndash; mention of 64-bit</li>
<li>puppet resource</li>
<li>supported modules</li>
<li>community modules (inc OT)</li>
<li>geppetto vs VS</li>
<li>problems

<ul>
<li>quotes</li>
<li>case sensitivity</li>
<li>UAC</li>
</ul>
</li>
</ul>


<h4>Test Driven Development with Puppet &ndash; Gareth Rushgrove, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/tddforpuppet-39598529">Slides</a></h4>

<p>This is Gareth’s basic introduction to TDD with Puppet. It covers the latest tooling and how to build yourself a recent CI pipeline for your modules so that
they are forge-ready. Useful for anyone who is new to the space or who hasn’t released any modules yet.</p>

<ul>
<li>TDD</li>
<li><a href="http://rspec-puppet.com/">rspec-puppet</a></li>
<li><a href="http://puppet-lint.com/">puppet-lint</a></li>
<li><a href="https://github.com/guard/guard-rspec">guard</a></li>
<li><a href="https://github.com/gds-operations/puppet-syntax">puppet-syntax</a></li>
<li><a href="https://github.com/puppetlabs/beaker">beaker</a> (vagrant + serverspec)</li>
<li><a href="https://travis-ci.org/">travis</a></li>
<li><a href="https://github.com/garethr/puppet-module-skeleton">puppet module skeleton</a></li>
</ul>


<h4>Using Docker with Puppet &ndash; James Turnbull, Kickstarter &ndash; <a href="http://www.slideshare.net/PuppetLabs/using-docker-with-puppet-puppetconf-2014">Slides</a></h4>

<p>James gave a good introduction to Docker. Showing off the things that Docker is good at and also detailing some of the things that it isn’t.
He also showed how and when to use Puppet in this environment. For anyone moving from a  traditional set-up to a Docker based one then this talk is a must.</p>

<ul>
<li>what is docker</li>
<li>dockerfile</li>
<li>dockerhub</li>
<li>what it does</li>
<li>what it doesn’t

<ul>
<li>low-level</li>
<li>resource dependencies</li>
<li>what runs, when</li>
</ul>
</li>
<li>don’t install puppet inside your containers</li>
<li>puppet apply</li>
</ul>


<h4>Tools and Virtualization to Manage our Operations at Puppet Labs &ndash; Cody Herriges, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/tools-and-virtualization-to-manage-our-operations-at-puppet-labs-puppetconf-2014">Slides</a></h4>

<p>Cody, is a member of the PuppetLabs operations team and wow they seriously have their work cut out for them. They have to manage pretty much every network,
vm technology and cloud platform available. This gives some of the challenges in doing that and some of the tools they have built to help them in
achieving that.</p>

<ul>
<li>all the VM technologies</li>
<li>all the cloud platforms</li>
<li>all the network providers</li>
<li>automation</li>
<li>monitoring (ELK)</li>
<li>vmpooler (<a href="https://github.com/puppetlabs/vmpooler">https://github.com/puppetlabs/vmpooler</a>)</li>
</ul>


<h3>Other Talks</h3>

<ul>
<li>The Switch as a Server &ndash; Leslie Carr, Cumulus Networks &ndash; <a href="http://www.slideshare.net/PuppetLabs/the-switch-as-a-server-puppetconf-2014">Slides</a></li>
<li>Intro to Using MCollective &ndash; Devon Peters, Jive Software &ndash; <a href="http://www.slideshare.net/PuppetLabs/intro-to-using-mcollective-puppetconf-2014">Slides</a></li>
<li>How Puppet Enables the Use of Lightweight Virtualized Containers &ndash; Jeff McCune, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/how-puppet-enables-the-use-of-lightweight-virtualized-containers-jeff-mc-cune-puppet-labs">Slides</a></li>
<li>Server Locality Using Razor and LLDP &ndash; Jonas Rosland, EMC &ndash; <a href="http://www.slideshare.net/PuppetLabs/server-locality-withrazorandlldp">Slides</a></li>
<li>Node Classifier Fundamentals &ndash; Dan Lidral-Porter, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/node-classifier-fundamentals-dan-lidralporter-puppet-lab">Slides</a></li>
<li>What&rsquo;s Next for Puppet Enterprise &ndash; Lindsey Smith, Puppet Labs &amp; Susannah Axelrod, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/whats-next-for-puppet-enterprise-and-beyond">Slides</a></li>
<li>The DevOps Field Guide to Cognitive Biases (2nd Edition) &ndash; Lindsay Holmwood, Bulletproof Networks</li>
<li>Delegated Configuration with Multiple Hiera Databases &ndash; Robert Terhaar, Atlantic Dynamic &ndash; <a href="http://www.slideshare.net/PuppetLabs/rob-terhaar-puppetconf2014">Slides</a></li>
<li>Understanding OpenStack Deployments &ndash; Chris Hoge, OpenStack Foundation &ndash; <a href="http://www.slideshare.net/PuppetLabs/understanding-openstack-deployments-puppetconf-2014">Slides</a></li>
<li>Implementing Puppet at a South American Government Agency, Challenges and Solutions &ndash; Pablo Wright, Edrans &ndash; <a href="http://www.slideshare.net/PuppetLabs/implementing-puppet-at-a-south-american-government-agency-challenges-and-solutions-pablo-wright-edrans">Slides</a></li>
<li>Infrastructure as Software &ndash; Dustin J. Mitchell, Mozilla, Inc. &ndash; <a href="http://www.slideshare.net/PuppetLabs/infrastructure-as-software-dustin-j-mitchell-mozilla-inc?">Slides</a></li>
<li>Dev to Delivery with Puppet &ndash; Sam Bashton, Bashton Ltd. &ndash; <a href="http://www.slideshare.net/PuppetLabs/dev-to-delivery-with-puppet-sam-bashton-bashton-ltd">Slides</a></li>
<li>Get Puppet Enterprise into Your Company &ndash; Iko Saadhoff, KPN</li>
<li>The Puppet Master on the JVM &ndash; Chris Price, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/the-puppet-master-on-the-jvm-puppetconf-2014">Slides</a></li>
<li>The Grand Puppet Sub-Systems Tour &ndash; Nicholas Fagerlund, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/the-grand-puppet-subsystems-tour-nicholas-fagerlund-puppet-labs">Slides</a></li>
<li>Building Community: One Puppet Module at a Time &ndash; Diane Mueller, Red Hat &amp; Diego Castro, Getup Cloud</li>
<li>Puppet for Everybody! &ndash; Federated and Hierarchical Puppet Enterprise &ndash; Chris Bowles, University of Texas at Austin &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppet-for-everybody-federated-and-hierarchical-puppet-enterprise-puppetconf-2014">Slides</a></li>
<li>Puppetizing Multitier Architecture &ndash; Reid Vandewiele, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppetizing-multitier-architecture-puppetconf-2014">Slides</a></li>
<li>The Evolving Design Patterns of Puppet Enterprise &ndash; Jonathan Spinks, Sourced Group &amp; John Painter, Sourced Group &ndash; <a href="http://www.slideshare.net/PuppetLabs/the-evolving-design-patterns-of-puppet-enterprise-jonathan-spinks-sourced-group-john-painter-sourced-group">Slides</a></li>
<li>From Development to Testing to Deployment with Puppet Enterprise and Microsoft Azure &ndash; Ross Gardler, Microsoft Open Technologies, Inc. &ndash; <a href="http://www.slideshare.net/PuppetLabs/from-development-to-testing-to-deployment-with-puppet-enterprise-and-microsoft-azure-ross-gardler-microsoft-open-technologies-inc">Slides</a></li>
<li>Exploring the Final Frontier of Data Center Orchestration: Network Elements &ndash; Jason Pfeifer, Cisco &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppetconf-cisco">Slides</a></li>
<li>An In-Depth Introduction to the Puppet Enterprise Console &ndash; Ruth Linehan, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/an-indepth-introduction-to-the-puppet-enterprise-console-ruth-linehan-puppet-labs">Slides</a></li>
<li>Packaging Software, Puppet Labs Style &ndash; Melissa Stone, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/packaging-software-puppet-labs-style-puppetconf-2014">Slides</a></li>
<li>Orchestrated Functional Testing with Puppet-spec and Mspectator &ndash; Raphaël Pinson, Camptocamp &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppetconf-mspectator-talk">Slides</a></li>
<li>Fully Automate Application Delivery with Puppet and F5 &ndash; Colin Walker, F5 &ndash; <a href="http://www.slideshare.net/PuppetLabs/i-control-rest-presentation-for-puppet">Slides</a></li>
<li>Managing the File and Exposing the API &ndash; Christopher Webber, Chef Software</li>
<li>Case Study: Developing a Vblock Systems Based Private Cloud Platform with Puppet and VMware vCloud Suite &ndash; Peng Liu &amp; Paul Harb, VCE &ndash; <a href="http://www.slideshare.net/VCE_Computing/puppet-confvce-preso20140925">Slides</a></li>
<li>Got Logs? Get Answers with Elasticsearch ELK &ndash; Jordan Sissel, Elasticsearch &ndash; <a href="http://www.slideshare.net/PuppetLabs/got-logs-get-answers-with-elasticsearch-elk-puppetconf-2014">Slides</a></li>
<li>Managing Network Security Monitoring at Large Scale with Puppet &ndash; Michael Pananen &amp; Chris Nyhuis, Vigilant Technology Services &ndash; <a href="http://www.slideshare.net/PuppetLabs/managing-network-security-monitoring-at-large-scale-with-puppet-puppetconf-2014">Slides</a></li>
<li>Building and Testing from Scratch a Puppet Environment with Docker &ndash; Carla Souza, Reliant &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppet-conf2014">Slides</a></li>
</ul>


<h3>Other Interesting Links</h3>

<ul>
<li><a href="http://blog.superk.org/2014/09/puppet-conf-2014-review.html">http://blog.superk.org/2014/09/puppet-conf-2014-review.html</a></li>
<li><a href="http://www.olindata.com/blog/2014/09/first-impressions-new-cfacter">http://www.olindata.com/blog/2014/09/first-impressions-new-cfacter</a></li>
<li><a href="http://cwebber.net/blog/2014/09/26/i-am-not-a-coder/">http://cwebber.net/blog/2014/09/26/i-am-not-a-coder/</a></li>
<li><a href="http://www.slideshare.net/PuppetLabs/tag/puppetconf-2014">http://www.slideshare.net/PuppetLabs/tag/puppetconf-2014</a></li>
<li><a href="http://puppetlabs.com/blog/puppetconf-2014-day-1-tips-treats-and-tweets">http://puppetlabs.com/blog/puppetconf-2014-day-1-tips-treats-and-tweets</a></li>
<li><a href="http://puppetlabs.com/blog/puppetconf-2014-day-2-luke-q-and-a-devops-containers-and-more">http://puppetlabs.com/blog/puppetconf-2014-day-2-luke-q-and-a-devops-containers-and-more</a></li>
<li><a href="http://puppetlabs.com/blog/puppetconf-2014-day-1-tips-treats-and-tweets">http://puppetlabs.com/blog/puppetconf-2014-day-1-tips-treats-and-tweets</a></li>
<li><a href="http://puppetlabs.com/blog/puppet-conf-2014-wrap-up">http://puppetlabs.com/blog/puppet-conf-2014-wrap-up</a></li>
<li><a href="https://forge.puppetlabs.com/approved/criteria">https://forge.puppetlabs.com/approved/criteria</a></li>
<li><a href="http://puppetlabs.com/blog/puppet-server-bringing-soa-to-a-puppet-master-near-you">http://puppetlabs.com/blog/puppet-server-bringing-soa-to-a-puppet-master-near-you</a></li>
<li><a href="https://github.com/puppetlabs/puppetlabs-strings/">https://github.com/puppetlabs/puppetlabs-strings/</a></li>
<li><a href="http://bitergia.dev.puppetlabs.com/browser/">http://bitergia.dev.puppetlabs.com/browser/</a></li>
<li><a href="https://www.flickr.com/photos/pleia2/sets/72157648049231891">https://www.flickr.com/photos/pleia2/sets/72157648049231891/</a></li>
<li><a href="http://theshipshow.com/2014/10/the-pulse-of-puppetconf-2014/">http://theshipshow.com/2014/10/the-pulse-of-puppetconf-2014/</a></li>
<li><a href="http://www.theregister.co.uk/2014/09/23/puppetconf_2014_keynote/">http://www.theregister.co.uk/2014/09/23/puppetconf_2014_keynote/</a></li>
<li><a href="http://www.infoq.com/news/2014/09/puppet-approved-modules">http://www.infoq.com/news/2014/09/puppet-approved-modules</a></li>
<li><a href="https://github.com/ferventcoder/puppet-chocolatey-presentation">https://github.com/ferventcoder/puppet-chocolatey-presentation</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PuppetConf 2014 - Part 2]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/10/06/puppetconf-2014-part-2/"/>
    <updated>2014-10-06T12:30:58+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/10/06/puppetconf-2014-part-2</id>
    <content type="html"><![CDATA[<h2>Day 1</h2>

<p>This is our summary of PuppetConf 2014. In our <a href="http://tech.opentable.co.uk/blog/2014/10/06/puppetconf-2014-part-1/">previous post</a> we gave an overview of the contributor summit. This post will provide an overview
of the first day of PuppetConf.</p>

<p>As you might expect there were great keynotes with plenty of announcements and too many talks for us to attend. We have provided an outline for all the talks
we did attend and links to those we didn&rsquo;t.</p>

<h3>KeyNotes</h3>

<h4>Nearly a Decade of Puppet: What We’ve Learned and Where We’re Going Next &ndash; Luke Kanies, PuppetLabs &ndash; <a href="http://www.slideshare.net/PuppetLabs/luke-kanies-keynote-nearly-a-decade-of-puppet-what-weve-learned-and-where-were-going-next-puppetconf-2014">Slides</a></h4>

<div style="float:right;margin:0 10px 10px 10px;width:50%">
  <img src="http://tech.opentable.co.uk/images/posts/puppetconf-luke-1.jpg">
</div>


<p>The big keynote of the event to kick off the first day from the author of Puppet himself. This was obviously going to be a tweet worthy affair full of photos
and big announcements and it did not disappoint.</p>

<p>Native Clients (CFactor + C++ rewrite of agents) are coming in the very near future. This is not only a matter of improving the performance for existing users part
of philosophy of PuppetLabs to become ubiquitous across as many devices and platforms as possible. This is one of those improvements that is really setting up
PuppetLabs for the future.</p>

<p>Puppet Server (a.k.a the Clojure rewrite). This is PuppetLabs big move away from Ruby on onto the JVM. Being on the JVM means they can slowly rewrite the
codebase while also maintaining compatibility thanks to JRuby. They have gained a lot of experience with Clojure thanks to the PuppetDB &amp; TrapKeeper projects and given how
successful that project has been it has helped ease many of the fears people have in moving the JVM. Puppet Server is also a self contained application so there
is no longer any need to worry about the whole apache/passanger yak shave. There was even a demo on the metrics that are now exposed by Puppet Server &ndash; yes
you can now plug Puppet into graphite.</p>

<p>There have been plenty of follow-ups on this that you might be interested in reading:</p>

<ul>
<li><a href="http://www.infoworld.com/article/2687553/devops/puppet-server-drops-ruby-for-clojure.html">http://www.infoworld.com/article/2687553/devops/puppet-server-drops-ruby-for-clojure.html</a></li>
<li><a href="http://puppetlabs.com/blog/puppet-server-bringing-soa-to-a-puppet-master-near-you">http://puppetlabs.com/blog/puppet-server-bringing-soa-to-a-puppet-master-near-you</a></li>
<li><a href="http://puppetlabs.com/blog/new-era-application-services-puppet-labs">http://puppetlabs.com/blog/new-era-application-services-puppet-labs</a></li>
<li><a href="https://github.com/puppetlabs/puppet-server">https://github.com/puppetlabs/puppet-server</a></li>
<li><a href="http://www.informationweek.com/cloud/software-as-a-service/puppet-servers-big-revamp/d/d-id/1315934">http://www.informationweek.com/cloud/software-as-a-service/puppet-servers-big-revamp/d/d-id/1315934</a></li>
</ul>


<p>Puppet Apps was the next big announcement. Puppet Apps is actually a fantastic piece of marketing around the idea that they are refactoring to a more micro-services
style approach &ndash; splitting up the monolith that is currently the Puppet master into smaller applications that have their own release cadence and can be scaled
separately.</p>

<p>The first announcement from the &ldquo;Apps&rdquo; initiative is Puppet Node Manager the new node classifier which will roll out in the Q1 of 2015 as an add-on
to Puppet Enterprise. Given that Puppet has allowed external node classifiers to be written for a long time now (and there are many open source ones out there)
it is good to see PuppetLabs stepping up and trying to own this more and improve the experience.</p>

<p><a href="http://puppetlabs.com/about/press-releases/puppet-labs-kicks-puppetconf-announcements-major-updates-industrys-most-popular">http://puppetlabs.com/about/press-releases/puppet-labs-kicks-puppetconf-announcements-major-updates-industrys-most-popular</a></p>

<p>Another huge announcement (of which we got a preview at the contributors summit) was Puppet Approved Modules. Luke and the rest of PuppetLabs have the huge
idea that 80% of what you&rsquo;re going to want to configure on your systems should be possible with what is available on the forge. Some of the bigger pieces have
been covered by the module engineers at PuppetLabs under the existing Puppet Support Modules program. This has been fantastic in driving for consensus around
configuration making installation of certain products (like apache) easier for people.</p>

<p>The reality is that if PuppetLabs want to achieve its 80% goal they are are not going to be able to do that with the engineers and resources they have
available to them. Nor do they have the expertise to know about all the software out there. This is where the Puppet Approved program comes in. Its aim is to
provide the same standard of quality that you see in the Supported modules but for modules written by the community. It is easy for users of the forge to
be able to pick out high quality, actively maintained modules and know what they are getting. As a user this is very exciting and as a module author, while
there will be plenty of work for me to do, I am glad that the community is moving in this direction.</p>

<p>Speaking of the community, Luke used this opportunity to announce the finalists and the winner of the Most Valued Puppetier (MVP) competition.</p>

<p>Finalists:</p>

<ul>
<li>Daniele Sluijters (<a href="https://twitter.com/daenney">@daenney</a>)</li>
<li>Felix Frank</li>
<li>Tim Sharp (<a href="https://twitter.com/rodjek">@rodjek</a>)</li>
</ul>


<p>Winner</p>

<ul>
<li>Erik Dalén (<a href="(https://twitter.com/erik_dalen">@erik_dalen</a>)</li>
</ul>


<p>The last part of the keynote was talking about some of the wider thoughts as we look to the next ten years of Puppet and what comes next. There is going to be
more focus on the ubiquity of Puppet, on devices more network device partners and solving problems like orchestration. The next ten years is going to be about
taking Puppet beyond the single node. We are already thinking of machines as cattle and not pets &ndash; Puppet should also better reflect that change.</p>

<p>I for one am very excited by all this and look forward to seeing what comes out over the next few years.</p>

<h4>The Phoenix Project: Lessons Learned &ndash; Gene Kim, IT Revolution Press &ndash; <a href="http://www.slideshare.net/PuppetLabs/keynote-the-phoenix-project-lessons-learned-puppetconf-2014">Slides</a></h4>

<div style="float:right;margin:0 10px 10px 10px;width:50%">
  <img src="http://tech.opentable.co.uk/images/posts/puppetconf-gene.jpg">
</div>


<p>This was a great overview of Gene’s research of DevOps and how that intersects with high performing organisations. There were many interesting results that came
out the the survey that he did in joint co-operation with PuppetLabs many of which he shared during this talk.</p>

<p>I think the one that stands out and often tweeted is the following:</p>

<p><em>&ldquo;High performers have 30x more deployments and 8000x faster lead time, 2x the change success rate and 12x faster recovery&rdquo;</em></p>

<p>Read that again &ndash; wow.</p>

<p>This talk as one might expect was all about DevOps, its history, why and how it works. Even if you&rsquo;re fully familiar with the whole culture of DevOps there are
plenty of things to be learnt from this keynote and I look forward to re-watching it when the video lands on YouTube.</p>

<h4>Trust Me &ndash; Kate Matsudaira, Popforms &ndash; <a href="http://www.slideshare.net/PuppetLabs/keynote-trust-me-puppetconf-2014">Slides</a></h4>

<div style="float:right;margin:0 10px 10px 10px;width:50%">
  <img src="http://tech.opentable.co.uk/images/posts/puppetconf-kate.jpg">
</div>


<p>Following the theme of culture, Kate’s talk was a refreshing look at the culture of trust within an organisation. Far from being the usual &ldquo;this is what my
company culture looks like&rdquo; sort-of talk, this talk had a lot of practical advice. Discussion of how to build relationships, how to raise your profile within
the organisation and how to improve yourself as a manger. &ldquo;If you use your 1-on-1 to talk about status, you&rsquo;re wasting time. Get to know your boss, solicit
feedback on your performance.&rdquo; &ndash; Great advice like this is littered throughout the talk.</p>

<p>She says that trust is like money and that you need to be wise in how you spend that trust. Most organisations are not a meritocracy and we need to stop thinking that they are. Your relationships within the organisation are just as important as the quality of the work that you do.  There needs to be balance between these two things &ndash; are your relationships as good as the work that you do?</p>

<p>If you want to improve yourself and advance your career, either as an engineer or as a manager then you should absolutely take the time to listen to this talk.</p>

<p><strong>Bonus</strong>: the slides rock! (I won’t spoilt it &ndash; take a look)</p>

<h3>Track Talks</h3>

<h4>The Puppet Debugging Kit: Building Blocks for Exploration and Problem Solving &ndash; Charlie Sharpsteen, Puppet Labs (<a href="https://twitter.com/csharpsteen">@csharpsteen</a>) &ndash; <a href="http://www.slideshare.net/PuppetLabs/the-puppet-debugging-kit-building-blocks-for-exploration-and-problem-solving-charlie-sharpsteen-puppet-labs">Slides</a></h4>

<p>Interesting tool, has some cross-over with the Beaker testing tool. PDK is more for focused manual testing rather than automated acceptance tests.</p>

<ul>
<li><a href="https://github.com/Sharpie/puppet-debugging-kit">https://github.com/Sharpie/puppet-debugging-kit</a></li>
<li>vagrant + oscar (<a href="https://github.com/adrienthebo/oscar">https://github.com/adrienthebo/oscar</a>)</li>
<li>oscar is a collection of vagrant plugins</li>
<li>vagrant-config_builder &ndash;> adds role to share vagrant config  (similar to the beaker nodeset file)</li>
<li>PDK is a set of oscar roles</li>
<li>facter / hiera and Puppet running off GitHub</li>
<li>beaker vs oscar &ndash; oscar is optimised for manual testing. There is room to share stuff here.</li>
</ul>


<h4>Cloudy with a Chance of Fireballs: Provisioning and Certificate Management in Puppet &ndash; Eric Sorenson (<a href="https://twitter.com/ahpook">@ahpook</a>), Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/sorenson-fireballspuppet-conf2014">Slides</a></h4>

<ul>
<li>Apple iCloud uses Puppet + autosign</li>
<li>auto sign doesn&rsquo;t work very well for the cloud</li>
<li>Amazon IAM can be applied by machines &ndash; IAM so instance can read it’s own tags (if it has ec2-client-utils installed)</li>
<li>puts instance_id, ami_id and role into /etc/puppet/csr_attriubutes.yaml</li>
<li>can validate the metadata in the cert using x509</li>
<li>true_node_data = true &amp; immutable_node_data = true</li>
<li>closes security hole of setting certname to fact on agent</li>
</ul>


<h4>Beaker: Automated, Cloud-Based Acceptance Testing &ndash; Alice Nodelman (<a href="https://twitter.com/alicenode">@alicenode</a>), Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/beaker-automated-cloudbased-acceptance-testing-puppetconf-2014">Slides</a></h4>

<p>Having contributed to this tool, I was a little bias in attending this talk. Still plenty of interesting new things that came up though.
If you haven’t heard of beaker yet you will also be interested in our <a href="http://tech.opentable.co.uk/blog/2014/04/04/testing-puppet-with-beaker/">previous blog post</a>.</p>

<ul>
<li>basic introduction to what beaker is and how to use it.</li>
<li>rspec vs test dsl &ndash; both are still supported methods of writing tests.</li>
<li>junit export &ndash; useful when integrating with Jenkins</li>
<li><code>on host as</code> &ndash; is a feature that is coming soon so that you can run a command on a host with a given user account</li>
</ul>


<h4>Puppet Language 4.0 &ndash; Henrik Lindberg (<a href="https://twitter.com/hel">@hel</a>), Puppet Labs  &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppet-language-40-puppetconf-2014">Slides</a></h4>

<p>Lots and lots of interesting information here about the new Puppet 4 syntax and jokes about some of the terrible edge cases of the past. It is good to
know now that with Puppet 4 there is a formal specification for the language so we should no longer see these sorts of weird edge cases of the past.
There are also lots of new features in the language: some to deal with long standing pain points (interation), some to help in the move away from ruby
(Puppet templates) and some to prevent authors themselves writing buggy manifests (the type system). Puppet 4 is going to be an exciting this to use.</p>

<ul>
<li>pain-points / cleanup (specification)

<ul>
<li>numbers are numbers (and not strings)</li>
<li>Type references</li>
</ul>
</li>
<li>heredoc</li>
<li>Puppet templates</li>
<li>iteration (each, map, filter, reduce, slice, with)</li>
<li>local defaults</li>
<li>Type system</li>
</ul>


<h4>7 Puppet Horror Stories in 7 Years &ndash; Kris Buytaert (<a href="https://twitter.com/KrisBuytaert">@KrisBuytaert</a>), Inuits &ndash; <a href="http://www.slideshare.net/KrisBuytaert/7-years-of-puppet-horror-stories">Slides</a></h4>

<p>This was more of an interactive talk, trying to get members of the audience to try and predict what the actual problem was. For more senior Puppetiers
this was a fun talk, reminding us of the challenges many of us have faced. For newer Puppet developers this was likely acting as a good warning and
foreshadowing of things that may arise if your not careful (or are very unlucky).</p>

<ul>
<li>SSL</li>
<li>Full Disk</li>
<li>Puppet Bugs</li>
<li>DNS (everything is a DNS problem)</li>
</ul>


<h4>Killer R10K Workflow &ndash; Phil Zimmerman (<a href="https://twitter.com/phil_zimmerman">@phil_zimmerman</a>), Time Warner Cable &ndash; <a href="http://www.slideshare.net/PuppetLabs/killer-r10k-39571913">Slides</a></h4>

<p>This was a good introduction to r10k and the reasons you would want to use it. The workflow is pretty straightforward and I think that for anyone managing Puppet at scale this is going to be something to look at.</p>

<ul>
<li>some good use cases for r10k

<ul>
<li>upgrading modules</li>
<li>not having to wait for all role tests to run</li>
<li>deploying everything to all masters (even hiera)</li>
</ul>
</li>
<li>workflow

<ul>
<li>ci per module</li>
<li>release job per module (tags)</li>
<li>deploy job per module (cap task to wrap r10k for masters/nodes)</li>
</ul>
</li>
</ul>


<h3>Other Talks from the Day</h3>

<ul>
<li>Infrastructure-as-Code with Puppet Enterprise in the Cloud &ndash; Evan Scheessele, HP &ndash; <a href="http://www.slideshare.net/PuppetLabs/infrastructure-ascode-with-puppet-enterprise-in-the-cloud-evan-scheessele-hp">Slides</a></li>
<li>Getting Started with Puppet &ndash; Michael Stahnke, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/getting-started-with-puppet-puppetconf-2014">Slides</a></li>
<li>Plan, Deploy &amp; Manage Modern Applications Leveraging vCloud Automation Center and Puppet &ndash; Pradnesh Patil, VMware &ndash; <a href="http://www.slideshare.net/PuppetLabs/plan-deploy-manage-modern-applications-leveraging-vcloud-automation-center-and-puppet-puppetconf-2014">Slides</a></li>
<li>Writing and Publishing Puppet Modules &ndash; Colleen Murphy, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/writing-and-publishing-puppet-modules-colleen-murphy-puppet-labs">Slides</a></li>
<li>To the Future! &ndash; Goals for Puppet 4 &ndash; Andrew Parker, Puppet Labs &amp; Kylo Ginsberg, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/to-the-future-goals-for-puppet-and-facter-1">Slides</a></li>
<li>Managing and Scaling Puppet &ndash; Miguel Zuniga, Symantec &ndash; <a href="http://www.slideshare.net/PuppetLabs/managing-and-scaling-puppet-puppetconf-2014-39542923">Slides</a></li>
<li>What Developers and Operations Can Learn from Design: 6 Ways to Work Better Together &ndash; Ashley Hathaway, IBM Watson &ndash; <a href="http://www.slideshare.net/PuppetLabs/what-developers-and-operations-can-learn-from-design-6-ways-to-work-better-together-puppetconf-2014">Slides</a></li>
<li>Performance Tuning Your Puppet Infrastructure &ndash; Nic Benders, New Relic &ndash; <a href="http://www.slideshare.net/PuppetLabs/performance-tuning-your-puppet-infrastructure-nic-benders-new-relic">Slides</a></li>
<li>&ldquo;Sensu and Sensibility&rdquo; &ndash; The Story of a Journey From #monitoringsucks to #monitoringlove &ndash; Tomas Doran, Yelp &ndash; <a href="http://www.slideshare.net/PuppetLabs/130pm-210pm-tomas-doran-track-1-puppetconf2014-sensu">Slides</a></li>
<li>DevOps Means Business &ndash; Gene Kim, IT Revolution Press &amp; Nicole Forsgren Velasquez, Utah State University &ndash; <a href="http://www.slideshare.net/PuppetLabs/devops-means-business-gene-kim-it-revolution-press-nicole-forsgren-velasquez-utah-state-university">Slides</a></li>
<li>Auditing/Security with Puppet &ndash; Robert Maury, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/auditingsecurity-with-puppet-puppetconf-2014">Slides</a></li>
<li>Absolute Beginners Guide to Puppet Through Types &ndash; Igor Galić, Brainsware OG &ndash; <a href="http://www.slideshare.net/PuppetLabs/absolute-beginners-guide-to-puppet-through-types-igor-galic-brainsware-og">Slides</a></li>
<li>Plugging Chocolatey into Your Puppet Infrastructure &ndash; Rob Reynolds, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/plugging-chocolatey-into-your-puppet-infrastructure-rob-reynolds-puppet-labs">Slides</a></li>
<li>PuppetDB: One Year Faster &ndash; Deepak Giridharagopal, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppetconf-2014">Slides</a></li>
<li>The Puppet Community: Current State and Future Plans &ndash; Dawn Foster, Puppet Labs &amp; Kara Sowles, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/the-puppet-community-current-state-and-future-plans-dawn-foster-puppet-labs-kara-sowles-puppet-labs">Slides</a></li>
<li>Continuous Delivery of Puppet-Based Infrastructure &ndash; Sam Kottler, Digital Ocean &ndash; <a href="http://www.slideshare.net/PuppetLabs/continuous-delivery-of-puppetbased-infrastructure-puppetconf-2014">Slides</a></li>
<li>The Seven Habits of Highly Effective Puppet Users &ndash; David Danzilio, Constant Contact &ndash; <a href="http://www.slideshare.net/PuppetLabs/the-seven-habits-of-highly-effective-puppet-users-puppetconf-2014">Slides</a></li>
<li>Fact-Based Monitoring &ndash; Alexis Le-Quoc, Datadog &ndash; <a href="http://www.slideshare.net/PuppetLabs/fact-based-monitoring-puppetconf-2014">Slides</a></li>
<li>Test-Driven Puppet Development &ndash; Nan Liu, Bodeco &ndash; <a href="http://www.slideshare.net/PuppetLabs/testdriven-puppet-development-puppetconf-2014">Slides</a></li>
<li>A Practical Guide to Modules &ndash; Lauren Rother, Puppet Labs &amp; Morgan Haskel, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/a-practical-guide-to-modules-lauren-rother-puppet-labs-morgan-haskel-puppet-labs">Slides</a></li>
<li>Leveraging the PuppetDB API: Puppetboard &ndash; Daniele Sluijters, Nedap</li>
<li>Puppet Availability and Performance at 100K Nodes &ndash; John Jawed, eBay/PayPal &ndash; <a href="http://www.slideshare.net/PuppetLabs/puppet-availability-and-performance-at-100k-nodes-puppetconf-2014">Slides</a></li>
<li>DevOps and Software Defined Networking &ndash; John Willis, Pacific Crest</li>
<li>Razor, the Provisioning Toolbox &ndash; David Lutterkort, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/razor-the-provisioning-toolbox-puppetconf-2014">Slides</a></li>
<li>How to Puppetize Google Cloud Platform &ndash; Katharina Probst, Google, Matt Bookman, Google &amp; Ryan Coleman, Puppet Labs &ndash; <a href="http://www.slideshare.net/PuppetLabs/how-to-puppetize-google-cloud-platform-katharina-e">Slides</a></li>
<li>Continuous Infrastructure: Modern Puppet for the Jenkins Project &ndash; R.Tyler Croy, Jenkins &ndash; <a href="http://www.slideshare.net/PuppetLabs/continuous-infrastructure-modern-puppet-for-the-jenkins-project-rtyler-croy-jenkins">Slides</a></li>
<li>How to Measure Everything: A Million Metrics Per Second with Minimal Developer Overhead &ndash; Jos Boumans, Krux &ndash; <a href="http://www.slideshare.net/PuppetLabs/how-to-measure-everything-a-million-metrics-per-second-with-minimal-developer-overhead-puppetco">Slides</a></li>
<li>How to Open Source Your Puppet Configuration &ndash; Elizabeth Krumbach Joseph, HP &ndash; <a href="http://www.slideshare.net/PuppetLabs/how-to-open-source-your-puppet-configuration-elizabeth-krumbach-joseph-hp">Slides</a></li>
<li>Manageable Puppet Infrastructure &ndash; Ger Apeldoorn, Freelance Puppet Consultant &ndash; <a href="http://www.slideshare.net/PuppetLabs/manageable-puppet-infrastructure-ger-apeldoorn-freelance-puppet-consultant">Slides</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PuppetConf 2014 - Part 1]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/10/06/puppetconf-2014-part-1/"/>
    <updated>2014-10-06T11:47:57+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/10/06/puppetconf-2014-part-1</id>
    <content type="html"><![CDATA[<p><img src="http://tech.opentable.co.uk/images/posts/puppetconf2014.jpg" alt="The start of PuppetConf 2014" /></p>

<p>It has been one week since our attendance at this years PuppetConf and we have just now caught up on all the great talks that were
given and the projects demonstrated over the 3 day period. Here&rsquo;s our summary of the event (split into 3 parts), hopefully you will
find as much inspiration in the content as we have.</p>

<h2>Day 0 &ndash; Contributor Summit</h2>

<p>For the first time, this years Puppet Contributor Summit was held the day prior to the conference itself and I think this was a great idea.
Most of the Puppetlabs staff and many of the high profile community members were in town for PuppetConf anyway so it made sense. There was
roughly 60-70 people in attendance both senior contributors and people new to the community so it was a great mix that led to some
fantastic discussions.</p>

<p>The day itself had two tracks: a module track for forge modules and a core track for people contributing to puppet and factor.</p>

<p>Those of you who have seen our <a href="http://forge.puppetlabs.com/opentable">forge module page</a> will understand why we chose to stay in the module track.
Although I heard there were many great discussions to be had with regards to Puppet 4 in the core track.</p>

<p>Each track was split into three sections: a brief introduction from the track lead Ryan Coleman (<a href="https://twitter.com/ryanycoleman">@ryanycoleman</a>),
followed by some lighting talks and then several hours of hacking and open discussions.</p>

<h3>Lightning Talks:</h3>

<p>Here is a quick overview of the lightening talks from the module track:</p>

<h4>Puppet Analytics (Spencer Krum <a href="https://twitter.com/nibalizer">@nibalizer</a>)</h4>

<p>Spencer gave a quick demonstration of his latest project <a href="http://puppet-analytics.org/">puppet-analytics</a>. This problem that this tool was aiming to
solve was that at the present time the are no good analytics for the forge modules. The number of downloads listed for each module is very inaccurate
and can be easily inflated by (for example) an automated CI process. The point of this web app and it’s corresponding client
<a href="https://github.com/nibalizer/puppet-analytics-client">puppet-analytics-client</a> was to be built into an existing tool chain and for end users to report
which modules and versions they were using. It also has the added benefit that we could also get stats for teams using private forges.</p>

<p>Ryan also commented that PuppetLabs has some metrics it uses for it’s own modules that can be found here:
<a href="http://forge-module-metrics.herokuapp.com/">http://forge-module-metrics.herokuapp.com/</a></p>

<h4>Puppet Community (Daniele Sluijters <a href="https://twitter.com/daenney">@daenney</a>)</h4>

<p>Discussion of the shared namespace for community modules: <a href="http://puppet-community.github.io/">puppet-community</a>. This talk was about a community project
to keep modules in a shared namespace so that everyone can work on them independent of company ownership. There are limitations right now with with
regards to the forge e.g. no shared accounts and no easy migration path to move modules between namespaces but working with Ryan on that.</p>

<p>This is how the boxen project works and it seems to work pretty well.</p>

<h4>Beaker Testing Windows Environments (Liam Bennett <a href="https://twitter.com/liamjbennett">@liamjbennett</a>) &ndash; me!!</h4>

<p>My talk on hacking beaker to work better for testing windows environments.</p>

<p>Demos and PRs. Discussed more in some of our earlier posts: <a href="http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-2-the-windows-story/">Testing Puppet with Beaker pt.2 &ndash; The Windows story</a>
and <a href="http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-3-testing-roles/">Testing Puppet with Beaker pt.3 &ndash; Testing Roles</a></p>

<h4>Module Anti-Patterns (Peter Souter <a href="https://twitter.com/petems">@petems</a>) &ndash; <a href="http://www.slideshare.net/petems/puppet-module-anti-patterns">Slides</a></h4>

<p>Some interesting patterns here that are still quite preverlant in the modules found on the forge. Hopefully improved tooling and the new Puppet Approved
program will help here.</p>

<h4>Puppetlabs ModuleSync tool (Colleen Murphy <a href="https://twitter.com/pdx_krinkle">@pdx_krinkle</a>)</h4>

<p>A demonstration of the the tool <a href="https://github.com/puppetlabs/modulesync">puppetlabs-modulesync</a> which aims to take out some of the pain of managing common
static build files across a number of modules (e.g. a common Rakefile or .travis.yml which the same across almost all modules)</p>

<p>Having used this on a number of our modules now I can say that this in extremely useful and I don’t know how we managed without it. A key use case for us was
adding support for puppet 3.7 into our test matrix of our travis.yml file. 1 line change &ndash; 1 command &ndash; 18 modules updated.</p>

<h4>Strict Variables (Tomas Doran <a href="https://twitter.com/bobtfish">@bobtfish</a>)</h4>

<p>Tomas has one very good point to make here: enable <a href="https://docs.puppetlabs.com/references/latest/configuration.html#strictvariables">strict_variables</a>. Many
languages have a strict option and Puppet’s makes sure to check for those unknown variable references. The latest version of the
<a href="https://github.com/puppetlabs/puppetlabs_spec_helper">puppetlabs_spec_helper</a> supports adding this setting with an environment variable so that you can now
add this into your testing matrix.</p>

<p>We have enabled this on our open source modules and it did indeed surfice a few bugs so go and do it now.</p>

<h4>Puppet Documentation Linting (Peter Souter <a href="https://twitter.com/petems">@petems</a>)</h4>

<p>While we have very good linking for our puppet manifests themselves thanks to the <a href="http://puppet-lint.com/">puppet-lint</a> project. We still do not have any
coverage for our documentation of those manifests. That is where Peter’s <a href="https://github.com/petems/puppet-doc-lint">puppet-doc-lint</a> project comes in and aims
to lint each of you manifests for correct rdoc documentation.</p>

<p>This only supports puppet 3.4.3 right now but it is a useful tool and demonstrations something functional in an area that is missing from the current crop of
community tooling. This is going to become more useful as we want to have good documentation for Puppet Approved status.</p>

<p>It is also worth noting that PuppetLabs themselves have been doing some work in this area with
<a href="https://github.com/puppetlabs/puppetlabs-strings/">puppet-strings</a>. This projects works on puppet 3.6 + and support yard doc but is roughly the same idea.</p>

<h4>Quick Survey (Michael Stahnke <a href="https://twitter.com/stahnma">@stahnma</a>)</h4>

<p>Michael here decided to use the opportunity of having everyone in the room to ask a few questions regarding the state of puppet use and the platforms it’s
deployed on. Not too many surprises here: Debian (mostly ubuntu 12) and RedHat (mostly centos 6) dominate with a small grouping of other platforms like AIX and
Solaris in toe. Some poor individuals still have ubuntu 8 and 10 in production but I won’t name name’s because we have all been in that position before. No
mention of windows but then I did bring that up in my own talk so I think that was covered already.</p>

<h3>Hacking and Discussions</h3>

<p>The second part of the day was the hacking and discussions part. This was more un-conference style with variables tables put together to discuss various topics,
try and resolves issues or hack on projects. There were four main areas that I noticed: module testing, windows, docker, forge improvements (apologies if I
missed your topic/table).</p>

<h4>Module Testing</h4>

<p>This was probably the most common topic and several tables were set up around this idea but a huge range of things were discussed. Some people wanted to know
about how to get up and running with beaker tests using vagrant+vagrant cloud, some wanted to discuss specific platform issues (windows, docker, solaris), other
 wanted to discuss how best to scale out the tests once you have them.</p>

<p>There was some discussion based around the tools like puppet-doc-lint that were demonstrated during the lightning talks and it’s good to see these missing
aspects of the testing tool chain getting some light.</p>

<p>It’s nice to think that we have moved to this stage now where we have all the tools to support a full development tool chain for puppet and that most of the
discussion was around improving and maturing what we have.</p>

<h4>Docker</h4>

<p>Docker is one of those tools that can be considered the latest hotness so it’s no surprise that it gained some interest here also. Many people wanted to see it
in use and demonstrated and to discuss it’s use either from the point of view of being able to test with it or test against it.</p>

<p>I see this topic getting a lot more coverage in the future as more and more teams move into this space.</p>

<h4>Windows</h4>

<p>Led by myself, Drewi Wilson and Travis Fields (<a href="https://twitter.com/tefields">@tefields</a>) the two aims for this discussion were to gather input/feedback from people using
the existing windows modules and to try and discover areas in the windows ecosystem that were not currently managed (either well or at all) by Puppet.</p>

<p>We got some fantastic feedback we got regarding our OpenTable modules &ndash; thank you to everyone who was there any everyone else who reached out about that.</p>

<p>We also managed to start to populate a list of things that need some work. You can contribute to that list
<a href="https://docs.google.com/document/d/1bwgTo4D7lL8REA1s-IIKlfMrvY434Xn0cyZ7b1X-TwQ">here</a></p>

<p>There was also some discussion of using MCollective on Windows. This has been a little painful in the past (I should blog about this in the future) but it will
be getting a little more love going forward. Generally PuppetLabs is very aware of the orchestration space and will be looking into solving this problem with
it’s tools going forward.</p>

<h4>Forge Improvements</h4>

<p>Given that this was the Module track it was obvious that at some point we would all want to discuss improvement that we would want to see in the puppet forge. Ryan
led the table here and there was lots of be said by all.</p>

<p>A couple of interesting documents emerged that you might be interested in:</p>

<ul>
<li><a href="https://docs.google.com/document/d/1N8U_8UnIGFHC1Q6aTyLgx1d6wvvjuyTT1EO-OYSIu3k">Suggestions for the Puppet Approved module criteria</a></li>
<li><a href="https://docs.google.com/document/d/1gwoM8xHnWaRQ3Jqce0oursI_ts5BWnHEUVXRQuIh6Yk">Forge Improvements</a></li>
</ul>


<p>There was also some discussion of how best to pull stats out from the forge. Many people either scrape the API, use the API to take a dump of the whole of the forge
but none of these approaches are best for either the user or for the forge site itself. PuppetLabs uses various approaches to this internally depending on the use
case. Such use cases include: &ldquo;who is using my module?&rdquo; or &ldquo;who is using the bit of code?&rdquo;. There should be improvements to the forge to make answering these sorts
of questions a little easier in the future.</p>

<h2>Summary</h2>

<p>The contributor summit was personally one of the most useful days of the conference. Being able to see the lastest tooling and discuss the latest problems is always
very useful to module authors like ourselves. Hopefully you&rsquo;ll find this summary as useful as we do.</p>

<p>Next up Day 1 &ndash; PuppetConf proper..</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing Hobknob: Feature toggling with etcd]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/09/04/introducing-hobknob-feature-toggling-with-etcd/"/>
    <updated>2014-09-04T20:09:52+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/09/04/introducing-hobknob-feature-toggling-with-etcd</id>
    <content type="html"><![CDATA[<p>The ability to dynamically turn features on/off in software without the need to redeploy code is extremely beneficial. Whether you are trialing a new feature or using branch by abstraction to avoid creating feature branches, the use of feature toggles can aid continuous delivery and provide a mechanism to reduce mean time to resolution when an issue occurs.</p>

<p>With a relatively large engineering department with multiple teams spread across the US and UK the need to manage feature toggles has evolved to the point whereby individual teams have developed their own implementations. Most of these are simple config files.</p>

<p>We decided to unify this effort by providing a central place to store feature toggles, provide a dashboard to be able to turn these toggles on/off and provide language specific clients to integrate into our software components.</p>

<p>The results of this was <a href="https://github.com/opentable/hobknob">Hobknob</a>.</p>

<h2>Why etcd?</h2>

<p>We made the decision to use <a href="https://github.com/coreos/etcd">etcd</a>. Etcd is &ldquo;a highly-available key value store for shared configuration&rdquo; (<a href="https://github.com/coreos/etcd#etcd">https://github.com/coreos/etcd#etcd</a>). It provides a HTTP API to store and retrieve data. This is what makes it perfect for a feature toggling solution used by multiple components. It means that we didn&rsquo;t have to write an intermediate API on top of a data store for consumers.</p>

<p>So, for example, to store a feature toggle in etcd:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -L http://127.0.0.1:4001/v2/keys/v1/toggles/restaurant-api/testtoggle -XPUT -d value="true"</span></code></pre></td></tr></table></div></figure>


<p>To retrieve a feature toggle:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -L http://127.0.0.1:4001/v2/keys/v1/toggles/restaurant-api/testtoggle</span></code></pre></td></tr></table></div></figure>


<h2>The Hobknob Clients</h2>

<p>To aid adoption we created, and open sourced, several hobknob clients in multiple languages:</p>

<ul>
<li>NodeJs (NPM) &ndash; <a href="https://github.com/opentable/hobknob-client-nodejs">https://github.com/opentable/hobknob-client-nodejs</a></li>
<li>.NET (Nuget) &ndash; <a href="https://github.com/opentable/hobknob-client-net">https://github.com/opentable/hobknob-client-net</a></li>
<li>Go &ndash; <a href="https://github.com/opentable/hobknob-client-go">https://github.com/opentable/hobknob-client-go</a></li>
<li>Java (Maven) &ndash; <a href="https://github.com/opentable/hobknob-client-java">https://github.com/opentable/hobknob-client-java</a></li>
</ul>


<p>The clients all store a configurable in-memory cache that is periodically updated on a polling interval. They are all read-only and updates only occur on the dashboard where they can be audited.</p>

<p>We decided to create a simple <a href="https://github.com/opentable/hobknob-demo">demo application</a> to show off how easy it is to use Hobknob in your applications. In order to try the demo you will need to start up Hobknob (see instructions below). The demo app uses the NodeJS client which is as simple as:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>var client = new Client("hobknob-demo", {
</span><span class='line'>  etcdHost: etcdHost,
</span><span class='line'>  etcdPort: etcdPort,
</span><span class='line'>  cacheIntervalMs: 5000
</span><span class='line'>});</span></code></pre></td></tr></table></div></figure>


<p>In the route definition it uses the client to request the toggle named <em>show-first-and-last-name-input</em> and passes the toggle value through to the view:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>var result = hobknobClient.getOrDefault('show-first-and-last-name-input', true);
</span><span class='line'>res.render('server', {
</span><span class='line'>                  page: 'server',
</span><span class='line'>              useTwoFieldNameInput: value
</span><span class='line'>              });</span></code></pre></td></tr></table></div></figure>


<p>The view then uses the value to decide whether to display one or two textboxes on the page:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if useTwoFieldNameInput
</span><span class='line'>  input.form-control.demo-input-small(type='text', placeholder='First name', name='firstname')
</span><span class='line'>  input.form-control.demo-input-small(type='text', placeholder='Last name', name='lastname')
</span><span class='line'>else
</span><span class='line'>  input.form-control.demo-input-large(type='text', placeholder='Full name', name='fullname')</span></code></pre></td></tr></table></div></figure>


<h2>The Hobknob Dashboard</h2>

<p>Hobknob is a NodeJS/AngularJS app. If you want to play with Hobknob the simplest way to get started is to use Vagrant. If you don&rsquo;t have it installed then get it from <a href="http://www.vagrantup.com/">http://www.vagrantup.com/</a>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/opentable/hobknob
</span><span class='line'>cd hobknob
</span><span class='line'>vagrant up</span></code></pre></td></tr></table></div></figure>


<p>You should now be able to open the dashboard on <a href="http://127.0.0.1:3006">http://127.0.0.1:3006</a></p>

<p><img src="http://tech.opentable.co.uk/images/posts/hobknob-dashboard.png" alt="Hobknob dashboard" /></p>

<p>All actions in the dashboard are audited. So when you create or update a toggle by turning it on/off an audit is written for that toggle. Clicking on a toggle in the dashboard takes you to the audit view:</p>

<p><img src="http://tech.opentable.co.uk/images/posts/hobknob-audit.png" alt="Hobknob audit" /></p>

<h3>Authentication</h3>

<p>By default Hobknob ships with authentication disabled. As a result all auditing will be recorded as &ldquo;Anonymous&rdquo;. Currently, we only support Google OAuth. To enable this follow the instructions <a href="https://github.com/opentable/hobknob/blob/master/README.md#configuring-authentication">here</a></p>

<h3>Session Storage</h3>

<p>By default Hobknob ships using in-memory session storage. You don&rsquo;t want to use this when you have a load balanced infrastructure. Hobknob supports both redis and etcd itself as a session store. To use either of these simply npm install the relevent connect middleware (<a href="https://github.com/visionmedia/connect-redis">connect-redis</a> or <a href="https://github.com/opentable/connect-etcd">connect-etcd</a>). To learn more follow the instructions <a href="https://github.com/opentable/hobknob/blob/master/README.md#configuring-session">here</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Puppet with Beaker pt.3 - Testing Roles]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-3-testing-roles/"/>
    <updated>2014-09-01T13:09:05+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-3-testing-roles</id>
    <content type="html"><![CDATA[<p>In the first two parts of this blog series we have focusing on testing puppet <em>modules</em> with beaker. As an open source contributor there is always
a large test matrix so this makes absolute sense. But what about the other large use-case for beaker &ndash; what about our day-to-day internal code base?
Not all of this is modules, in fact a large portion of it is other puppet code &ndash; roles, profiles, facts, hiera data etc. All of this needs testing
as well.</p>

<p>In this blog post I will be showing how we have started using beaker to test our puppet roles and profiles for both Linux and Windows.</p>

<h2>Master-vs-Masterless</h2>

<p>Prior to this post all our beaker testing has been master-less i.e. using using puppet agent apply. This is perfectly adequate for most use cases when
testing modules in isolation but doesn&rsquo;t always work when testing an internal code base (unless you are masterless there as well then please skip to the next section).</p>

<p>At OpenTable we do use a central puppet master to compile our catalogs. So when testing our puppet roles we wanted to make sure that we were also testing
with a master-agent configuration. It is worth mentioning here that if (like us) you are testing windows agents then you are going to need to test with master-agent
approach due to the lack of a windows master.</p>

<p>Testing the master-agent configuration means configuring multi-node sets in beaker. There are not many examples of this but the principle is very much
the same as the single-node nodeset. Here is an example:</p>

<pre><code>HOSTS:
  ubuntu-server-12042-x64-master:
    roles:
      - master
    platform: ubuntu-12.04-amd64
    box: ubuntu-server-12042-x64-vbox4210-nocm
    box_url: http://puppet-vagrant-boxes.puppetlabs.com/ubuntu-server-12042-x64-vbox4210-nocm.box
    hypervisor: vagrant
    ip: '10.255.33.135'
  win-2008R2-std:
    roles:
      - default
      - agent
    platform: windows-server-amd64
    box: opentable/win-2008r2-standard-amd64-nocm
    box_version: = 1.0.0
    box_check_update: false
    hypervisor: vagrant
    user: vagrant
    ip: '10.255.33.129'
    communicator: bitvise
CONFIG:
  log_level: verbose
  type: git
</code></pre>

<p>In this example you will see that we are specifying different &lsquo;roles&rsquo; for each host in the nodeset. What a role is in in this context is a tag for that node that allows
us to reference it directly later when running commands on the host. To avoid any further confusion, from this point onwards if I am referring to the role defined in the
nodeset file I will call it the &lsquo;nodeset role&rsquo; otherwise I am referring the the puppet role provided in the manifest. There are a couple of build-in nodeset roles that
Beaker already knows about: master, agent and default. The first two are pretty self explanatory but the last nodeset role &ndash; default &ndash; is the location where the tests
themselves run. In you don&rsquo;t specify the &lsquo;default&rsquo; nodeset role on any of your host definitions then the tests will run on the first host that you specified in in the
nodeset file (which in the case of the example above would be wrong).</p>

<p>You may have a more complicated configuration that you wish to test and this allows you to specify arbitrary tags which can be very useful.</p>

<p>We can now use these nodeset roles to configure our master and agent.</p>

<p>In parts <a href="http://tech.opentable.co.uk/blog/2014/04/04/testing-puppet-with-beaker/">[1]</a> and <a href="http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-2-the-windows-story">[2]</a> of this series we saw what a basic spec_acceptence file looks like. So let&rsquo;s start with that:</p>

<pre><code>require 'beaker-rspec/spec_helper'
require 'beaker-rspec/helpers/serverspec'
require 'winrm'

hosts.each do |host|

  if host['platform'] =~ /windows/
    include Serverspec::Helper::Windows
    include Serverspec::Helper::WinRM
  end

  version = ENV['PUPPET_VERSION'] || '3.5.1'
  install_puppet(:version =&gt; version)

  if host['roles'].include?('master')

    ... # Install a master

  else

    ... # Install an agent

  end
end

RSpec.configure do |c|

  c.before :suite do

    hosts.each do |host|
      c.host = host

      if host['platform'] =~ /windows/
        endpoint = "http://127.0.0.1:5985/wsman"
        c.winrm = ::WinRM::WinRMWebService.new(endpoint, :ssl, :user =&gt; 'vagrant', :pass =&gt; 'vagrant', :basic_auth_only =&gt; true)
        c.winrm.set_timeout 300
      end
    end
  end
end
</code></pre>

<p>We can see here how we use the host[&lsquo;roles&rsquo;] in order to select the appropriate code-path for configurting each nodeset role. Now let&rsquo;s
move onto how we configure each of those nodeset roles.</p>

<h2>Configuring the master</h2>

<p>There are a lot of things that go into building a puppetmaster:
 &ndash; puppetmaster packages
 &ndash; hiera backends
 &ndash; gems for addditional dependencies (eyaml + puppetdbquery)
 &ndash; downloading external modules</p>

<p>Now let&rsquo;s step through our new spec_acceptence file that supports this multi-node environment:</p>

<h3>Deploying the codebase</h3>

<p>Stage one is getting our puppet codebase onto the master, which includes all the files, internal modules and anything else we need to get the master up and
running. We do this like follows:</p>

<pre><code>files = [ 'environments','facts','hiera','roles', 'profiles', 'keys', 'app_modules', 'auth.conf','autosign.conf',
          'fileserver.conf', 'Gemfile','hiera.yaml','Puppetfile'
        ]

files.each do |file|
  scp_to master, File.expand_path(File.join(File.dirname(__FILE__), '..', file)), "/etc/puppet/#{file}"
end

# scp dist modules folder (this excludes stuff like spec and test folders)
dist_modules = Dir["#{dist_modules_root}/*/"].map { |a| File.basename(a) }
dist_modules.each do |module_name|
  dist_module_dir = "#{dist_modules_root}/#{module_name}"
  copy_module_to(master, :source =&gt; dist_module_dir, :module_name =&gt; module_name)
end
</code></pre>

<p>Here we are selecting all the files that we want and calling the scp_to method which will scp any file or directory to the host of choice, in this case our
master.</p>

<h3>The puppetmaster:</h3>

<pre><code>...

on master, "apt-get install -y rubygems git"
on master, "apt-get install -y puppet-common=#{version}-1puppetlabs1 puppetmaster-common=#{version}-1puppetlabs1 puppetmaster=#{version}-1puppetlabs1 "
on master, "echo '*' &gt; /etc/puppet/autosign.conf"

...
</code></pre>

<p>So we have already installed puppet at a previous stage in our script. At this point we are performing all the steps required to install the
puppetmaster: git, rubygems (if on an older distro) and the puppetmaster packages. We also making sure that we auto-signing if configured to
save us some pain later on. This step should really be configured as another beaker method that we can just call but for now it is still manual.
It is at this point that we have first introduced the &ldquo;on master&rdquo; this does what you think it might, it executes the command you pass it onto
the host with the nodeset role on &lsquo;master&rsquo;.</p>

<h3>Set the puppet.conf file:</h3>

<pre><code>...

config = {
  'main' =&gt; {
    'server'   =&gt; master_name,
    'certname' =&gt; master_name,
    'logdir'   =&gt; '/var/log/puppet',
    'vardir'   =&gt; '/var/lib/puppet',
    'ssldir'   =&gt; '/var/lib/puppet/ssl',
    'rundir'   =&gt; '/var/run/puppet'
  },
  'agent' =&gt; {
    'environment' =&gt; 'vagrant'
  }
}

configure_puppet(master, config)

...
</code></pre>

<p>Here we are configuring out puppet.conf file, making sure that it includes any customization we might need. This uses a configure_puppet method
that we have added to beaker to allow us to do this customization and in this case it is taking the hash to modify the puppet.conf file on the master
host.</p>

<h3>Install the required ruby gems:</h3>

<pre><code>...

on master, "gem install bundler"
on master, "gem install hiera-eyaml"
on master, "cd /etc/puppet &amp;&amp; bundle install --without development"

...
</code></pre>

<p>The average production-ready puppetmaster also requires a number of gems to function such as hiera-eyaml, deep_merge any many others
depending upon what backends and other custom puppet extensions you have implemented. Here we are installing all our dependencies from
the Gemfile we have already put onto the host.</p>

<h3>Installing modules:</h3>

<pre><code>...

on master, "cd /etc/puppet &amp;&amp; bundle exec librarian-puppet install"

...
</code></pre>

<p>The last major step is installing any external modules you have. You may be using librarian-puppet or r10k to do this. In our case it
is the former so we go ahead and make sure that our modules directory is full of all the modules we require.</p>

<h3>Networking:</h3>

<pre><code>...

master_name = "#{master}.test.local"
on master, "echo '10.255.33.135   #{master_name}' &gt;&gt; /etc/hosts"
on master, "hostname #{master_name}"
on master, "/etc/init.d/puppetmaster restart"

...
</code></pre>

<p>This last step is a small hack that you will probably require if you are running on vagrant. It just configures the host file to make
sure that it&rsquo;s hostname if configured correctly from certificate signing to work as expected. This might not be required in your
environment and I would try it without first but it&rsquo;s worth noting anyway.</p>

<h2>Configuring the agent</h2>

<p>So if you&rsquo;ve got to this point well done &ndash; most of the hard work is done. Configuring the agent(s) is pretty straightforward in comparison
to a puppetmaster and some of the steps are similiar:</p>

<h3>Set the puppet.conf file:</h3>

<pre><code>if host['roles'].include?('master')
  ...
else
  agent = host
  master = only_host_with_role(hosts, 'master')
  agent_name = agent.to_s.downcase
  master_fqdn = "#{master}.test.local"
  agent_fqdn = "#{agent_name}.test.local"

  if agent['platform'] =~ /windows/
    config = {
      'main' =&gt; {
        'server'   =&gt; master_fqdn,
        'certname' =&gt; agent_name,
        'logdir'   =&gt; 'C:\\ProgramData\\PuppetLabs\\puppet\\var\\log',
        'vardir'   =&gt; 'C:\\ProgramData\\PuppetLabs\\puppet\\var\\lib',
        'ssldir'   =&gt; 'C:\\ProgramData\\PuppetLabs\\puppet\\var\\lib\\ssl',
        'rundir'   =&gt; 'C:\\ProgramData\\PuppetLabs\\puppet\\var\\run'
      },
      'agent' =&gt; {
        'environment' =&gt; 'vagrant'
      }
    }
  else
    config = {
      'main' =&gt; {
        'server'   =&gt; master_fqdn,
        'certname' =&gt; agent_fqdn,
        'logdir'   =&gt; '/var/log/puppet',
        'vardir'   =&gt; '/var/lib/puppet',
        'ssldir'   =&gt; '/var/lib/puppet/ssl',
        'rundir'   =&gt; '/var/run/puppet'
      },
      'agent' =&gt; {
        'environment' =&gt; 'vagrant'
      }
    }
  end
  ...

  configure_puppet(agent, config)
end

...
</code></pre>

<p>Again here we are again using the configure_puppet method, this time change the puppe.conf file on the agent.</p>

<p>As you can see we are catering for both windows and linux hosts here. We are also making sure that the certname
and server are defined properly and match what we set-up for the master so that auto-signing works correctly.</p>

<h2>Testing the Role</h2>

<p>At this point we have now does all our prerequisites and we can spin up two machines to test against &ndash; 1 master and
1 agent. But when we are testing a role what is it that we actually want to test and why is this not covered in
earlier less-expensive puppet-rspec unit tests?</p>

<p>Well there are 3 key things that we wanted to test:
1. Idempotence <br/> This is pretty straight forward to test. Beaker provides a method run_agent_on that will run the puppet agent on a
  given host. This means we can test idempotency like this:</p>

<pre><code>   run_agent_on(agent, :catch_failures =&gt; true)
   expect(run_agent_on(agent, :catch_failures =&gt; true).exit_code).to be_zero
</code></pre>

<ol>
<li><p>Interaction of multiple modules and profiles <br/> This is the big motivator &ndash; we want to test that and make sure that the combinations
of profiles that we are applying work together and do not either break the catalog or operate in a non-idempotent way. We are also gaining
the ability to test that updates in modules (many of which are external from the puppet forge) do not break our roles in any way.</p></li>
<li><p>Postivie/Negative testing &ndash; do we clean up after ourselves if we remove something. <br/> This is not something that is often considered
very often, particularly in a world where machines are torn down and re-build so often but there still exists a use-case where this is not
always possible and we want to make sure that our roles and manifests are not littering our machines unnecessarily.</p></li>
</ol>


<p>Below is a full example of one of our linux profiles:</p>

<pre><code>require 'spec_helper_acceptance'

describe 'linux_base_profile', :if =&gt; fact('osfamily').eql?('Debian') do
  context 'linux base profile' do
    it 'should should run successfully' do

      agent = only_host_with_role(hosts, 'agent')
      master = only_host_with_role(hosts, 'master')

      pp = "node \"#{agent}\" { include profiles::linux::base }"
      on master, "echo '#{pp}' &gt;&gt; /etc/puppet/manifests/site.pp"

      run_agent_on(agent, :catch_failures =&gt; true)
      expect(run_agent_on(agent, :catch_failures =&gt; true).exit_code).to be_zero
    end

    context 'installation of ops tools' do

      describe package('sysstat') do
        it { should be_installed }
      end

      describe package('iotop') do
        it { should be_installed }
      end

      describe package('ngrep') do
        it { should be_installed }
      end

      describe package('lsof') do
        it { should be_installed }
      end

      describe package('unzip') do
        it { should be_installed }
      end
    end

    context 'managing puppet version' do

      describe file('/etc/apt/sources.list.d/puppetlabs.list') do
        it { should be_file }
        it { should be_owned_by 'root' }
        it { should be_mode 644 }
      end

      describe package('puppet') do
        it { should be_installed.by('apt').with_version('3.6.1-1puppetlabs1') }
      end
    end

    context 'manage sshd configuration' do

      describe process("sshd") do
        it { should be_running }
      end

      describe port(22) do
        it { should be_listening }
      end

      describe file('/etc/ssh/sshd_config') do
        its(:content) { should match /PermitRootLogin no/ }
        its(:content) { should match /PasswordAuthentication yes/ }
        its(:content) { should match /UseDNS no/ }
      end
    end
  end
end
</code></pre>

<p>We have a lot of roles and profiles that we would like to test. As you might imagine this could get quite verbose and repetitive pretty quickly. We are currently building
up <a href="https://www.relishapp.com/rspec/rspec-core/docs/example-groups/shared-context">shared_contexts</a> for each of our profiles which we can
then wrap up into roles to easily reflect our roles/profiles structure in the main codebase.</p>

<h2>Summary</h2>

<p>We are just at the very beginning of this journey with Beaker. As well as testing all our modules we are looking to scale our to test the roles and profiles in our whole
code base. These examples here are how we are doing it at the moment for our mixed-platform environment. We will continue to expand upon it and build it into our pipeline.
At this moment we are looking to expand beyond vagrant and run these against AWS instances but perhaps that is for the next post &hellip;</p>

<p>As usual for any questions or comments then please reach out to me on twitter <a href="https://twitter.com/liamjbennett">@liamjbennett</a></p>
]]></content>
  </entry>
  
</feed>
