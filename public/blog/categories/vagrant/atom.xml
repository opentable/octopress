<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Vagrant | OpenTable Tech UK Blog]]></title>
  <link href="http://tech.opentable.co.uk/blog/categories/vagrant/atom.xml" rel="self"/>
  <link href="http://tech.opentable.co.uk/"/>
  <updated>2015-02-07T14:21:51+00:00</updated>
  <id>http://tech.opentable.co.uk/</id>
  <author>
    <name><![CDATA[OpenTable]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Testing Puppet with Beaker pt.3 - Testing Roles]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-3-testing-roles/"/>
    <updated>2014-09-01T13:09:05+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-3-testing-roles</id>
    <content type="html"><![CDATA[<p>In the first two parts of this blog series we have focusing on testing puppet <em>modules</em> with beaker. As an open source contributor there is always
a large test matrix so this makes absolute sense. But what about the other large use-case for beaker &ndash; what about our day-to-day internal code base?
Not all of this is modules, in fact a large portion of it is other puppet code &ndash; roles, profiles, facts, hiera data etc. All of this needs testing
as well.</p>

<p>In this blog post I will be showing how we have started using beaker to test our puppet roles and profiles for both Linux and Windows.</p>

<h2>Master-vs-Masterless</h2>

<p>Prior to this post all our beaker testing has been master-less i.e. using using puppet agent apply. This is perfectly adequate for most use cases when
testing modules in isolation but doesn&rsquo;t always work when testing an internal code base (unless you are masterless there as well then please skip to the next section).</p>

<p>At OpenTable we do use a central puppet master to compile our catalogs. So when testing our puppet roles we wanted to make sure that we were also testing
with a master-agent configuration. It is worth mentioning here that if (like us) you are testing windows agents then you are going to need to test with master-agent
approach due to the lack of a windows master.</p>

<p>Testing the master-agent configuration means configuring multi-node sets in beaker. There are not many examples of this but the principle is very much
the same as the single-node nodeset. Here is an example:</p>

<pre><code>HOSTS:
  ubuntu-server-12042-x64-master:
    roles:
      - master
    platform: ubuntu-12.04-amd64
    box: ubuntu-server-12042-x64-vbox4210-nocm
    box_url: http://puppet-vagrant-boxes.puppetlabs.com/ubuntu-server-12042-x64-vbox4210-nocm.box
    hypervisor: vagrant
    ip: '10.255.33.135'
  win-2008R2-std:
    roles:
      - default
      - agent
    platform: windows-server-amd64
    box: opentable/win-2008r2-standard-amd64-nocm
    box_version: = 1.0.0
    box_check_update: false
    hypervisor: vagrant
    user: vagrant
    ip: '10.255.33.129'
    communicator: bitvise
CONFIG:
  log_level: verbose
  type: git
</code></pre>

<p>In this example you will see that we are specifying different &lsquo;roles&rsquo; for each host in the nodeset. What a role is in in this context is a tag for that node that allows
us to reference it directly later when running commands on the host. To avoid any further confusion, from this point onwards if I am referring to the role defined in the
nodeset file I will call it the &lsquo;nodeset role&rsquo; otherwise I am referring the the puppet role provided in the manifest. There are a couple of build-in nodeset roles that
Beaker already knows about: master, agent and default. The first two are pretty self explanatory but the last nodeset role &ndash; default &ndash; is the location where the tests
themselves run. In you don&rsquo;t specify the &lsquo;default&rsquo; nodeset role on any of your host definitions then the tests will run on the first host that you specified in in the
nodeset file (which in the case of the example above would be wrong).</p>

<p>You may have a more complicated configuration that you wish to test and this allows you to specify arbitrary tags which can be very useful.</p>

<p>We can now use these nodeset roles to configure our master and agent.</p>

<p>In parts <a href="http://tech.opentable.co.uk/blog/2014/04/04/testing-puppet-with-beaker/">[1]</a> and <a href="http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-2-the-windows-story">[2]</a> of this series we saw what a basic spec_acceptence file looks like. So let&rsquo;s start with that:</p>

<pre><code>require 'beaker-rspec/spec_helper'
require 'beaker-rspec/helpers/serverspec'
require 'winrm'

hosts.each do |host|

  if host['platform'] =~ /windows/
    include Serverspec::Helper::Windows
    include Serverspec::Helper::WinRM
  end

  version = ENV['PUPPET_VERSION'] || '3.5.1'
  install_puppet(:version =&gt; version)

  if host['roles'].include?('master')

    ... # Install a master

  else

    ... # Install an agent

  end
end

RSpec.configure do |c|

  c.before :suite do

    hosts.each do |host|
      c.host = host

      if host['platform'] =~ /windows/
        endpoint = "http://127.0.0.1:5985/wsman"
        c.winrm = ::WinRM::WinRMWebService.new(endpoint, :ssl, :user =&gt; 'vagrant', :pass =&gt; 'vagrant', :basic_auth_only =&gt; true)
        c.winrm.set_timeout 300
      end
    end
  end
end
</code></pre>

<p>We can see here how we use the host[&lsquo;roles&rsquo;] in order to select the appropriate code-path for configurting each nodeset role. Now let&rsquo;s
move onto how we configure each of those nodeset roles.</p>

<h2>Configuring the master</h2>

<p>There are a lot of things that go into building a puppetmaster:
 &ndash; puppetmaster packages
 &ndash; hiera backends
 &ndash; gems for addditional dependencies (eyaml + puppetdbquery)
 &ndash; downloading external modules</p>

<p>Now let&rsquo;s step through our new spec_acceptence file that supports this multi-node environment:</p>

<h3>Deploying the codebase</h3>

<p>Stage one is getting our puppet codebase onto the master, which includes all the files, internal modules and anything else we need to get the master up and
running. We do this like follows:</p>

<pre><code>files = [ 'environments','facts','hiera','roles', 'profiles', 'keys', 'app_modules', 'auth.conf','autosign.conf',
          'fileserver.conf', 'Gemfile','hiera.yaml','Puppetfile'
        ]

files.each do |file|
  scp_to master, File.expand_path(File.join(File.dirname(__FILE__), '..', file)), "/etc/puppet/#{file}"
end

# scp dist modules folder (this excludes stuff like spec and test folders)
dist_modules = Dir["#{dist_modules_root}/*/"].map { |a| File.basename(a) }
dist_modules.each do |module_name|
  dist_module_dir = "#{dist_modules_root}/#{module_name}"
  copy_module_to(master, :source =&gt; dist_module_dir, :module_name =&gt; module_name)
end
</code></pre>

<p>Here we are selecting all the files that we want and calling the scp_to method which will scp any file or directory to the host of choice, in this case our
master.</p>

<h3>The puppetmaster:</h3>

<pre><code>...

on master, "apt-get install -y rubygems git"
on master, "apt-get install -y puppet-common=#{version}-1puppetlabs1 puppetmaster-common=#{version}-1puppetlabs1 puppetmaster=#{version}-1puppetlabs1 "
on master, "echo '*' &gt; /etc/puppet/autosign.conf"

...
</code></pre>

<p>So we have already installed puppet at a previous stage in our script. At this point we are performing all the steps required to install the
puppetmaster: git, rubygems (if on an older distro) and the puppetmaster packages. We also making sure that we auto-signing if configured to
save us some pain later on. This step should really be configured as another beaker method that we can just call but for now it is still manual.
It is at this point that we have first introduced the &ldquo;on master&rdquo; this does what you think it might, it executes the command you pass it onto
the host with the nodeset role on &lsquo;master&rsquo;.</p>

<h3>Set the puppet.conf file:</h3>

<pre><code>...

config = {
  'main' =&gt; {
    'server'   =&gt; master_name,
    'certname' =&gt; master_name,
    'logdir'   =&gt; '/var/log/puppet',
    'vardir'   =&gt; '/var/lib/puppet',
    'ssldir'   =&gt; '/var/lib/puppet/ssl',
    'rundir'   =&gt; '/var/run/puppet'
  },
  'agent' =&gt; {
    'environment' =&gt; 'vagrant'
  }
}

configure_puppet(master, config)

...
</code></pre>

<p>Here we are configuring out puppet.conf file, making sure that it includes any customization we might need. This uses a configure_puppet method
that we have added to beaker to allow us to do this customization and in this case it is taking the hash to modify the puppet.conf file on the master
host.</p>

<h3>Install the required ruby gems:</h3>

<pre><code>...

on master, "gem install bundler"
on master, "gem install hiera-eyaml"
on master, "cd /etc/puppet &amp;&amp; bundle install --without development"

...
</code></pre>

<p>The average production-ready puppetmaster also requires a number of gems to function such as hiera-eyaml, deep_merge any many others
depending upon what backends and other custom puppet extensions you have implemented. Here we are installing all our dependencies from
the Gemfile we have already put onto the host.</p>

<h3>Installing modules:</h3>

<pre><code>...

on master, "cd /etc/puppet &amp;&amp; bundle exec librarian-puppet install"

...
</code></pre>

<p>The last major step is installing any external modules you have. You may be using librarian-puppet or r10k to do this. In our case it
is the former so we go ahead and make sure that our modules directory is full of all the modules we require.</p>

<h3>Networking:</h3>

<pre><code>...

master_name = "#{master}.test.local"
on master, "echo '10.255.33.135   #{master_name}' &gt;&gt; /etc/hosts"
on master, "hostname #{master_name}"
on master, "/etc/init.d/puppetmaster restart"

...
</code></pre>

<p>This last step is a small hack that you will probably require if you are running on vagrant. It just configures the host file to make
sure that it&rsquo;s hostname if configured correctly from certificate signing to work as expected. This might not be required in your
environment and I would try it without first but it&rsquo;s worth noting anyway.</p>

<h2>Configuring the agent</h2>

<p>So if you&rsquo;ve got to this point well done &ndash; most of the hard work is done. Configuring the agent(s) is pretty straightforward in comparison
to a puppetmaster and some of the steps are similiar:</p>

<h3>Set the puppet.conf file:</h3>

<pre><code>if host['roles'].include?('master')
  ...
else
  agent = host
  master = only_host_with_role(hosts, 'master')
  agent_name = agent.to_s.downcase
  master_fqdn = "#{master}.test.local"
  agent_fqdn = "#{agent_name}.test.local"

  if agent['platform'] =~ /windows/
    config = {
      'main' =&gt; {
        'server'   =&gt; master_fqdn,
        'certname' =&gt; agent_name,
        'logdir'   =&gt; 'C:\\ProgramData\\PuppetLabs\\puppet\\var\\log',
        'vardir'   =&gt; 'C:\\ProgramData\\PuppetLabs\\puppet\\var\\lib',
        'ssldir'   =&gt; 'C:\\ProgramData\\PuppetLabs\\puppet\\var\\lib\\ssl',
        'rundir'   =&gt; 'C:\\ProgramData\\PuppetLabs\\puppet\\var\\run'
      },
      'agent' =&gt; {
        'environment' =&gt; 'vagrant'
      }
    }
  else
    config = {
      'main' =&gt; {
        'server'   =&gt; master_fqdn,
        'certname' =&gt; agent_fqdn,
        'logdir'   =&gt; '/var/log/puppet',
        'vardir'   =&gt; '/var/lib/puppet',
        'ssldir'   =&gt; '/var/lib/puppet/ssl',
        'rundir'   =&gt; '/var/run/puppet'
      },
      'agent' =&gt; {
        'environment' =&gt; 'vagrant'
      }
    }
  end
  ...

  configure_puppet(agent, config)
end

...
</code></pre>

<p>Again here we are again using the configure_puppet method, this time change the puppe.conf file on the agent.</p>

<p>As you can see we are catering for both windows and linux hosts here. We are also making sure that the certname
and server are defined properly and match what we set-up for the master so that auto-signing works correctly.</p>

<h2>Testing the Role</h2>

<p>At this point we have now does all our prerequisites and we can spin up two machines to test against &ndash; 1 master and
1 agent. But when we are testing a role what is it that we actually want to test and why is this not covered in
earlier less-expensive puppet-rspec unit tests?</p>

<p>Well there are 3 key things that we wanted to test:
1. Idempotence <br/> This is pretty straight forward to test. Beaker provides a method run_agent_on that will run the puppet agent on a
  given host. This means we can test idempotency like this:</p>

<pre><code>   run_agent_on(agent, :catch_failures =&gt; true)
   expect(run_agent_on(agent, :catch_failures =&gt; true).exit_code).to be_zero
</code></pre>

<ol>
<li><p>Interaction of multiple modules and profiles <br/> This is the big motivator &ndash; we want to test that and make sure that the combinations
of profiles that we are applying work together and do not either break the catalog or operate in a non-idempotent way. We are also gaining
the ability to test that updates in modules (many of which are external from the puppet forge) do not break our roles in any way.</p></li>
<li><p>Postivie/Negative testing &ndash; do we clean up after ourselves if we remove something. <br/> This is not something that is often considered
very often, particularly in a world where machines are torn down and re-build so often but there still exists a use-case where this is not
always possible and we want to make sure that our roles and manifests are not littering our machines unnecessarily.</p></li>
</ol>


<p>Below is a full example of one of our linux profiles:</p>

<pre><code>require 'spec_helper_acceptance'

describe 'linux_base_profile', :if =&gt; fact('osfamily').eql?('Debian') do
  context 'linux base profile' do
    it 'should should run successfully' do

      agent = only_host_with_role(hosts, 'agent')
      master = only_host_with_role(hosts, 'master')

      pp = "node \"#{agent}\" { include profiles::linux::base }"
      on master, "echo '#{pp}' &gt;&gt; /etc/puppet/manifests/site.pp"

      run_agent_on(agent, :catch_failures =&gt; true)
      expect(run_agent_on(agent, :catch_failures =&gt; true).exit_code).to be_zero
    end

    context 'installation of ops tools' do

      describe package('sysstat') do
        it { should be_installed }
      end

      describe package('iotop') do
        it { should be_installed }
      end

      describe package('ngrep') do
        it { should be_installed }
      end

      describe package('lsof') do
        it { should be_installed }
      end

      describe package('unzip') do
        it { should be_installed }
      end
    end

    context 'managing puppet version' do

      describe file('/etc/apt/sources.list.d/puppetlabs.list') do
        it { should be_file }
        it { should be_owned_by 'root' }
        it { should be_mode 644 }
      end

      describe package('puppet') do
        it { should be_installed.by('apt').with_version('3.6.1-1puppetlabs1') }
      end
    end

    context 'manage sshd configuration' do

      describe process("sshd") do
        it { should be_running }
      end

      describe port(22) do
        it { should be_listening }
      end

      describe file('/etc/ssh/sshd_config') do
        its(:content) { should match /PermitRootLogin no/ }
        its(:content) { should match /PasswordAuthentication yes/ }
        its(:content) { should match /UseDNS no/ }
      end
    end
  end
end
</code></pre>

<p>We have a lot of roles and profiles that we would like to test. As you might imagine this could get quite verbose and repetitive pretty quickly. We are currently building
up <a href="https://www.relishapp.com/rspec/rspec-core/docs/example-groups/shared-context">shared_contexts</a> for each of our profiles which we can
then wrap up into roles to easily reflect our roles/profiles structure in the main codebase.</p>

<h2>Summary</h2>

<p>We are just at the very beginning of this journey with Beaker. As well as testing all our modules we are looking to scale our to test the roles and profiles in our whole
code base. These examples here are how we are doing it at the moment for our mixed-platform environment. We will continue to expand upon it and build it into our pipeline.
At this moment we are looking to expand beyond vagrant and run these against AWS instances but perhaps that is for the next post &hellip;</p>

<p>As usual for any questions or comments then please reach out to me on twitter <a href="https://twitter.com/liamjbennett">@liamjbennett</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Puppet with Beaker pt.2 - The Windows story]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-2-the-windows-story/"/>
    <updated>2014-09-01T09:43:10+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/09/01/testing-puppet-with-beaker-pt-dot-2-the-windows-story</id>
    <content type="html"><![CDATA[<p>In <a href="http://tech.opentable.co.uk/blog/2014/04/04/testing-puppet-with-beaker/">part one</a> we discussed our first steps into the world of acceptance testing our Puppet manifests.
By using Beaker we able to test managing local users on our Linux boxes. This was a positive experience for us. It allowed us to get to grips with the basics of configuring
Beaker to run tests and configuring our node sets to run those tests against. In this post, we will be discussing how we went about getting Beaker working with Windows.</p>

<p>As many of your reading this will be aware, OpenTable currently has quite a large Windows infrastructure and we are using Puppet extensively to maintain that environment.
We are also moving forward with releasing as many of our modules open source onto the <a href="https://forge.puppetlabs.com/opentable">Puppet Forge</a> as possible (11 out of 18 of which are Windows
exclusive). What this means is that there was no way that we could ignore trying to use Beaker to test our manifests against Windows. We knew that we would have to support
many different versions and editions of Windows out there in the community as well that the ones we have to support internally.</p>

<p>This was going to be a challenge (configuration management with Windows usually is) but we were up for it.</p>

<h2>The Preliminaries</h2>

<h3>Serverspec</h3>

<p>The first step was looking at Serverspec. Serverspec is a Ruby gem that provides extensions to RSpec that allow you to test the actual state of your servers, either locally
or from the outside in via SSH. What we needed to know was did it support Windows? The answer was thankfully a resounding &ldquo;Yes!&rdquo;. All the <a href="http://serverspec.org/resource_types.html">resource types</a> that you might want to test including file, service and user are available and supported on Windows. There are also a couple of Windows specific ones such as iis_website, Windows_feature and Windows_registry_key. We even added our own to support <a href="https://github.com/serverspec/serverspec/pull/403/files">Windows_scheduled_task</a>. Interestingly Serverspec also supports WinRM as an alternative to SSH when you are testing from the outside-in but we will go back into that later. As long as your using Serverspec > 1.6 you will have all the Windows support you might need.</p>

<h3>Packer</h3>

<p>Step two was to build some Windows Vagrant boxes to test against. The documentation on the <a href="http://github.com/puppetlabs/beaker/wiki">wiki</a> was (at the time) a bit slim when it came
to building test boxes but we knew we needed Cygwin so we went ahead and created the boxes that we needed. All our boxes are created with Packer <a href="http://github.com/opentable/packer-images">and are open sourced on GitHub</a>. They have also been <a href="http://vagrantcloud.com/opentable">published to Vagrant Cloud</a>
so you can download pre-built images and get up and running quickly (version 1.x images contain the Cygwin installation).</p>

<h3>Beaker</h3>

<p>So far, so good. We hit a couple of issues in our initial test runs with Beaker: missing module_path, installation using the msi and 32-bit Windows support &ndash; but these were very
small issues and we were happy to be able to contribute back some changes (<a href="https://github.com/puppetlabs/beaker/pull/234">234</a>,
<a href="https://github.com/puppetlabs/beaker/pull/235">235</a>, <a href="https://github.com/puppetlabs/beaker/pull/236">236</a>). We were very happy and managed to get out first module tested,
the <a href="http://github.com/opentable/puppet-puppetversion/">cross-platform module puppet-puppetversion</a> for doing Puppet upgrades.</p>

<h2>The First Example</h2>

<p>Let&rsquo;s take a more detailed look at those puppetversion tests, how we configured Beaker to run and how it changed for the Windows support. I am going to assume at this point that
you already have some familiarity with Beaker; if not and this is your first steps into the testing tool then I would suggest going back and read <a href="http://tech.opentable.co.uk/blog/2014/04/04/testing-puppet-with-beaker/">part one</a> of this series which contains a little bit of background to this and some useful resources for getting started.</p>

<p>The first thing that we needed to change for Windows was our <a href="https://raw.githubusercontent.com/opentable/puppet-puppetversion/master/spec/spec_helper_acceptance.rb">spec_accepentance.rb file</a>.</p>

<p>Step one was to include the appropriate Serverspec helpers. What this does is let Serverspec know that we are executing on Windows so that underlying resources work correctly. We are also telling
server spec here to communicate using WinRM.</p>

<pre><code>require 'beaker-rspec/spec_helper'
require 'beaker-rspec/helpers/serverspec'
require 'winrm'

hosts.each do |host|
  case host['platform']
    when /windows/
      include Serverspec::Helper::Windows
      include Serverspec::Helper::WinRM

      version = ENV['PUPPET_VERSION'] || '3.4.3'

      install_puppet(:version =&gt; version)

  else
    install_puppet
  end
end

...
</code></pre>

<p>The next step is to configure WinRM so that it can connect properly. In our case this meant connecting to Vagrant boxes.</p>

<pre><code>...

RSpec.configure do |c|
  ...
  hosts.each do |host|
    c.host = host

    if host['platform'] =~ /windows/
      endpoint = "http://127.0.0.1:5985/wsman"
      c.winrm = ::WinRM::WinRMWebService.new(endpoint, :ssl, :user =&gt; 'vagrant', :pass =&gt; 'vagrant', :basic_auth_only =&gt; true)
      c.winrm.set_timeout 300
    end

    ...
  end
end

...
</code></pre>

<p>Now let&rsquo;s look at one of the tests themselves.</p>

<p>The first part should look pretty familiar. We use the face(&lsquo;osfamily&rsquo;) helper in Beaker to make sure that the test itself is only ever executed for our Windows hosts. We are then running an apply_manifest two times in order to validate that the manifest is idempotent. The only different here is that we are specifying a custom Windows-specific module_path.</p>

<pre><code>...
require 'spec_helper_acceptance'

describe 'puppetversion', :unless =&gt; UNSUPPORTED_PLATFORMS.include?(fact('osfamily')) do
  ...

  context 'upgrade on windows', :if =&gt; fact('osfamily').eql?('windows') do

  it 'should install the new version' do
    pp = &lt;&lt;-PP
      class { 'puppetversion':
        version =&gt; '3.5.1',
        time_delay =&gt; 1
      }
    PP

    apply_manifest(pp, :modulepath =&gt; 'C:/ProgramData/PuppetLabs/puppet/etc/modules', :catch_failures =&gt; true)
    expect(apply_manifest(pp, :modulepath =&gt; 'C:/ProgramData/PuppetLabs/puppet/etc/modules', :catch_failures =&gt; true).exit_code).to be_zero
  end
</code></pre>

<p>The next part is where we actually perform the bulk of the tests. In the case of this module, we are testing
that the scheduled task has run and that Puppet has been upgraded to the appropriate version. We are making use
of the Windows_scheduled_task resource that we created earlier:</p>

<pre><code>  describe Windows_scheduled_task('puppet upgrade task') do
    it { should exist }
  end

  #This will fail if your laptop (and therefor the Vagrant vm) is not running on AC power
  describe package('puppet') do
    it {
      sleep(240) #Wait for the task to execute
      should be_installed.with_version('3.5.1')
    }
  end

  describe Windows_scheduled_task('puppet upgrade task') do
    it {
      pp = &lt;&lt;-PP
        class { 'puppetversion':
          version =&gt; '3.5.1'
        }
      PP

      apply_manifest(pp, :modulepath =&gt; 'C:/ProgramData/PuppetLabs/puppet/etc/modules', :catch_failures =&gt; true)

      should_not exist
    }
  end
end
</code></pre>

<p>The final part was to configure the nodeset file for the Windows box that we wanted to run our test against:</p>

<pre><code>HOSTS:
  windows-2008R2-serverstandard-x64:
  roles:
    - agent
  platform: windows-server-amd64
  box : opentable/win-2008r2-standard-amd64-nocm
  box_url : opentable/win-2008r2-standard-amd64-nocm
  hypervisor : vagrant
  user: vagrant
CONFIG:
  log_level: verbose
  type: git
</code></pre>

<p>This was working well for us so we continued on to our next module.</p>

<p>The next module we chose to look at was <a href="http://github.com/opentable/puppet-Windowsfeature">puppet-Windowsfeature</a>.</p>

<p>The test we have implemented in this moudle looks like this:</p>

<pre><code>require 'spec_helper_acceptance'

describe 'Windowsfeature' do
  context 'windows feature should be installed' do
    it 'should install .net 3.5 feature' do

      pp = &lt;&lt;-PP
        Windowsfeature { 'as-net-framework': }
      PP

      apply_manifest(pp, :catch_failures =&gt; true)
      expect(apply_manifest(pp, :catch_failures =&gt; true).exit_code).to be_zero
    end

    describe Windows_feature('as-net-framework') do
      it { should be_installed.by('powershell') }
    end
  end
end
</code></pre>

<p>This module was a little more tricky. Why? Installing Windows features requires elevated permissions. What this meant is that when Beaker attempted to SSH into our Windows box and our Puppet module ran its underlying PowerShell we were faced with a harsh and non-descriptive <strong>&ldquo;Access is denied error&rdquo;</strong>.</p>

<h2>SSH</h2>

<p>Not all SSH daemons are created equal. To understand the &ldquo;Access is denied error&rdquo; we were seeing and why it happens you need to understand a little bit about how sshd on Cygwin works. You can read all about the details from the Cygwin forum archives (<a href="http://cygwin.com/ml/cygwin/2004-09/msg00087.html">[1]</a>, <a href="http://cygwin.com/ml/cygwin/2006-06/msg00862.html">[2]</a>, <a href="http://thread.gmane.org/gmane.os.cygwin/128472">[3]</a>, <a href="https://cygwin.com/cygwin-ug-net/ntsec.html#ntsec-nopasswd1">[4]</a>) but TLDR; is that you need to use a username and password rather than private key authentication in order to get reasonable admin permissions. Having said all that, and having read all the documentation about the issue above we were still facing the same problem so we had to look at alternative options.</p>

<p>There are several paths you can go down and I want to tell you about them here to save you a similar yak shave:</p>

<h3>OpenSSH for Windows</h3>

<p>A thinner alternative than having to install the full Cygwin stack using OpenSSH for Windows is the same OpenSSH implementation. The issue here however is that it doesn’t contain some of the Unix binaries required for Beaker to function. You can work around this if you have Git for Windows installed on your machine by putting its bin directory on your path but overall this doesn’t really solve any of the issues we were facing. We get a lighter footprint on the machine but still the same error as before</p>

<h3>Bitvise SSH Server</h3>

<p><a href="http://www.bitvise.com/ssh-server-download">Bitvise SSH Server</a> is an alternative SSH implementation (of which there are many more listed on <a href="http://en.wikipedia.org/wiki/Comparison_of_SSH_servers">Wikipedia</a>). It resolves the permissions issue (it deals with the elevation internally) and has the benefit that it provides a proper command shell rather than a emulated bash shell. It also means we don’t have to have any binaries on there that we don’t need &ndash; a big plus. It would mean that we needed to make a few small changes to Beaker in order to replace some of the internal bash command with Windows alternatives but this was not a big task to do and is something we could contribute back.</p>

<h3>WinRM</h3>

<p>Could we do away with SSH altogether? It eliminates the problem we were facing and also means we don’t have to install anything on our Windows boxes &ndash; it’s all built in already. This would be an ideal solution but does all our tooling support it? I’ll discuss this in a little bit more detail later.</p>

<h3>Not use Beaker at all</h3>

<p>The nuclear option. If we couldn’t get anything to work we could not use Beaker at all, we could try and use Test Kitchen (with <a href="https://github.com/neillturner/kitchen-puppet">test-kitchen-puppet</a>) or some hand-rolled solution. Not the best idea, for us or the community but we though we might have to go down this path at one point. We even added <a href="https://github.com/liamjbennett/kitchen-puppet/tree/Windows_support">Windows support to test-kitchen-puppet</a> as part our diversion in this direction.</p>

<h2>What worked in the end:</h2>

<p>So we went down all these avenues and decided that the best option for us was to use Bitvise. It fixed the problem we were facing but it meant that we had some work ahead of us:
1. We had to rebuild all our Windows images with Bitvise rather than Cygwin (<a href="https://vagrantcloud.com/opentable">vagrantcloud.com/opentable</a> &ndash; version 2.x images now have this)
2. We had to make some changes to Beaker to support using a standard Windows command shell rather than a Unix shell:</p>

<ul>
<li> <a href="https://github.com/puppetlabs/beaker/pull/419">https://github.com/puppetlabs/beaker/pull/419</a> – configure_puppet method</li>
<li> <a href="https://github.com/puppetlabs/beaker/pull/420">https://github.com/puppetlabs/beaker/pull/419</a> – host_entry method</li>
<li> <a href="https://github.com/puppetlabs/beaker/pull/418">https://github.com/puppetlabs/beaker/pull/419</a> – Vagrant box_version</li>
<li> <a href="https://github.com/puppetlabs/beaker/pull/424">https://github.com/puppetlabs/beaker/pull/419</a> – Bitvise SSH</li>
</ul>


<p>With it finally working we had something that looked like this:</p>

<h2>Second Example</h2>

<p>Well with all the changes we implemented there were actually very few changes that we needed to make to our actual tests code.</p>

<p>No adjustments are needed for our spec_acceptance.rb file.</p>

<p>No adjustments are required for our spec file (show above).</p>

<p>The main change we made was in the nodeset file:</p>

<pre><code>HOSTS:
  win-2008R2-std:
  roles:
    - default
    - agent
  platform: Windows-server-amd64
  box: opentable/win-2008r2-standard-amd64-nocm
  hypervisor: vagrant
  user: vagrant
  ip: '10.255.33.129'
  communicator: bitvise
CONFIG:
  log_level: verbose
  type: git
</code></pre>

<p>The biggest change you will see here is the addition of the &lsquo;communicator&rsquo; option. What this does is to allows us to actively select to use either Cygwin or Bitvise. This means that in our case we want to use Bitvise SSH as this fixes the error we were seeing and it&rsquo;s the version of SSH now installed on your newer Vagrant boxes. Bitvise is the only supported option at the moment (in our Beaker fork) but it is likely that this will soon support WinRM as well.</p>

<p>Things to note here:
* The name of the Windows host defined in the node set must be the same as the name of the Windows hostname &ndash; if it is not then when Vagrant boots up it will change the hostname
which will put Windows into a &ldquo;restart pending&rdquo; state.</p>

<h2>The Future and WinRM</h2>

<p>Most modern versions of Windows server have WinRM enabled by default but if you are using an older version or you are attempting to test a client then you will need to make sure
that this is enabled on your boxes. This is still the direction that we would like to go long-term as it is the most Windows-friendly approach but there are few road blocks in
the way of doing so right now:</p>

<ol>
<li><p>Packer doesn’t set support WinRM as a communication method. This is being actively worked on and you can follow the work here:</p>

<ul>
<li><a href="https://github.com/mitchellh/packer/issues/451">https://github.com/mitchellh/packer/issues/451</a></li>
<li><a href="https://github.com/dylanmei/packer-communicator-winrm">https://github.com/dylanmei/packer-communicator-winrm</a></li>
</ul>
</li>
<li><p>Beaker doesn’t yet support WinRM as a communication protocol. This is currently being discussed internally after we raised the idea. The work that we have completed for
Bitvise support will go some way it allowing other providers, such as wirm going forward and therefore WinRM support should be coming in the near future.</p></li>
</ol>


<h2>Summary</h2>

<p>Using Beaker to test modules for Windows has been a long and complicated journey. I have attempted to cover here all the problems that you might run into when trying to do this for yourselves and provide some good examples to get you going. You will soon see this being rolled out to all of the OpenTable open source modules shortly so you will have some complete working examples to reference. We will continue to work with PuppetLabs in improving Beaker (and its Windows support) in order to make this a easy process for everyone.</p>

<p>For any questions or comments then please reach out to me on twitter <a href="https://twitter.com/liamjbennett">@liamjbennett</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Puppet with Beaker]]></title>
    <link href="http://tech.opentable.co.uk/blog/2014/04/04/testing-puppet-with-beaker/"/>
    <updated>2014-04-04T17:30:00+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2014/04/04/testing-puppet-with-beaker</id>
    <content type="html"><![CDATA[<p>One afternoon I got asked to write a new Puppet module to manage local users on our Linux boxes. Not a contrived example but a real-world need as we begin to move our infrastructure from Windows to Linux. Managing users is one of those tasks that is at the core of the Puppet ecosystem and I thought this would be pretty easy as I had done this sort of thing many times before. What added to the complexity was that we needed to support Ubuntu, Centos and FreeBSD machines that we had in our stack and we wanted to make it something that was open source and on the Forge &ndash; so lots of testing was required.</p>

<p>This was not the first module that I had written for the Forge but it was the first that I had written since PuppetLabs had introduced their new acceptance testing framework <a href="https://github.com/puppetlabs/beaker">Beaker</a> and so I wanted to spend some time getting the module working with this new tool.</p>

<h2>Beaker</h2>

<p>The purpose of Beaker is to allow you to write acceptance tests for your modules, that is to write some manifests that use your module and test them out on a virtual machine. Some of you may remember <a href="https://github.com/puppetlabs/rspec-system-puppet">rspec-system-puppet</a> was previously used to accomplish this, well PuppetLabs has since deprecated that in favour of Beaker but the premise is very much the same.</p>

<p>Using rspec-puppet for unit testing your manifests really only goes so far. If you&rsquo;re just using the standard Puppet resources then it pretty safe to assume that it does what it says on the tin (I mean PuppetLabs really test their stuff!) but as soon as you start doing things that are a little more complex, using exec statements, custom facts, custom functions or targeting multiple operating systems then you&rsquo;re really going to want to make sure that once the catalogs compile that they are doing what they are meant to be doing and this is where your acceptance test suite will come in.</p>

<p>With Beaker you can spin up a virtual machine, install modules, apply a manifest and then test what really happened.</p>

<p>Beaker works with many different hypervisor technologies but most people will be using <a href="http://www.vagrantup.com/">Vagrant</a> so that is what I will cover here.</p>

<h3>Configuring Beaker</h3>

<p>The first thing in configuring your existing project to use Beaker is to add “beaker” and “beaker_rspec” to you Gemfile. You&rsquo;re then going to want to create a new spec_helper file called spec_helper_acceptence.rb that should look something like this:</p>

<pre><code>require 'beaker-rspec/spec_helper'
require 'beaker-rspec/helpers/serverspec'

hosts.each do |host|
  install_puppet
end

UNSUPPORTED_PLATFORMS = ['Suse','windows','AIX','Solaris']

RSpec.configure do |c|
  proj_root = File.expand_path(File.join(File.dirname(__FILE__), '..'))

  c.formatter = :documentation

  # Configure all nodes in nodeset
  c.before :suite do
    puppet_module_install(:source =&gt; proj_root, :module_name =&gt; 'homes')
    hosts.each do |host|
      on host, puppet('module','install','puppetlabs-stdlib'), { :acceptable_exit_codes =&gt; [0,1] }
      on host, puppet('module', 'install', 'opentable-altlib'), { :acceptable_exit_codes =&gt; [0,1] }
    end
  end
end
</code></pre>

<p>This contains quite a bit of new setup that you won’t have seen before. Beaker contains lots of useful helper methods for doing all the things that you&rsquo;re going to want to do when running Puppet against a virtual machine; install Puppet (so your boxes don’t have to have it pre-baked), installing local modules and installing modules from the Forge. We also specify the platforms that we don’t support &ndash; we’ll make use of this later.</p>

<p>The next step is to define some machines that we want to set against. Beaker calls these nodesets because while in most cases you’ll only want to test one host machine at a time, Beaker does support testing multi-node configurations for more complex scenarios. Looking at the homes project your directory structure will look something like this:</p>

<pre><code>puppet-homes
  manifests
  spec
    acceptance
      nodesets
        centos-64-x64.yml
        default.yml
        ubuntu-server-12042-x64.yml
      homes_spec.rb 
    defines
    fixtures
    spec_helper.rb
    spec_helper_acceptance.rb
  tests 
</code></pre>

<p>A nodeset is simply a yaml file that specifies the box name, where it downloads it from, its platform and the hypervisor you are using. A example from the homes module below:</p>

<pre><code>HOSTS:
  ubuntu-server-12042-x64:
  roles:
    - master
  platform: ubuntu-12.04-amd64
  box : ubuntu-server-12042-x64-vbox4210-nocm
  box_url : http://puppet-vagrant-boxes.puppetlabs.com/ubuntu-server-12042-x64-vbox4210-nocm.box
  hypervisor : vagrant
CONFIG:
  log_level: verbose
  type: git
</code></pre>

<p>More detail about how to configure these yaml files can be found on the Beaker wiki, <a href="https://github.com/puppetlabs/beaker/wiki/Creating-A-Test-Environment">Creating A Test Environment</a></p>

<p>In the above example I am using Vagrant boxes provided by PuppetLabs but there are a few other sources to discover already pre-built boxes:</p>

<ul>
<li><a href="http://puppet-vagrant-boxes.puppetlabs.com/">http://puppet-vagrant-boxes.puppetlabs.com/</a></li>
<li><a href="http://www.vagrantbox.es/">http://www.vagrantbox.es/</a></li>
<li><a href="https://vagrantcloud.com">https://vagrantcloud.com</a></li>
</ul>


<h3>Writing tests in Beaker</h3>

<p>So now that we have our environment set up let’s look at actually writing some tests. Here is an example from the homes project:</p>

<pre><code>require ‘spec_helper_acceptance'

describe 'homes defintion', :unless =&gt; UNSUPPORTED_PLATFORMS.include?(fact('osfamily')) do

  context 'valid user parameter’ do

    it 'should work with no errors’ do
      pp = &lt;&lt;-EOS
        $myuser = {
        'testuser' =&gt; { 'shell' =&gt; '/bin/bash' }
      }

      homes { 'testuser':
        user =&gt; $myuser
      }
      EOS

      apply_manifest(pp, :catch_failures =&gt; true)
      expect(apply_manifest(pp, :catch_failures =&gt; true).exit_code).to be_zero
   end

   describe user('testuser') do
     it { should exist }
   end

   describe file('/home/testuser') do
     it { should be_directory }
   end
 end

end
</code></pre>

<p>In this case we are writing a test to make sure that when our module runs, it creates the user and its home directory as it expects. Using the UNSUPPORTED_PLATFORMS that we defined earlier we can also skip groups of tests if they are not supported on the current node.</p>

<p>The idea here is that we define a manifest (using Heredoc &ndash; but please don’t make them too long!) and then we want to apply that manifest to the node. Beaker provides a nice helper methods that: apply_manifest. In our case we run it once, which will cause the changes and then we run it a second time with the scope of a test to check for idempotency. We can then make use of Beaker’s resource based helpers to actually test the functionality on the node itself. Their many helper methods will allow you to do almost everything that you need to do, either for setup purposes or for actually testing the node:</p>

<ul>
<li><a href="https://github.com/puppetlabs/beaker/wiki/The-Beaker-DSL-API">The-Beaker-DSL-API</a></li>
<li><a href="https://github.com/puppetlabs/beaker/blob/master/lib/beaker/dsl/helpers.rb">beaker/dsl/helpers.rb</a></li>
</ul>


<p>It’s actually worth noting that Beaker makes heavy use of <a href="https://github.com/serverspec/serverspec">serverspec</a> which you should go and take a look at.</p>

<h2>Summary</h2>

<p>So now you know a little about testing Beaker with Puppet go forth and test all your modules against everything that you expect your users to be running it on.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Grunt + Vagrant = Acceptance Test Heaven]]></title>
    <link href="http://tech.opentable.co.uk/blog/2013/08/16/grunt-plus-vagrant-equals-acceptance-test-heaven/"/>
    <updated>2013-08-16T15:32:00+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2013/08/16/grunt-plus-vagrant-equals-acceptance-test-heaven</id>
    <content type="html"><![CDATA[<p>My continued love affair with Grunt reached a new high the other day, when I combined <a href="http://www.vagrantup.com">Vagrant</a> with my <a href="http://tech.opentable.co.uk/blog/2013/08/08/grunt-your-deployments-too/">Grunt deployment tasks</a> and test runners.</p>

<p>I&rsquo;m not going to bang on about how great Vagrant is, because better people than me have already soliloquised at length on that subject. Let&rsquo;s just take it as writ that <strong>Vagrant is awesome</strong>.</p>

<p>The objective is simple, we want to have a virtualised environment to run our acceptance tests against, that we can create and provision on demand, to ensure that our acceptance tests only deal with functional-correctness, not data- or environment-correctness.</p>

<p>I created a set of Grunt tasks which were able to do the following:</p>

<ul>
<li>Spin up an provision a Vagrant instance</li>
<li>Deploy the project code</li>
<li>Start the server</li>
<li>Run the acceptance tests</li>
<li>Tear it all down</li>
</ul>


<p>All from a single command: <code>grunt acceptance</code></p>

<p>The price of this magic? About ten lines of Bash script, a six line Vagrantfile and some Grunt glue.</p>

<h2>Diving in</h2>

<p>Assuming you&rsquo;ve got Vagrant installed, you can create a Vagrantfile in the root of your project, which looks like this:</p>

<pre><code>Vagrant.configure("2") do |config|
    config.vm.box = "Ubuntu precise 64 VMWare"
    config.vm.box_url = "http://files.vagrantup.com/precise64_vmware.box"
    config.vm.network :forwarded_port, guest: 3000, host: 3000
    config.vm.provision :shell, :path =&gt; "setup/bootstrap.sh"
end
</code></pre>

<p>Notice the last line &lsquo;config.vm.provision&rsquo;, this tells Vagrant that there is a shell script at setup/bootstrap.sh which is going to provision your vm. You can provision the box with Puppet, Chef or a variety of other tools, but for the purposes of this simple testing machine, I&rsquo;m happy to use a shell script.</p>

<p>Let&rsquo;s have a look at the bootstrap file:</p>

<pre><code>apt-get update -y -q
apt-get install build-essential mongodb -y -q

cp /vagrant/tests/acceptance-tests/mongodb.conf /etc/mongodb.conf
service mongodb restart

wget --quiet http://nodejs.org/dist/v0.10.15/node-v0.10.15-linux-x64.tar.gz

tar -zxf node-v0.10.15-linux-x64.tar.gz

mv node-v0.10.15-linux-x64/ /opt/node/
ln -s /opt/node/bin/node /usr/bin/node
ln -s /opt/node/bin/npm /usr/bin/npm
</code></pre>

<p>After booting the VM, Vagrant will run this script, which will can do anything you need it to. All the commands run as root, so there&rsquo;s very little restriction as to what you can achieve.</p>

<p>We&rsquo;re installing Node.js (downloading the binaries manually because the version of Node in the Ubuntu repository is really old), and MongoDB (which our app depends on).</p>

<p>Note this line: <code>cp /vagrant/tests/acceptance-tests/mongodb.conf /etc/mongodb.conf</code> which installs a custom config for MongoDB.</p>

<p>By default, Vagrant will mount a share in /vagrant to the current directory (i.e. the directory on the host machine from which you executed <code>vagrant up</code>), you can map additional folders by adding <code>config.vm.synced_folder "path/on/host", "/path/on/guest"</code> to your Vagrantfile.</p>

<p>Now that we&rsquo;ve got our Vagrant config sorted, we can hook this into Grunt, using a bit of glue code.</p>

<pre><code>var shell = require('shelljs');

grunt.registerTask('vagrant-up', function(){
    shell.exec('vagrant up');
});

grunt.registerTask('vagrant-destroy', function(){
    shell.exec('vagrant destroy -f');
});
</code></pre>

<p>So now that we&rsquo;ve got our machine provisioned and booted, we can use Grunt to <a href="http://tech.opentable.co.uk/blog/2013/08/08/grunt-your-deployments-too/">deploy our code and start our service</a>.</p>

<p>Assuming that we&rsquo;ve got all that going on, we can move on to the next step, getting Grunt to deploy the code to the Vagrant box.</p>

<p>What I&rsquo;m going to do here is hook the deployment step into the &lsquo;vagrant-up&rsquo; task.</p>

<pre><code>grunt.registerTask('vagrant-up', function(){
    shell.exec('vagrant up');
    grunt.option('config', 'vagrant');
    grunt.task.run('deploy');
});
</code></pre>

<p>The reason for this is so that <code>grunt vagrant-up</code> will spin me up a provisioned box <em>and</em> install the code.</p>

<p>You&rsquo;ll notice that I set the &lsquo;config&rsquo; option inside the task, this option is required by the deploy task. I could specify it on the command line, but this is just friendlier and makes for a cleaner syntax of the command.</p>

<p>Now, when we run <code>grunt acceptance</code>, it&rsquo;ll do the following:</p>

<ul>
<li>Spin up the Vagrant box</li>
<li>Deploy the code</li>
<li>Tear it down again</li>
</ul>


<p>The only step remaining is to run our acceptance tests. For our app, we&rsquo;re using mocha, you can use anything so long as you&rsquo;ve got a Grunt task to drop in.</p>

<pre><code>var shell = require('shelljs');

grunt.initConfig({
    ...
    mochaTest: {
        options: {
            reporter: 'spec'
        },
        AcceptanceTests:{
            src: ['tests/acceptance-tests/**/*.js']
        }
    }
});

grunt.registerTask('deploy', [
    'sshexec:stop',
    'sshexec:make-release-dir',
    'sshexec:update-symlinks',
    'sftp:deploy',
    'sshexec:npm-update',
    'sshexec:set-config',
    'sshexec:start'
]);

grunt.registerTask('vagrant-up', function(){
    shell.exec('vagrant up');
    grunt.option('config', 'vagrant');
    grunt.task.run('deploy');
});

grunt.registerTask('vagrant-test', [ 'mochaTest:AcceptanceTests' ]);

grunt.registerTask('vagrant-destroy', function(){
    shell.exec('vagrant destroy -f');
});

grunt.registerTask('acceptance', [
    'vagrant-up',
    'vagrant-test',
    'vagrant-destroy'
]);
</code></pre>

<p>Ta-Da! Wasn&rsquo;t that painless?</p>

<p>The key part here is that everything is now in source control. So whenever someone checks out the project, it takes precisely <strong><em>one</em></strong> command to get the project going. No more time wasted configuring your dev machine to be able to run this, or that.</p>

<p>The machine is brand-new every time, with its own spangly MongoDB instance ready for use.</p>

<p>What&rsquo;s that I hear you whine? &ldquo;<em>My application depends on shared data, I can&rsquo;t use an empty database</em>&rdquo;. Not true. If you need it, set it up or mock it out. The acceptance tests should set-up and tear-down all their own data, if you rely on shared data sources for acceptance tests then you&rsquo;re going to have a painful time. Script it once and it&rsquo;ll forever be your friend. It&rsquo;s time to enter the dynamic era, no more false failures on your CI build because a shared datasource is missing and/or has been changed.</p>

<p>What&rsquo;s more you can now run <code>grunt acceptance</code> from anywhere and <strong><em>know</em></strong> that it&rsquo;ll be the same. No more environment pains!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Vagrant to work with ElasticSearch on your local machine]]></title>
    <link href="http://tech.opentable.co.uk/blog/2013/08/05/using-vagrant-to-work-with-elasticsearch-on-your-local-machine/"/>
    <updated>2013-08-05T08:45:00+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2013/08/05/using-vagrant-to-work-with-elasticsearch-on-your-local-machine</id>
    <content type="html"><![CDATA[<p>Recently, I have started to work a lot more with <a href="http://www.vagrantup.com/">Vagrant</a> as a tool for creating a standard development environment across my team. This essentially means that regardless what the developers' machine is set up or running as, they can still reproduce the same environment as their colleagues just by entering a command.</p>

<p>Configuration managgement is something we have had to embrace to help us maintain an ever changing world of technologies. The hardest thing is knowing what we actually have to build in these environments. We use Vagrant to help us understand this. The simple flow is as follows:</p>

<ul>
<li>Developer starts a new project</li>
<li>Developer creates a Vagrantfile to spin up a local VM</li>
<li>Vagrantfile gets iterated on as the development process goes forward</li>
</ul>


<p>Once the developer understands what they need to actually run their software, we would then go about creating an environment to which this software will actually be deployed for end-to-end testing. I won&rsquo;t go any further into the details of our Vagrant flow in this post, if you want to read more about how to get started with Vagrant, then I would suggest reading <a href="http://shop.oreilly.com/product/0636920026358.do">Vagrant Up and Running</a> by <a href="https://twitter.com/mitchellh">Mitchell Hashimoto</a>.</p>

<h2>Vagrant and ElasticSearch</h2>

<p>Whilst reviewing a book on <a href="http://www.elasticsearch.org/">ElasticSearch</a>, I noticed how simple the instructions were to get up and running with ElasticSearch. Please note, that there are already lots of Puppet modules for configuring ElasticSearch on <a href="http://forge.puppetlabs.com/modules?q=elasticsearch">Puppetlabs Forge</a>. This post only talks about how I was able to quickly spin up some local instances. I didn&rsquo;t want to manually do this, so I decided to use Vagrant (and Puppet) to take care of it for me. The instructions can be summarised as follows:</p>

<ul>
<li>Download and install the JavaSDK</li>
<li>Download the specific ElasticSearch package</li>
<li>Install ElasticSearch</li>
<li>Download and install curl (to be able to interact with ElasticSearch)</li>
<li>Make sure the service is started</li>
</ul>


<p>I hate doing this manually. Luckily, with the correct script, I am able to automate all of this as follows:</p>

<pre><code>Vagrant.configure("2") do |config|
    config.vm.box = "Ubuntu precise 64 VMWare"
    config.vm.box_url = "http://files.vagrantup.com/precise64_vmware.box"
    config.vm.network :forwarded_port, guest: 9200, host: 9200
    config.vm.provision :puppet do |puppet|
        puppet.module_path = '../setup/modules'
        puppet.manifests_path = '../setup/manifests'
        puppet.manifest_file = 'default.pp'
        puppet.options = '--verbose --debug'
    end
end
</code></pre>

<p>Essentially, this script says to create a clone of a VM from a predefined box, forward port 9200 on the vm to 9200 on my local machine and then provision the server using Puppet. The Puppet script works as follows:</p>

<pre><code>exec { "apt-get-update":
    command =&gt; "/usr/bin/apt-get update",
}

package {'curl':
    provider =&gt; apt,
    ensure   =&gt; latest,
    require  =&gt; Exec['apt-get-update']
}

class {'elasticsearch':
    version =&gt; '0.90.0',
    require =&gt; Exec['apt-get-update'],
}
</code></pre>

<p>This defines that the command apt-get-update gets applied (due to both the class and the package requiring it) and then will install curl and ElasticSearch in no particular order. Once the script runs, I will be able to open a browser on my local machine, go to <a href="http://localhost:9200">http://localhost:9200</a> and see the newly provisioned ElasticSearch node. The result of the JSON was something similar to this:</p>

<pre><code>{
    "ok" : true,
    "status" : 200,
    "name" : "Gibborim",
    "version" : {
        "number" : "0.90.0",
        "snapshot_build" : false,
    },
    "tagline" : "You Know, for Search"
}
</code></pre>

<p>By entering the URL, &lsquo;**<a href="http://localhost:9200/_cluster/health?pretty**">http://localhost:9200/_cluster/health?pretty**</a>&rsquo;, you can see the state of the ElasticSearch cluster. It should show something like this:</p>

<pre><code>{
    "cluster_name" : "elasticsearch",
    "status" : "yellow",
    "timed_out" : false,
    "number_of_nodes" : 1,              
    "number_of_data_nodes" : 1,         
    "active_primary_shards" : 5,        
    "active_shards" : 5,                
    "relocating_shards" : 0,            
    "initializing_shards" : 0,          
    "unassigned_shards" : 5             
}
</code></pre>

<p>I wanted to be able to provision multiple nodes and then let them create a cluster. I was able to take the existing Vagrantfile and then using the multi-environment features of Vagrant. This created a new Vagrantfile as follows:</p>

<pre><code>Vagrant::Config.run do |config|
    config.vm.box = "Ubuntu precise 64 VMWare"
    config.vm.box_url = "http://files.vagrantup.com/precise64_vmware.box"

    config.vm.define "es1" do |es1|
        es1.vm.network :hostonly, "192.168.1.10"
        es1.vm.provision :puppet do |puppet|
            puppet.module_path = '../setup/modules'
            puppet.manifests_path = '../setup/manifests'
            puppet.manifest_file = 'default.pp'
            puppet.options = '--verbose --debug'
        end
    end

    config.vm.define "es2" do |es2|
        es2.vm.network :hostonly, "192.168.1.11"
        es2.vm.provision :puppet do |puppet|
            puppet.module_path = '../setup/modules'
            puppet.manifests_path = '../setup/manifests'
            puppet.manifest_file = 'default.pp'
            puppet.options = '--verbose --debug'
        end
    end

    config.vm.define "es3" do |es3|
        es3.vm.network :hostonly, "192.168.1.12"
        es3.vm.provision :puppet do |puppet|
            puppet.module_path = '../setup/modules'
            puppet.manifests_path = '../setup/manifests'
            puppet.manifest_file = 'default.pp'
            puppet.options = '--verbose --debug'
        end
    end
end
</code></pre>

<p>This effectively tells Vagrant to create three instances of ElasticSearch using the Puppet configuration (as above). Each ElasticSearch node is given its own IP. Thanks to ElasticSearch using Multicast and Unicast discovery, it is able to find other nodes on the network and create a cluster. By running a similar url as before, &lsquo;**<a href="http://192.168.1.10:9200/_cluster/health?pretty**">http://192.168.1.10:9200/_cluster/health?pretty**</a>&rsquo;, we can now see that the cluster looks as follows:</p>

<pre><code>{
    "cluster_name" : "elasticsearch",
    "status" : "green",
    "timed_out" : false,
    "number_of_nodes" : 3,              
    "number_of_data_nodes" : 3,         
    "active_primary_shards" : 5,        
    "active_shards" : 15,                
    "relocating_shards" : 0,            
    "initializing_shards" : 0,          
    "unassigned_shards" : 0             
}
</code></pre>

<p>Using this method, we can continue to spin up as many instances as we need to replicate different scenarios or testing conditions. Vagrant has made this very easy to do. If you want a copy of the Vagrantfiles and Puppet modules to try this yourself, then you can find them on my <a href="https://github.com/stack72/vagrant-examples/tree/master/elasticsearch">github repository</a>. The scripts are available under the <a href="http://opensource.org/licenses/MIT">MIT</a> license.</p>
]]></content>
  </entry>
  
</feed>
