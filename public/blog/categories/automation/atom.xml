<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Automation | OpenTable Tech UK Blog]]></title>
  <link href="http://tech.opentable.co.uk/blog/categories/automation/atom.xml" rel="self"/>
  <link href="http://tech.opentable.co.uk/"/>
  <updated>2015-02-07T14:21:51+00:00</updated>
  <id>http://tech.opentable.co.uk/</id>
  <author>
    <name><![CDATA[OpenTable]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Grunt + Vagrant = Acceptance Test Heaven]]></title>
    <link href="http://tech.opentable.co.uk/blog/2013/08/16/grunt-plus-vagrant-equals-acceptance-test-heaven/"/>
    <updated>2013-08-16T15:32:00+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2013/08/16/grunt-plus-vagrant-equals-acceptance-test-heaven</id>
    <content type="html"><![CDATA[<p>My continued love affair with Grunt reached a new high the other day, when I combined <a href="http://www.vagrantup.com">Vagrant</a> with my <a href="http://tech.opentable.co.uk/blog/2013/08/08/grunt-your-deployments-too/">Grunt deployment tasks</a> and test runners.</p>

<p>I&rsquo;m not going to bang on about how great Vagrant is, because better people than me have already soliloquised at length on that subject. Let&rsquo;s just take it as writ that <strong>Vagrant is awesome</strong>.</p>

<p>The objective is simple, we want to have a virtualised environment to run our acceptance tests against, that we can create and provision on demand, to ensure that our acceptance tests only deal with functional-correctness, not data- or environment-correctness.</p>

<p>I created a set of Grunt tasks which were able to do the following:</p>

<ul>
<li>Spin up an provision a Vagrant instance</li>
<li>Deploy the project code</li>
<li>Start the server</li>
<li>Run the acceptance tests</li>
<li>Tear it all down</li>
</ul>


<p>All from a single command: <code>grunt acceptance</code></p>

<p>The price of this magic? About ten lines of Bash script, a six line Vagrantfile and some Grunt glue.</p>

<h2>Diving in</h2>

<p>Assuming you&rsquo;ve got Vagrant installed, you can create a Vagrantfile in the root of your project, which looks like this:</p>

<pre><code>Vagrant.configure("2") do |config|
    config.vm.box = "Ubuntu precise 64 VMWare"
    config.vm.box_url = "http://files.vagrantup.com/precise64_vmware.box"
    config.vm.network :forwarded_port, guest: 3000, host: 3000
    config.vm.provision :shell, :path =&gt; "setup/bootstrap.sh"
end
</code></pre>

<p>Notice the last line &lsquo;config.vm.provision&rsquo;, this tells Vagrant that there is a shell script at setup/bootstrap.sh which is going to provision your vm. You can provision the box with Puppet, Chef or a variety of other tools, but for the purposes of this simple testing machine, I&rsquo;m happy to use a shell script.</p>

<p>Let&rsquo;s have a look at the bootstrap file:</p>

<pre><code>apt-get update -y -q
apt-get install build-essential mongodb -y -q

cp /vagrant/tests/acceptance-tests/mongodb.conf /etc/mongodb.conf
service mongodb restart

wget --quiet http://nodejs.org/dist/v0.10.15/node-v0.10.15-linux-x64.tar.gz

tar -zxf node-v0.10.15-linux-x64.tar.gz

mv node-v0.10.15-linux-x64/ /opt/node/
ln -s /opt/node/bin/node /usr/bin/node
ln -s /opt/node/bin/npm /usr/bin/npm
</code></pre>

<p>After booting the VM, Vagrant will run this script, which will can do anything you need it to. All the commands run as root, so there&rsquo;s very little restriction as to what you can achieve.</p>

<p>We&rsquo;re installing Node.js (downloading the binaries manually because the version of Node in the Ubuntu repository is really old), and MongoDB (which our app depends on).</p>

<p>Note this line: <code>cp /vagrant/tests/acceptance-tests/mongodb.conf /etc/mongodb.conf</code> which installs a custom config for MongoDB.</p>

<p>By default, Vagrant will mount a share in /vagrant to the current directory (i.e. the directory on the host machine from which you executed <code>vagrant up</code>), you can map additional folders by adding <code>config.vm.synced_folder "path/on/host", "/path/on/guest"</code> to your Vagrantfile.</p>

<p>Now that we&rsquo;ve got our Vagrant config sorted, we can hook this into Grunt, using a bit of glue code.</p>

<pre><code>var shell = require('shelljs');

grunt.registerTask('vagrant-up', function(){
    shell.exec('vagrant up');
});

grunt.registerTask('vagrant-destroy', function(){
    shell.exec('vagrant destroy -f');
});
</code></pre>

<p>So now that we&rsquo;ve got our machine provisioned and booted, we can use Grunt to <a href="http://tech.opentable.co.uk/blog/2013/08/08/grunt-your-deployments-too/">deploy our code and start our service</a>.</p>

<p>Assuming that we&rsquo;ve got all that going on, we can move on to the next step, getting Grunt to deploy the code to the Vagrant box.</p>

<p>What I&rsquo;m going to do here is hook the deployment step into the &lsquo;vagrant-up&rsquo; task.</p>

<pre><code>grunt.registerTask('vagrant-up', function(){
    shell.exec('vagrant up');
    grunt.option('config', 'vagrant');
    grunt.task.run('deploy');
});
</code></pre>

<p>The reason for this is so that <code>grunt vagrant-up</code> will spin me up a provisioned box <em>and</em> install the code.</p>

<p>You&rsquo;ll notice that I set the &lsquo;config&rsquo; option inside the task, this option is required by the deploy task. I could specify it on the command line, but this is just friendlier and makes for a cleaner syntax of the command.</p>

<p>Now, when we run <code>grunt acceptance</code>, it&rsquo;ll do the following:</p>

<ul>
<li>Spin up the Vagrant box</li>
<li>Deploy the code</li>
<li>Tear it down again</li>
</ul>


<p>The only step remaining is to run our acceptance tests. For our app, we&rsquo;re using mocha, you can use anything so long as you&rsquo;ve got a Grunt task to drop in.</p>

<pre><code>var shell = require('shelljs');

grunt.initConfig({
    ...
    mochaTest: {
        options: {
            reporter: 'spec'
        },
        AcceptanceTests:{
            src: ['tests/acceptance-tests/**/*.js']
        }
    }
});

grunt.registerTask('deploy', [
    'sshexec:stop',
    'sshexec:make-release-dir',
    'sshexec:update-symlinks',
    'sftp:deploy',
    'sshexec:npm-update',
    'sshexec:set-config',
    'sshexec:start'
]);

grunt.registerTask('vagrant-up', function(){
    shell.exec('vagrant up');
    grunt.option('config', 'vagrant');
    grunt.task.run('deploy');
});

grunt.registerTask('vagrant-test', [ 'mochaTest:AcceptanceTests' ]);

grunt.registerTask('vagrant-destroy', function(){
    shell.exec('vagrant destroy -f');
});

grunt.registerTask('acceptance', [
    'vagrant-up',
    'vagrant-test',
    'vagrant-destroy'
]);
</code></pre>

<p>Ta-Da! Wasn&rsquo;t that painless?</p>

<p>The key part here is that everything is now in source control. So whenever someone checks out the project, it takes precisely <strong><em>one</em></strong> command to get the project going. No more time wasted configuring your dev machine to be able to run this, or that.</p>

<p>The machine is brand-new every time, with its own spangly MongoDB instance ready for use.</p>

<p>What&rsquo;s that I hear you whine? &ldquo;<em>My application depends on shared data, I can&rsquo;t use an empty database</em>&rdquo;. Not true. If you need it, set it up or mock it out. The acceptance tests should set-up and tear-down all their own data, if you rely on shared data sources for acceptance tests then you&rsquo;re going to have a painful time. Script it once and it&rsquo;ll forever be your friend. It&rsquo;s time to enter the dynamic era, no more false failures on your CI build because a shared datasource is missing and/or has been changed.</p>

<p>What&rsquo;s more you can now run <code>grunt acceptance</code> from anywhere and <strong><em>know</em></strong> that it&rsquo;ll be the same. No more environment pains!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Managing Windows Certificates with PowerShell]]></title>
    <link href="http://tech.opentable.co.uk/blog/2013/07/08/managing-windows-certificates-with-powershell/"/>
    <updated>2013-07-08T18:51:00+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2013/07/08/managing-windows-certificates-with-powershell</id>
    <content type="html"><![CDATA[<p>Managing certificates on Windows is <em>really</em> painful. There is no easy way to do it. The general way to install a certificate to a Windows Server 2008 machine is as follows:</p>

<ul>
<li>Open the Certificates snap-in for a user, computer, or service.</li>
<li>In the console tree, click the logical store where you want to import the certificate.</li>
<li>On the Action menu, point to All Tasks, and then click Import to start the Certificate Import Wizard.</li>
<li>Type the file name containing the certificate to be imported.</li>
<li>If you want to specify where the certificate is stored, select Place all certificates in the following store, click Browse, and choose the certificate store to use. OR</li>
<li>If the certificate should be automatically placed in a certificate store based on the type of certificate, click Automatically select the certificate store based on the type of certificate.</li>
</ul>


<p>The first time I ran this process, I felt as though this was just wrong to not be able to automate. The goal of our team is to automate everything we are currently doing manually. PowerShell is a better option for this import process as it allows you to write code to do it. As we all know, code is better for a number of reasons, I won&rsquo;t go into the infrastructure as code argument in this post (but it is coming soonâ€¦.). Using PowerShell, I can write a simple function as follows:</p>

<pre><code>function Import-PfxCertificate($certName, $CertLocaton, $certRootStore, $certStore) {    
     $pfx = new-object System.Security.Cryptography.X509Certificates.X509Certificate2    

     $pfxPass = convertto-securestring $CertPassword -asplaintext -force

     $certPath = $CertLocaton + "\" + $certName   
     $pfx.import($certPath,$pfxPass,"Exportable,PersistKeySet")    

     $store = new-object System.Security.Cryptography.X509Certificates.X509Store($certStore,$certRootStore)    
     $store.open("MaxAllowed")    
     $store.add($pfx)    
     $store.close()    
}
</code></pre>

<p>This makes certificate management easier. To manage certificates in this way, I just need to invoke a script similar to this:</p>

<pre><code>.\import-certificate.ps1 -CertificateName "mycert.pfx" -CertLocation "c:\ssl\mycerts"
</code></pre>

<p>Much simpler! You can download a <a href="https://gist.github.com/opentable-devops/5951108">gist</a> of this script should you wish to use it. Please note that the license that this script is available under can be read from our <a href="https://github.com/opentable/licensing/blob/master/LICENSE">github repository</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Windows Feature Management with PowerShell]]></title>
    <link href="http://tech.opentable.co.uk/blog/2013/06/14/windows-feature-management-with-powershell/"/>
    <updated>2013-06-14T20:31:00+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2013/06/14/windows-feature-management-with-powershell</id>
    <content type="html"><![CDATA[<p>In late 2012, our development team started to move towards our systems being much more automated. Long gone are the days of developers creating runbooks in Word and giving them to our operations team to use to set up our production servers.</p>

<p>When building our webservers on Windows, in order to install / activate Windows features, this was the general set of instructions that was needed to be followed:</p>

<ul>
<li>Click Start Button</li>
<li>Click on Control Panel</li>
<li>Click on Programs</li>
<li>Click on Turn Windows features on or off</li>
</ul>


<p>This would present a screen as follows:</p>

<p><img class="center" src="/images/posts/windowsfeature.png"></p>

<p>You would need to find the correct features to enable and check the box, press OK and then wait for the features to be installed.</p>

<p>When Microsoft introduced Windows Server 2008 and PowerShell 2.0, they also introducted the module &lsquo;ServerManager&rsquo;. This is a module that allows us to interact, with PowerShell, Windows Features using a range of cmdlets:</p>

<ul>
<li>Get-WindowsFeature</li>
<li>Add-WindowsFeature</li>
<li>Remove-WindowsFeature</li>
</ul>


<p>This meant that instead of creating runbooks in Word, our developers could create automation scripts that would take a base Windows Server 2008 server and enable all the Windows Features needed to run our applications. This allowed our operations team to move much faster in configuring our servers.</p>

<p>To turn on the ASP.NET Application Development features in Windows, we would run the following script from PowerShell:</p>

<pre><code>Import-Module ServerManager
Add-WindowsFeature Web-Asp-Net
</code></pre>

<p>By knowing what Windows Features we needed to install on our servers, we were able to create the following script:</p>

<pre><code>function enable_net_3_5_features()
{
    Add-WindowsFeature NET-HTTP-Activation
    Add-WindowsFeature NET-Win-CFAC
    Add-WindowsFeature NET-Non-HTTP-Activ
    Add-WindowsFeature AS-MSMQ-Activation
}

function enable_iis_common_http_features()
{
    Add-WindowsFeature Web-Static-Content
    Add-WindowsFeature Web-Http-Errors
    Add-WindowsFeature Web-Default-Doc
}

function enable_iis_application_development_features()
{
    Add-WindowsFeature Web-Asp-Net
    Add-WindowsFeature Web-Net-Ext
    Add-WindowsFeature Web-ISAPI-Ext
    Add-WindowsFeature Web-ISAPI-Filter
}

function enable_iis_health_and_diagnostics_features()
{
    Add-WindowsFeature Web-Http-Logging
    Add-WindowsFeature Web-Request-Monitor
}

function enable_iis_security_features()
{
    Add-WindowsFeature Web-Filtering
}

function enable_iis_performance_features()
{
    Add-WindowsFeature Web-Stat-Compression
    Add-WindowsFeature Web-Dyn-Compression
}

function enable_iis_management_tools()
{
    Add-WindowsFeature Web-Mgmt-Tools
    Add-WindowsFeature Web-Mgmt-Console
}


Write-Host('Starting Application Server Setup')

Import-Module ServerManager
enable_net_3_5_features
enable_iis_common_http_features
enable_iis_application_development_features
enable_iis_health_and_diagnostics_features
enable_iis_security_features
enable_iis_performance_features
enable_iis_management_tools 

Write-Host('Application Server Setup complete')
</code></pre>

<p>Running the script, meant that we could enable features much faster than we could enable them via the GUI. Notice how we have grouped how we enable Windows Features into the same groupings found in the &lsquo;Turn Windows features on or off&rsquo; menu. For a full list of the names of the features that can be turned on or off, please refer to this <a href="http://technet.microsoft.com/en-us/library/cc732757.aspx">technet article</a></p>

<p>You can download a <a href="https://gist.github.com/opentable-devops/5886831">gist</a> of this script if you want to use it. Please note that the license that this script is available under can be read from our <a href="https://github.com/opentable/licensing/blob/master/LICENSE">github repository</a>. We hope that the script helps you as much as it helped us.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Started With SpecRun]]></title>
    <link href="http://tech.opentable.co.uk/blog/2013/06/07/getting-started-with-specrun/"/>
    <updated>2013-06-07T11:33:00+01:00</updated>
    <id>http://tech.opentable.co.uk/blog/2013/06/07/getting-started-with-specrun</id>
    <content type="html"><![CDATA[<h2>First some background</h2>

<p>We recently switched from writing automated acceptance from Cucumber to SpecFlow&hellip; this is no slight on Cucumber it&rsquo;s just that we had a lot of C# developers who wanted to get closer to writing acceptance tests. Worth adding that SpecFlow has also come a long way as a .Net port of Cucumber and is pretty much like for like now.</p>

<h2>Why should I bother with SpecRun?</h2>

<p>Initially we ran our entire unit, integration and acceptance tests via nUnit. Pretty much industry standard but we felt nUnit wasn&rsquo;t really a good tool to run acceptance tests &ndash; yes it&rsquo;ll do the job but we were looking for better performance, quicker failure feedback and more comprehensive reporting. If you want details on SpecRun vs. nUnit Gasper has a <a href="http://gasparnagy.com/2011/09/specrun-because-integration-tests-are-not-unit-tests/">great blog post</a>.</p>

<p><salespitch>SpecRun itself is free to use although there is a random delay when running acceptance locally, setting up SpecRun on a CI environment is totally free and does not include the same delay. Definitely worth trying out and you can purchase a licence later if you like what it offers.</salespitch></p>

<h2>Installing SpecRun</h2>

<p>If you are already using SpecFlow with nUnit the migration to SpecRun is really simple &ndash; <a href="http://www.youtube.com/watch?v=c2ge90BWeI0">this video</a> shows you how to setup the test runner but I found myself having to watch it too many times. This post is an attempt at recording the steps should we roll out SpecRun for another project.</p>

<p>I&rsquo;m assuming you&rsquo;re running Visual Studio and are familiar with Nuget packages. I&rsquo;ll break it down so I don&rsquo;t miss anything:</p>

<ol>
<li>In VS, select your Acceptance test project and get the Nuget package down for SpecRun: <code>install-package SpecRun</code>.</li>
<li>You&rsquo;ll notice Nuget automatically adds configuration to your app.config so it&rsquo;s safe to remove the nUnit provider setting (this is to enable you to pick and choose your test runner but we prefer to only use SpecRun).</li>
<li>Open the Default.srprofile file and we normally delete any commented settings here.</li>
<li>Still inside Default.srprofile add the properties for projectName and projectId. The projectName is what you see in VS the projectId can be found by opening the acceptance .proj file and taking the projectGuid.</li>
<li>Setup the execution properties &ndash; this really depends on what you want to get out of running the tool &ndash; what retry count you want, whether to run on multiple threads, etc. Here are the values we normally use:</li>
</ol>


<p><code>&lt;Execution retryFor="None" stopAfterFailures="100" testThreadCount="1" testSchedulingMode="Sequential" apartmentState="STA"/&gt;</code></p>

<ol>
<li>We did tweak the SpecRun .cmd file used to run acceptance via command line &ndash; <a href="https://dl.dropboxusercontent.com/u/8835075/runacceptance.cmd">copy this file</a> to your project root, you may need to tweak some names and paths.</li>
</ol>


<p>Once you&rsquo;ve gone through those steps you should be able to browse to your project root, type <strong>runacceptance.cmd tag_to_run</strong> and it&rsquo;ll run your acceptance tests tagged <strong>@tag_to_run</strong>  (NOTE: you don&rsquo;t need to specify the @ symbol).</p>
]]></content>
  </entry>
  
</feed>
